{"ast":null,"code":"\"use strict\";\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.charCodeToOptimizedIndex = exports.minOptimizationVal = exports.buildLineBreakIssueMessage = exports.LineTerminatorOptimizedTester = exports.isShortPattern = exports.isCustomPattern = exports.cloneEmptyGroups = exports.performWarningRuntimeChecks = exports.performRuntimeChecks = exports.addStickyFlag = exports.addStartOfInput = exports.findUnreachablePatterns = exports.findModesThatDoNotExist = exports.findInvalidGroupType = exports.findDuplicatePatterns = exports.findUnsupportedFlags = exports.findStartOfInputAnchor = exports.findEmptyMatchRegExps = exports.findEndOfInputAnchor = exports.findInvalidPatterns = exports.findMissingPatterns = exports.validatePatterns = exports.analyzeTokenTypes = exports.enableSticky = exports.disableSticky = exports.SUPPORT_STICKY = exports.MODES = exports.DEFAULT_MODE = void 0;\n\nconst regexp_to_ast_1 = require(\"regexp-to-ast\");\n\nconst lexer_public_1 = require(\"./lexer_public\");\n\nconst first_1 = __importDefault(require(\"lodash/first\"));\n\nconst isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\n\nconst compact_1 = __importDefault(require(\"lodash/compact\"));\n\nconst isArray_1 = __importDefault(require(\"lodash/isArray\"));\n\nconst values_1 = __importDefault(require(\"lodash/values\"));\n\nconst flatten_1 = __importDefault(require(\"lodash/flatten\"));\n\nconst reject_1 = __importDefault(require(\"lodash/reject\"));\n\nconst difference_1 = __importDefault(require(\"lodash/difference\"));\n\nconst indexOf_1 = __importDefault(require(\"lodash/indexOf\"));\n\nconst map_1 = __importDefault(require(\"lodash/map\"));\n\nconst forEach_1 = __importDefault(require(\"lodash/forEach\"));\n\nconst isString_1 = __importDefault(require(\"lodash/isString\"));\n\nconst isFunction_1 = __importDefault(require(\"lodash/isFunction\"));\n\nconst isUndefined_1 = __importDefault(require(\"lodash/isUndefined\"));\n\nconst find_1 = __importDefault(require(\"lodash/find\"));\n\nconst has_1 = __importDefault(require(\"lodash/has\"));\n\nconst keys_1 = __importDefault(require(\"lodash/keys\"));\n\nconst isRegExp_1 = __importDefault(require(\"lodash/isRegExp\"));\n\nconst filter_1 = __importDefault(require(\"lodash/filter\"));\n\nconst defaults_1 = __importDefault(require(\"lodash/defaults\"));\n\nconst reduce_1 = __importDefault(require(\"lodash/reduce\"));\n\nconst includes_1 = __importDefault(require(\"lodash/includes\"));\n\nconst utils_1 = require(\"@chevrotain/utils\");\n\nconst reg_exp_1 = require(\"./reg_exp\");\n\nconst reg_exp_parser_1 = require(\"./reg_exp_parser\");\n\nconst PATTERN = \"PATTERN\";\nexports.DEFAULT_MODE = \"defaultMode\";\nexports.MODES = \"modes\";\nexports.SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\n\nfunction disableSticky() {\n  exports.SUPPORT_STICKY = false;\n}\n\nexports.disableSticky = disableSticky;\n\nfunction enableSticky() {\n  exports.SUPPORT_STICKY = true;\n}\n\nexports.enableSticky = enableSticky;\n\nfunction analyzeTokenTypes(tokenTypes, options) {\n  options = (0, defaults_1.default)(options, {\n    useSticky: exports.SUPPORT_STICKY,\n    debug: false,\n    safeMode: false,\n    positionTracking: \"full\",\n    lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n    tracer: (msg, action) => action()\n  });\n  const tracer = options.tracer;\n  tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n    initCharCodeToOptimizedIndexMap();\n  });\n  let onlyRelevantTypes;\n  tracer(\"Reject Lexer.NA\", () => {\n    onlyRelevantTypes = (0, reject_1.default)(tokenTypes, currType => {\n      return currType[PATTERN] === lexer_public_1.Lexer.NA;\n    });\n  });\n  let hasCustom = false;\n  let allTransformedPatterns;\n  tracer(\"Transform Patterns\", () => {\n    hasCustom = false;\n    allTransformedPatterns = (0, map_1.default)(onlyRelevantTypes, currType => {\n      const currPattern = currType[PATTERN];\n      /* istanbul ignore else */\n\n      if ((0, isRegExp_1.default)(currPattern)) {\n        const regExpSource = currPattern.source;\n\n        if (regExpSource.length === 1 && // only these regExp meta characters which can appear in a length one regExp\n        regExpSource !== \"^\" && regExpSource !== \"$\" && regExpSource !== \".\" && !currPattern.ignoreCase) {\n          return regExpSource;\n        } else if (regExpSource.length === 2 && regExpSource[0] === \"\\\\\" && // not a meta character\n        !(0, includes_1.default)([\"d\", \"D\", \"s\", \"S\", \"t\", \"r\", \"n\", \"t\", \"0\", \"c\", \"b\", \"B\", \"f\", \"v\", \"w\", \"W\"], regExpSource[1])) {\n          // escaped meta Characters: /\\+/ /\\[/\n          // or redundant escaping: /\\a/\n          // without the escaping \"\\\"\n          return regExpSource[1];\n        } else {\n          return options.useSticky ? addStickyFlag(currPattern) : addStartOfInput(currPattern);\n        }\n      } else if ((0, isFunction_1.default)(currPattern)) {\n        hasCustom = true; // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n\n        return {\n          exec: currPattern\n        };\n      } else if (typeof currPattern === \"object\") {\n        hasCustom = true; // ICustomPattern\n\n        return currPattern;\n      } else if (typeof currPattern === \"string\") {\n        if (currPattern.length === 1) {\n          return currPattern;\n        } else {\n          const escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n          const wrappedRegExp = new RegExp(escapedRegExpString);\n          return options.useSticky ? addStickyFlag(wrappedRegExp) : addStartOfInput(wrappedRegExp);\n        }\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n  });\n  let patternIdxToType;\n  let patternIdxToGroup;\n  let patternIdxToLongerAltIdxArr;\n  let patternIdxToPushMode;\n  let patternIdxToPopMode;\n  tracer(\"misc mapping\", () => {\n    patternIdxToType = (0, map_1.default)(onlyRelevantTypes, currType => currType.tokenTypeIdx);\n    patternIdxToGroup = (0, map_1.default)(onlyRelevantTypes, clazz => {\n      const groupName = clazz.GROUP;\n      /* istanbul ignore next */\n\n      if (groupName === lexer_public_1.Lexer.SKIPPED) {\n        return undefined;\n      } else if ((0, isString_1.default)(groupName)) {\n        return groupName;\n      } else if ((0, isUndefined_1.default)(groupName)) {\n        return false;\n      } else {\n        throw Error(\"non exhaustive match\");\n      }\n    });\n    patternIdxToLongerAltIdxArr = (0, map_1.default)(onlyRelevantTypes, clazz => {\n      const longerAltType = clazz.LONGER_ALT;\n\n      if (longerAltType) {\n        const longerAltIdxArr = (0, isArray_1.default)(longerAltType) ? (0, map_1.default)(longerAltType, type => (0, indexOf_1.default)(onlyRelevantTypes, type)) : [(0, indexOf_1.default)(onlyRelevantTypes, longerAltType)];\n        return longerAltIdxArr;\n      }\n    });\n    patternIdxToPushMode = (0, map_1.default)(onlyRelevantTypes, clazz => clazz.PUSH_MODE);\n    patternIdxToPopMode = (0, map_1.default)(onlyRelevantTypes, clazz => (0, has_1.default)(clazz, \"POP_MODE\"));\n  });\n  let patternIdxToCanLineTerminator;\n  tracer(\"Line Terminator Handling\", () => {\n    const lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n    patternIdxToCanLineTerminator = (0, map_1.default)(onlyRelevantTypes, tokType => false);\n\n    if (options.positionTracking !== \"onlyOffset\") {\n      patternIdxToCanLineTerminator = (0, map_1.default)(onlyRelevantTypes, tokType => {\n        if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n          return !!tokType.LINE_BREAKS;\n        } else {\n          return checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false && (0, reg_exp_1.canMatchCharCode)(lineTerminatorCharCodes, tokType.PATTERN);\n        }\n      });\n    }\n  });\n  let patternIdxToIsCustom;\n  let patternIdxToShort;\n  let emptyGroups;\n  let patternIdxToConfig;\n  tracer(\"Misc Mapping #2\", () => {\n    patternIdxToIsCustom = (0, map_1.default)(onlyRelevantTypes, isCustomPattern);\n    patternIdxToShort = (0, map_1.default)(allTransformedPatterns, isShortPattern);\n    emptyGroups = (0, reduce_1.default)(onlyRelevantTypes, (acc, clazz) => {\n      const groupName = clazz.GROUP;\n\n      if ((0, isString_1.default)(groupName) && !(groupName === lexer_public_1.Lexer.SKIPPED)) {\n        acc[groupName] = [];\n      }\n\n      return acc;\n    }, {});\n    patternIdxToConfig = (0, map_1.default)(allTransformedPatterns, (x, idx) => {\n      return {\n        pattern: allTransformedPatterns[idx],\n        longerAlt: patternIdxToLongerAltIdxArr[idx],\n        canLineTerminator: patternIdxToCanLineTerminator[idx],\n        isCustom: patternIdxToIsCustom[idx],\n        short: patternIdxToShort[idx],\n        group: patternIdxToGroup[idx],\n        push: patternIdxToPushMode[idx],\n        pop: patternIdxToPopMode[idx],\n        tokenTypeIdx: patternIdxToType[idx],\n        tokenType: onlyRelevantTypes[idx]\n      };\n    });\n  });\n  let canBeOptimized = true;\n  let charCodeToPatternIdxToConfig = [];\n\n  if (!options.safeMode) {\n    tracer(\"First Char Optimization\", () => {\n      charCodeToPatternIdxToConfig = (0, reduce_1.default)(onlyRelevantTypes, (result, currTokType, idx) => {\n        if (typeof currTokType.PATTERN === \"string\") {\n          const charCode = currTokType.PATTERN.charCodeAt(0);\n          const optimizedIdx = charCodeToOptimizedIndex(charCode);\n          addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n        } else if ((0, isArray_1.default)(currTokType.START_CHARS_HINT)) {\n          let lastOptimizedIdx;\n          (0, forEach_1.default)(currTokType.START_CHARS_HINT, charOrInt => {\n            const charCode = typeof charOrInt === \"string\" ? charOrInt.charCodeAt(0) : charOrInt;\n            const currOptimizedIdx = charCodeToOptimizedIndex(charCode); // Avoid adding the config multiple times\n\n            /* istanbul ignore else */\n            // - Difficult to check this scenario effects as it is only a performance\n            //   optimization that does not change correctness\n\n            if (lastOptimizedIdx !== currOptimizedIdx) {\n              lastOptimizedIdx = currOptimizedIdx;\n              addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n            }\n          });\n        } else if ((0, isRegExp_1.default)(currTokType.PATTERN)) {\n          if (currTokType.PATTERN.unicode) {\n            canBeOptimized = false;\n\n            if (options.ensureOptimizations) {\n              (0, utils_1.PRINT_ERROR)(`${reg_exp_1.failedOptimizationPrefixMsg}` + `\\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\\n` + \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n            }\n          } else {\n            const optimizedCodes = (0, reg_exp_1.getOptimizedStartCodesIndices)(currTokType.PATTERN, options.ensureOptimizations);\n            /* istanbul ignore if */\n            // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n            // the first should be a different validation and the second cannot be tested.\n\n            if ((0, isEmpty_1.default)(optimizedCodes)) {\n              // we cannot understand what codes may start possible matches\n              // The optimization correctness requires knowing start codes for ALL patterns.\n              // Not actually sure this is an error, no debug message\n              canBeOptimized = false;\n            }\n\n            (0, forEach_1.default)(optimizedCodes, code => {\n              addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n            });\n          }\n        } else {\n          if (options.ensureOptimizations) {\n            (0, utils_1.PRINT_ERROR)(`${reg_exp_1.failedOptimizationPrefixMsg}` + `\\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\\n` + \"\\tThis will disable the lexer's first char optimizations.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n          }\n\n          canBeOptimized = false;\n        }\n\n        return result;\n      }, []);\n    });\n  }\n\n  return {\n    emptyGroups: emptyGroups,\n    patternIdxToConfig: patternIdxToConfig,\n    charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n    hasCustom: hasCustom,\n    canBeOptimized: canBeOptimized\n  };\n}\n\nexports.analyzeTokenTypes = analyzeTokenTypes;\n\nfunction validatePatterns(tokenTypes, validModesNames) {\n  let errors = [];\n  const missingResult = findMissingPatterns(tokenTypes);\n  errors = errors.concat(missingResult.errors);\n  const invalidResult = findInvalidPatterns(missingResult.valid);\n  const validTokenTypes = invalidResult.valid;\n  errors = errors.concat(invalidResult.errors);\n  errors = errors.concat(validateRegExpPattern(validTokenTypes));\n  errors = errors.concat(findInvalidGroupType(validTokenTypes));\n  errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n  errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n  return errors;\n}\n\nexports.validatePatterns = validatePatterns;\n\nfunction validateRegExpPattern(tokenTypes) {\n  let errors = [];\n  const withRegExpPatterns = (0, filter_1.default)(tokenTypes, currTokType => (0, isRegExp_1.default)(currTokType[PATTERN]));\n  errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n  errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n  errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n  errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n  return errors;\n}\n\nfunction findMissingPatterns(tokenTypes) {\n  const tokenTypesWithMissingPattern = (0, filter_1.default)(tokenTypes, currType => {\n    return !(0, has_1.default)(currType, PATTERN);\n  });\n  const errors = (0, map_1.default)(tokenTypesWithMissingPattern, currType => {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- missing static 'PATTERN' property\",\n      type: lexer_public_1.LexerDefinitionErrorType.MISSING_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  const valid = (0, difference_1.default)(tokenTypes, tokenTypesWithMissingPattern);\n  return {\n    errors,\n    valid\n  };\n}\n\nexports.findMissingPatterns = findMissingPatterns;\n\nfunction findInvalidPatterns(tokenTypes) {\n  const tokenTypesWithInvalidPattern = (0, filter_1.default)(tokenTypes, currType => {\n    const pattern = currType[PATTERN];\n    return !(0, isRegExp_1.default)(pattern) && !(0, isFunction_1.default)(pattern) && !(0, has_1.default)(pattern, \"exec\") && !(0, isString_1.default)(pattern);\n  });\n  const errors = (0, map_1.default)(tokenTypesWithInvalidPattern, currType => {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' can only be a RegExp, a\" + \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n      type: lexer_public_1.LexerDefinitionErrorType.INVALID_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  const valid = (0, difference_1.default)(tokenTypes, tokenTypesWithInvalidPattern);\n  return {\n    errors,\n    valid\n  };\n}\n\nexports.findInvalidPatterns = findInvalidPatterns;\nconst end_of_input = /[^\\\\][$]/;\n\nfunction findEndOfInputAnchor(tokenTypes) {\n  class EndAnchorFinder extends regexp_to_ast_1.BaseRegExpVisitor {\n    constructor() {\n      super(...arguments);\n      this.found = false;\n    }\n\n    visitEndAnchor(node) {\n      this.found = true;\n    }\n\n  }\n\n  const invalidRegex = (0, filter_1.default)(tokenTypes, currType => {\n    const pattern = currType.PATTERN;\n\n    try {\n      const regexpAst = (0, reg_exp_parser_1.getRegExpAst)(pattern);\n      const endAnchorVisitor = new EndAnchorFinder();\n      endAnchorVisitor.visit(regexpAst);\n      return endAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return end_of_input.test(pattern.source);\n    }\n  });\n  const errors = (0, map_1.default)(invalidRegex, currType => {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" + \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n\nexports.findEndOfInputAnchor = findEndOfInputAnchor;\n\nfunction findEmptyMatchRegExps(tokenTypes) {\n  const matchesEmptyString = (0, filter_1.default)(tokenTypes, currType => {\n    const pattern = currType.PATTERN;\n    return pattern.test(\"\");\n  });\n  const errors = (0, map_1.default)(matchesEmptyString, currType => {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' must not match an empty string\",\n      type: lexer_public_1.LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n\nexports.findEmptyMatchRegExps = findEmptyMatchRegExps;\nconst start_of_input = /[^\\\\[][\\^]|^\\^/;\n\nfunction findStartOfInputAnchor(tokenTypes) {\n  class StartAnchorFinder extends regexp_to_ast_1.BaseRegExpVisitor {\n    constructor() {\n      super(...arguments);\n      this.found = false;\n    }\n\n    visitStartAnchor(node) {\n      this.found = true;\n    }\n\n  }\n\n  const invalidRegex = (0, filter_1.default)(tokenTypes, currType => {\n    const pattern = currType.PATTERN;\n\n    try {\n      const regexpAst = (0, reg_exp_parser_1.getRegExpAst)(pattern);\n      const startAnchorVisitor = new StartAnchorFinder();\n      startAnchorVisitor.visit(regexpAst);\n      return startAnchorVisitor.found;\n    } catch (e) {\n      // old behavior in case of runtime exceptions with regexp-to-ast.\n\n      /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n      return start_of_input.test(pattern.source);\n    }\n  });\n  const errors = (0, map_1.default)(invalidRegex, currType => {\n    return {\n      message: \"Unexpected RegExp Anchor Error:\\n\" + \"\\tToken Type: ->\" + currType.name + \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" + \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n\nexports.findStartOfInputAnchor = findStartOfInputAnchor;\n\nfunction findUnsupportedFlags(tokenTypes) {\n  const invalidFlags = (0, filter_1.default)(tokenTypes, currType => {\n    const pattern = currType[PATTERN];\n    return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n  });\n  const errors = (0, map_1.default)(invalidFlags, currType => {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n      type: lexer_public_1.LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n\nexports.findUnsupportedFlags = findUnsupportedFlags; // This can only test for identical duplicate RegExps, not semantically equivalent ones.\n\nfunction findDuplicatePatterns(tokenTypes) {\n  const found = [];\n  let identicalPatterns = (0, map_1.default)(tokenTypes, outerType => {\n    return (0, reduce_1.default)(tokenTypes, (result, innerType) => {\n      if (outerType.PATTERN.source === innerType.PATTERN.source && !(0, includes_1.default)(found, innerType) && innerType.PATTERN !== lexer_public_1.Lexer.NA) {\n        // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n        // in essence we are creating Equivalence classes on equality relation.\n        found.push(innerType);\n        result.push(innerType);\n        return result;\n      }\n\n      return result;\n    }, []);\n  });\n  identicalPatterns = (0, compact_1.default)(identicalPatterns);\n  const duplicatePatterns = (0, filter_1.default)(identicalPatterns, currIdenticalSet => {\n    return currIdenticalSet.length > 1;\n  });\n  const errors = (0, map_1.default)(duplicatePatterns, setOfIdentical => {\n    const tokenTypeNames = (0, map_1.default)(setOfIdentical, currType => {\n      return currType.name;\n    });\n    const dupPatternSrc = (0, first_1.default)(setOfIdentical).PATTERN;\n    return {\n      message: `The same RegExp pattern ->${dupPatternSrc}<-` + `has been used in all of the following Token Types: ${tokenTypeNames.join(\", \")} <-`,\n      type: lexer_public_1.LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n      tokenTypes: setOfIdentical\n    };\n  });\n  return errors;\n}\n\nexports.findDuplicatePatterns = findDuplicatePatterns;\n\nfunction findInvalidGroupType(tokenTypes) {\n  const invalidTypes = (0, filter_1.default)(tokenTypes, clazz => {\n    if (!(0, has_1.default)(clazz, \"GROUP\")) {\n      return false;\n    }\n\n    const group = clazz.GROUP;\n    return group !== lexer_public_1.Lexer.SKIPPED && group !== lexer_public_1.Lexer.NA && !(0, isString_1.default)(group);\n  });\n  const errors = (0, map_1.default)(invalidTypes, currType => {\n    return {\n      message: \"Token Type: ->\" + currType.name + \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n      type: lexer_public_1.LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n      tokenTypes: [currType]\n    };\n  });\n  return errors;\n}\n\nexports.findInvalidGroupType = findInvalidGroupType;\n\nfunction findModesThatDoNotExist(tokenTypes, validModes) {\n  const invalidModes = (0, filter_1.default)(tokenTypes, clazz => {\n    return clazz.PUSH_MODE !== undefined && !(0, includes_1.default)(validModes, clazz.PUSH_MODE);\n  });\n  const errors = (0, map_1.default)(invalidModes, tokType => {\n    const msg = `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-` + `which does not exist`;\n    return {\n      message: msg,\n      type: lexer_public_1.LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n      tokenTypes: [tokType]\n    };\n  });\n  return errors;\n}\n\nexports.findModesThatDoNotExist = findModesThatDoNotExist;\n\nfunction findUnreachablePatterns(tokenTypes) {\n  const errors = [];\n  const canBeTested = (0, reduce_1.default)(tokenTypes, (result, tokType, idx) => {\n    const pattern = tokType.PATTERN;\n\n    if (pattern === lexer_public_1.Lexer.NA) {\n      return result;\n    } // a more comprehensive validation for all forms of regExps would require\n    // deeper regExp analysis capabilities\n\n\n    if ((0, isString_1.default)(pattern)) {\n      result.push({\n        str: pattern,\n        idx,\n        tokenType: tokType\n      });\n    } else if ((0, isRegExp_1.default)(pattern) && noMetaChar(pattern)) {\n      result.push({\n        str: pattern.source,\n        idx,\n        tokenType: tokType\n      });\n    }\n\n    return result;\n  }, []);\n  (0, forEach_1.default)(tokenTypes, (tokType, testIdx) => {\n    (0, forEach_1.default)(canBeTested, ({\n      str,\n      idx,\n      tokenType\n    }) => {\n      if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n        const msg = `Token: ->${tokenType.name}<- can never be matched.\\n` + `Because it appears AFTER the Token Type ->${tokType.name}<-` + `in the lexer's definition.\\n` + `See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`;\n        errors.push({\n          message: msg,\n          type: lexer_public_1.LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n          tokenTypes: [tokType, tokenType]\n        });\n      }\n    });\n  });\n  return errors;\n}\n\nexports.findUnreachablePatterns = findUnreachablePatterns;\n\nfunction testTokenType(str, pattern) {\n  /* istanbul ignore else */\n  if ((0, isRegExp_1.default)(pattern)) {\n    const regExpArray = pattern.exec(str);\n    return regExpArray !== null && regExpArray.index === 0;\n  } else if ((0, isFunction_1.default)(pattern)) {\n    // maintain the API of custom patterns\n    return pattern(str, 0, [], {});\n  } else if ((0, has_1.default)(pattern, \"exec\")) {\n    // maintain the API of custom patterns\n    return pattern.exec(str, 0, [], {});\n  } else if (typeof pattern === \"string\") {\n    return pattern === str;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nfunction noMetaChar(regExp) {\n  //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n  const metaChars = [\".\", \"\\\\\", \"[\", \"]\", \"|\", \"^\", \"$\", \"(\", \")\", \"?\", \"*\", \"+\", \"{\"];\n  return (0, find_1.default)(metaChars, char => regExp.source.indexOf(char) !== -1) === undefined;\n}\n\nfunction addStartOfInput(pattern) {\n  const flags = pattern.ignoreCase ? \"i\" : \"\"; // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n\n  return new RegExp(`^(?:${pattern.source})`, flags);\n}\n\nexports.addStartOfInput = addStartOfInput;\n\nfunction addStickyFlag(pattern) {\n  const flags = pattern.ignoreCase ? \"iy\" : \"y\"; // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n  // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n\n  return new RegExp(`${pattern.source}`, flags);\n}\n\nexports.addStickyFlag = addStickyFlag;\n\nfunction performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  const errors = []; // some run time checks to help the end users.\n\n  if (!(0, has_1.default)(lexerDefinition, exports.DEFAULT_MODE)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + exports.DEFAULT_MODE + \"> property in its definition\\n\",\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n    });\n  }\n\n  if (!(0, has_1.default)(lexerDefinition, exports.MODES)) {\n    errors.push({\n      message: \"A MultiMode Lexer cannot be initialized without a <\" + exports.MODES + \"> property in its definition\\n\",\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n    });\n  }\n\n  if ((0, has_1.default)(lexerDefinition, exports.MODES) && (0, has_1.default)(lexerDefinition, exports.DEFAULT_MODE) && !(0, has_1.default)(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n    errors.push({\n      message: `A MultiMode Lexer cannot be initialized with a ${exports.DEFAULT_MODE}: <${lexerDefinition.defaultMode}>` + `which does not exist\\n`,\n      type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n    });\n  }\n\n  if ((0, has_1.default)(lexerDefinition, exports.MODES)) {\n    (0, forEach_1.default)(lexerDefinition.modes, (currModeValue, currModeName) => {\n      (0, forEach_1.default)(currModeValue, (currTokType, currIdx) => {\n        if ((0, isUndefined_1.default)(currTokType)) {\n          errors.push({\n            message: `A Lexer cannot be initialized using an undefined Token Type. Mode:` + `<${currModeName}> at index: <${currIdx}>\\n`,\n            type: lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n          });\n        } else if ((0, has_1.default)(currTokType, \"LONGER_ALT\")) {\n          const longerAlt = (0, isArray_1.default)(currTokType.LONGER_ALT) ? currTokType.LONGER_ALT : [currTokType.LONGER_ALT];\n          (0, forEach_1.default)(longerAlt, currLongerAlt => {\n            if (!(0, isUndefined_1.default)(currLongerAlt) && !(0, includes_1.default)(currModeValue, currLongerAlt)) {\n              errors.push({\n                message: `A MultiMode Lexer cannot be initialized with a longer_alt <${currLongerAlt.name}> on token <${currTokType.name}> outside of mode <${currModeName}>\\n`,\n                type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\n              });\n            }\n          });\n        }\n      });\n    });\n  }\n\n  return errors;\n}\n\nexports.performRuntimeChecks = performRuntimeChecks;\n\nfunction performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n  const warnings = [];\n  let hasAnyLineBreak = false;\n  const allTokenTypes = (0, compact_1.default)((0, flatten_1.default)((0, values_1.default)(lexerDefinition.modes)));\n  const concreteTokenTypes = (0, reject_1.default)(allTokenTypes, currType => currType[PATTERN] === lexer_public_1.Lexer.NA);\n  const terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n\n  if (trackLines) {\n    (0, forEach_1.default)(concreteTokenTypes, tokType => {\n      const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n\n      if (currIssue !== false) {\n        const message = buildLineBreakIssueMessage(tokType, currIssue);\n        const warningDescriptor = {\n          message,\n          type: currIssue.issue,\n          tokenType: tokType\n        };\n        warnings.push(warningDescriptor);\n      } else {\n        // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n        if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n          if (tokType.LINE_BREAKS === true) {\n            hasAnyLineBreak = true;\n          }\n        } else {\n          if ((0, reg_exp_1.canMatchCharCode)(terminatorCharCodes, tokType.PATTERN)) {\n            hasAnyLineBreak = true;\n          }\n        }\n      }\n    });\n  }\n\n  if (trackLines && !hasAnyLineBreak) {\n    warnings.push({\n      message: \"Warning: No LINE_BREAKS Found.\\n\" + \"\\tThis Lexer has been defined to track line and column information,\\n\" + \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" + \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" + \"\\tfor details.\",\n      type: lexer_public_1.LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n    });\n  }\n\n  return warnings;\n}\n\nexports.performWarningRuntimeChecks = performWarningRuntimeChecks;\n\nfunction cloneEmptyGroups(emptyGroups) {\n  const clonedResult = {};\n  const groupKeys = (0, keys_1.default)(emptyGroups);\n  (0, forEach_1.default)(groupKeys, currKey => {\n    const currGroupValue = emptyGroups[currKey];\n    /* istanbul ignore else */\n\n    if ((0, isArray_1.default)(currGroupValue)) {\n      clonedResult[currKey] = [];\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  });\n  return clonedResult;\n}\n\nexports.cloneEmptyGroups = cloneEmptyGroups; // TODO: refactor to avoid duplication\n\nfunction isCustomPattern(tokenType) {\n  const pattern = tokenType.PATTERN;\n  /* istanbul ignore else */\n\n  if ((0, isRegExp_1.default)(pattern)) {\n    return false;\n  } else if ((0, isFunction_1.default)(pattern)) {\n    // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n    return true;\n  } else if ((0, has_1.default)(pattern, \"exec\")) {\n    // ICustomPattern\n    return true;\n  } else if ((0, isString_1.default)(pattern)) {\n    return false;\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexports.isCustomPattern = isCustomPattern;\n\nfunction isShortPattern(pattern) {\n  if ((0, isString_1.default)(pattern) && pattern.length === 1) {\n    return pattern.charCodeAt(0);\n  } else {\n    return false;\n  }\n}\n\nexports.isShortPattern = isShortPattern;\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\n\nexports.LineTerminatorOptimizedTester = {\n  // implements /\\n|\\r\\n?/g.test\n  test: function (text) {\n    const len = text.length;\n\n    for (let i = this.lastIndex; i < len; i++) {\n      const c = text.charCodeAt(i);\n\n      if (c === 10) {\n        this.lastIndex = i + 1;\n        return true;\n      } else if (c === 13) {\n        if (text.charCodeAt(i + 1) === 10) {\n          this.lastIndex = i + 2;\n        } else {\n          this.lastIndex = i + 1;\n        }\n\n        return true;\n      }\n    }\n\n    return false;\n  },\n  lastIndex: 0\n};\n\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n  if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n    // if the user explicitly declared the line_breaks option we will respect their choice\n    // and assume it is correct.\n    return false;\n  } else {\n    /* istanbul ignore else */\n    if ((0, isRegExp_1.default)(tokType.PATTERN)) {\n      try {\n        // TODO: why is the casting suddenly needed?\n        (0, reg_exp_1.canMatchCharCode)(lineTerminatorCharCodes, tokType.PATTERN);\n      } catch (e) {\n        /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n        return {\n          issue: lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n          errMsg: e.message\n        };\n      }\n\n      return false;\n    } else if ((0, isString_1.default)(tokType.PATTERN)) {\n      // string literal patterns can always be analyzed to detect line terminator usage\n      return false;\n    } else if (isCustomPattern(tokType)) {\n      // custom token types\n      return {\n        issue: lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK\n      };\n    } else {\n      throw Error(\"non exhaustive match\");\n    }\n  }\n}\n\nfunction buildLineBreakIssueMessage(tokType, details) {\n  /* istanbul ignore else */\n  if (details.issue === lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n    return \"Warning: unable to identify line terminator usage in pattern.\\n\" + `\\tThe problem is in the <${tokType.name}> Token Type\\n` + `\\t Root cause: ${details.errMsg}.\\n` + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\";\n  } else if (details.issue === lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n    return \"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" + `\\tThe problem is in the <${tokType.name}> Token Type\\n` + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\";\n  } else {\n    throw Error(\"non exhaustive match\");\n  }\n}\n\nexports.buildLineBreakIssueMessage = buildLineBreakIssueMessage;\n\nfunction getCharCodes(charsOrCodes) {\n  const charCodes = (0, map_1.default)(charsOrCodes, numOrString => {\n    if ((0, isString_1.default)(numOrString)) {\n      return numOrString.charCodeAt(0);\n    } else {\n      return numOrString;\n    }\n  });\n  return charCodes;\n}\n\nfunction addToMapOfArrays(map, key, value) {\n  if (map[key] === undefined) {\n    map[key] = [value];\n  } else {\n    map[key].push(value);\n  }\n}\n\nexports.minOptimizationVal = 256;\n/**\n * We are mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\n\nlet charCodeToOptimizedIdxMap = [];\n\nfunction charCodeToOptimizedIndex(charCode) {\n  return charCode < exports.minOptimizationVal ? charCode : charCodeToOptimizedIdxMap[charCode];\n}\n\nexports.charCodeToOptimizedIndex = charCodeToOptimizedIndex;\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\n\nfunction initCharCodeToOptimizedIndexMap() {\n  if ((0, isEmpty_1.default)(charCodeToOptimizedIdxMap)) {\n    charCodeToOptimizedIdxMap = new Array(65536);\n\n    for (let i = 0; i < 65536; i++) {\n      charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n    }\n  }\n}","map":{"version":3,"sources":["../../../src/scan/lexer.ts"],"names":[],"mappings":";;;;;;;;;;;;;AAAA,MAAA,eAAA,GAAA,OAAA,CAAA,eAAA,CAAA;;AACA,MAAA,cAAA,GAAA,OAAA,CAAA,gBAAA,CAAA;;AACA,MAAA,OAAA,GAAA,eAAA,CAAA,OAAA,CAAA,cAAA,CAAA,CAAA;;AACA,MAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,MAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,MAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,MAAA,QAAA,GAAA,eAAA,CAAA,OAAA,CAAA,eAAA,CAAA,CAAA;;AACA,MAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,MAAA,QAAA,GAAA,eAAA,CAAA,OAAA,CAAA,eAAA,CAAA,CAAA;;AACA,MAAA,YAAA,GAAA,eAAA,CAAA,OAAA,CAAA,mBAAA,CAAA,CAAA;;AACA,MAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,MAAA,KAAA,GAAA,eAAA,CAAA,OAAA,CAAA,YAAA,CAAA,CAAA;;AACA,MAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,MAAA,UAAA,GAAA,eAAA,CAAA,OAAA,CAAA,iBAAA,CAAA,CAAA;;AACA,MAAA,YAAA,GAAA,eAAA,CAAA,OAAA,CAAA,mBAAA,CAAA,CAAA;;AACA,MAAA,aAAA,GAAA,eAAA,CAAA,OAAA,CAAA,oBAAA,CAAA,CAAA;;AACA,MAAA,MAAA,GAAA,eAAA,CAAA,OAAA,CAAA,aAAA,CAAA,CAAA;;AACA,MAAA,KAAA,GAAA,eAAA,CAAA,OAAA,CAAA,YAAA,CAAA,CAAA;;AACA,MAAA,MAAA,GAAA,eAAA,CAAA,OAAA,CAAA,aAAA,CAAA,CAAA;;AACA,MAAA,UAAA,GAAA,eAAA,CAAA,OAAA,CAAA,iBAAA,CAAA,CAAA;;AACA,MAAA,QAAA,GAAA,eAAA,CAAA,OAAA,CAAA,eAAA,CAAA,CAAA;;AACA,MAAA,UAAA,GAAA,eAAA,CAAA,OAAA,CAAA,iBAAA,CAAA,CAAA;;AACA,MAAA,QAAA,GAAA,eAAA,CAAA,OAAA,CAAA,eAAA,CAAA,CAAA;;AACA,MAAA,UAAA,GAAA,eAAA,CAAA,OAAA,CAAA,iBAAA,CAAA,CAAA;;AACA,MAAA,OAAA,GAAA,OAAA,CAAA,mBAAA,CAAA;;AACA,MAAA,SAAA,GAAA,OAAA,CAAA,WAAA,CAAA;;AAYA,MAAA,gBAAA,GAAA,OAAA,CAAA,kBAAA,CAAA;;AAEA,MAAM,OAAO,GAAG,SAAhB;AACa,OAAA,CAAA,YAAA,GAAe,aAAf;AACA,OAAA,CAAA,KAAA,GAAQ,OAAR;AAuBF,OAAA,CAAA,cAAA,GACT,OAAa,IAAI,MAAJ,CAAW,MAAX,EAAoB,MAAjC,KAA4C,SADnC;;AAGX,SAAgB,aAAhB,GAA6B;AAC3B,EAAA,OAAA,CAAA,cAAA,GAAiB,KAAjB;AACD;;AAFD,OAAA,CAAA,aAAA,GAAA,aAAA;;AAIA,SAAgB,YAAhB,GAA4B;AAC1B,EAAA,OAAA,CAAA,cAAA,GAAiB,IAAjB;AACD;;AAFD,OAAA,CAAA,YAAA,GAAA,YAAA;;AAIA,SAAgB,iBAAhB,CACE,UADF,EAEE,OAFF,EAUG;AAED,EAAA,OAAO,GAAG,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAT,EAAkB;AAC1B,IAAA,SAAS,EAAE,OAAA,CAAA,cADe;AAE1B,IAAA,KAAK,EAAE,KAFmB;AAG1B,IAAA,QAAQ,EAAE,KAHgB;AAI1B,IAAA,gBAAgB,EAAE,MAJQ;AAK1B,IAAA,wBAAwB,EAAE,CAAC,IAAD,EAAO,IAAP,CALA;AAM1B,IAAA,MAAM,EAAE,CAAC,GAAD,EAAc,MAAd,KAAmC,MAAM;AANvB,GAAlB,CAAV;AASA,QAAM,MAAM,GAAG,OAAO,CAAC,MAAvB;AAEA,EAAA,MAAM,CAAC,iCAAD,EAAoC,MAAK;AAC7C,IAAA,+BAA+B;AAChC,GAFK,CAAN;AAIA,MAAI,iBAAJ;AACA,EAAA,MAAM,CAAC,iBAAD,EAAoB,MAAK;AAC7B,IAAA,iBAAiB,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,UAAP,EAAoB,QAAD,IAAa;AAClD,aAAO,QAAQ,CAAC,OAAD,CAAR,KAAsB,cAAA,CAAA,KAAA,CAAM,EAAnC;AACD,KAFmB,CAApB;AAGD,GAJK,CAAN;AAMA,MAAI,SAAS,GAAG,KAAhB;AACA,MAAI,sBAAJ;AACA,EAAA,MAAM,CAAC,oBAAD,EAAuB,MAAK;AAChC,IAAA,SAAS,GAAG,KAAZ;AACA,IAAA,sBAAsB,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EACvB,iBADuB,EAEtB,QAAD,IAAmC;AACjC,YAAM,WAAW,GAAG,QAAQ,CAAC,OAAD,CAA5B;AAEA;;AACA,UAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,WAAT,CAAJ,EAA2B;AACzB,cAAM,YAAY,GAAG,WAAW,CAAC,MAAjC;;AACA,YACE,YAAY,CAAC,MAAb,KAAwB,CAAxB,IACA;AACA,QAAA,YAAY,KAAK,GAFjB,IAGA,YAAY,KAAK,GAHjB,IAIA,YAAY,KAAK,GAJjB,IAKA,CAAC,WAAW,CAAC,UANf,EAOE;AACA,iBAAO,YAAP;AACD,SATD,MASO,IACL,YAAY,CAAC,MAAb,KAAwB,CAAxB,IACA,YAAY,CAAC,CAAD,CAAZ,KAAoB,IADpB,IAEA;AACA,SAAC,CAAA,GAAA,UAAA,CAAA,OAAA,EACC,CACE,GADF,EAEE,GAFF,EAGE,GAHF,EAIE,GAJF,EAKE,GALF,EAME,GANF,EAOE,GAPF,EAQE,GARF,EASE,GATF,EAUE,GAVF,EAWE,GAXF,EAYE,GAZF,EAaE,GAbF,EAcE,GAdF,EAeE,GAfF,EAgBE,GAhBF,CADD,EAmBC,YAAY,CAAC,CAAD,CAnBb,CAJI,EAyBL;AACA;AACA;AACA;AACA,iBAAO,YAAY,CAAC,CAAD,CAAnB;AACD,SA9BM,MA8BA;AACL,iBAAO,OAAO,CAAC,SAAR,GACH,aAAa,CAAC,WAAD,CADV,GAEH,eAAe,CAAC,WAAD,CAFnB;AAGD;AACF,OA9CD,MA8CO,IAAI,CAAA,GAAA,YAAA,CAAA,OAAA,EAAW,WAAX,CAAJ,EAA6B;AAClC,QAAA,SAAS,GAAG,IAAZ,CADkC,CAElC;;AACA,eAAO;AAAE,UAAA,IAAI,EAAE;AAAR,SAAP;AACD,OAJM,MAIA,IAAI,OAAO,WAAP,KAAuB,QAA3B,EAAqC;AAC1C,QAAA,SAAS,GAAG,IAAZ,CAD0C,CAE1C;;AACA,eAAO,WAAP;AACD,OAJM,MAIA,IAAI,OAAO,WAAP,KAAuB,QAA3B,EAAqC;AAC1C,YAAI,WAAW,CAAC,MAAZ,KAAuB,CAA3B,EAA8B;AAC5B,iBAAO,WAAP;AACD,SAFD,MAEO;AACL,gBAAM,mBAAmB,GAAG,WAAW,CAAC,OAAZ,CAC1B,qBAD0B,EAE1B,MAF0B,CAA5B;AAIA,gBAAM,aAAa,GAAG,IAAI,MAAJ,CAAW,mBAAX,CAAtB;AACA,iBAAO,OAAO,CAAC,SAAR,GACH,aAAa,CAAC,aAAD,CADV,GAEH,eAAe,CAAC,aAAD,CAFnB;AAGD;AACF,OAbM,MAaA;AACL,cAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF,KA5EsB,CAAzB;AA8ED,GAhFK,CAAN;AAkFA,MAAI,gBAAJ;AACA,MAAI,iBAAJ;AACA,MAAI,2BAAJ;AACA,MAAI,oBAAJ;AACA,MAAI,mBAAJ;AACA,EAAA,MAAM,CAAC,cAAD,EAAiB,MAAK;AAC1B,IAAA,gBAAgB,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EACjB,iBADiB,EAEhB,QAAD,IAAc,QAAQ,CAAC,YAFN,CAAnB;AAKA,IAAA,iBAAiB,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,iBAAJ,EAAwB,KAAD,IAAe;AACxD,YAAM,SAAS,GAAG,KAAK,CAAC,KAAxB;AACA;;AACA,UAAI,SAAS,KAAK,cAAA,CAAA,KAAA,CAAM,OAAxB,EAAiC;AAC/B,eAAO,SAAP;AACD,OAFD,MAEO,IAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,SAAT,CAAJ,EAAyB;AAC9B,eAAO,SAAP;AACD,OAFM,MAEA,IAAI,CAAA,GAAA,aAAA,CAAA,OAAA,EAAY,SAAZ,CAAJ,EAA4B;AACjC,eAAO,KAAP;AACD,OAFM,MAEA;AACL,cAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF,KAZmB,CAApB;AAcA,IAAA,2BAA2B,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,iBAAJ,EAAwB,KAAD,IAAe;AAClE,YAAM,aAAa,GAAG,KAAK,CAAC,UAA5B;;AAEA,UAAI,aAAJ,EAAmB;AACjB,cAAM,eAAe,GAAG,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,aAAR,IACpB,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,aAAJ,EAAoB,IAAD,IAAe,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,iBAAR,EAA2B,IAA3B,CAAlC,CADoB,GAEpB,CAAC,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,iBAAR,EAA2B,aAA3B,CAAD,CAFJ;AAGA,eAAO,eAAP;AACD;AACF,KAT6B,CAA9B;AAWA,IAAA,oBAAoB,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EACrB,iBADqB,EAEpB,KAAD,IAAgB,KAAK,CAAC,SAFD,CAAvB;AAKA,IAAA,mBAAmB,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,iBAAJ,EAAwB,KAAD,IAC3C,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,KAAJ,EAAW,UAAX,CADoB,CAAtB;AAGD,GAvCK,CAAN;AAyCA,MAAI,6BAAJ;AACA,EAAA,MAAM,CAAC,0BAAD,EAA6B,MAAK;AACtC,UAAM,uBAAuB,GAAG,YAAY,CAC1C,OAAO,CAAC,wBADkC,CAA5C;AAGA,IAAA,6BAA6B,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,iBAAJ,EAAwB,OAAD,IAAa,KAApC,CAAhC;;AACA,QAAI,OAAO,CAAC,gBAAR,KAA6B,YAAjC,EAA+C;AAC7C,MAAA,6BAA6B,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,iBAAJ,EAAwB,OAAD,IAAY;AACjE,YAAI,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,OAAJ,EAAa,aAAb,CAAJ,EAAiC;AAC/B,iBAAO,CAAC,CAAC,OAAO,CAAC,WAAjB;AACD,SAFD,MAEO;AACL,iBACE,qBAAqB,CAAC,OAAD,EAAU,uBAAV,CAArB,KAA4D,KAA5D,IACA,CAAA,GAAA,SAAA,CAAA,gBAAA,EACE,uBADF,EAEE,OAAO,CAAC,OAFV,CAFF;AAOD;AACF,OAZ+B,CAAhC;AAaD;AACF,GApBK,CAAN;AAsBA,MAAI,oBAAJ;AACA,MAAI,iBAAJ;AACA,MAAI,WAAJ;AACA,MAAI,kBAAJ;AACA,EAAA,MAAM,CAAC,iBAAD,EAAoB,MAAK;AAC7B,IAAA,oBAAoB,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,iBAAJ,EAAuB,eAAvB,CAAvB;AACA,IAAA,iBAAiB,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,sBAAJ,EAA4B,cAA5B,CAApB;AAEA,IAAA,WAAW,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EACZ,iBADY,EAEZ,CAAC,GAAD,EAAM,KAAN,KAAoB;AAClB,YAAM,SAAS,GAAG,KAAK,CAAC,KAAxB;;AACA,UAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,SAAT,KAAuB,EAAE,SAAS,KAAK,cAAA,CAAA,KAAA,CAAM,OAAtB,CAA3B,EAA2D;AACzD,QAAA,GAAG,CAAC,SAAD,CAAH,GAAiB,EAAjB;AACD;;AACD,aAAO,GAAP;AACD,KARW,EASZ,EATY,CAAd;AAYA,IAAA,kBAAkB,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EACnB,sBADmB,EAEnB,CAAC,CAAD,EAAI,GAAJ,KAA2B;AACzB,aAAO;AACL,QAAA,OAAO,EAAE,sBAAsB,CAAC,GAAD,CAD1B;AAEL,QAAA,SAAS,EAAE,2BAA2B,CAAC,GAAD,CAFjC;AAGL,QAAA,iBAAiB,EAAE,6BAA6B,CAAC,GAAD,CAH3C;AAIL,QAAA,QAAQ,EAAE,oBAAoB,CAAC,GAAD,CAJzB;AAKL,QAAA,KAAK,EAAE,iBAAiB,CAAC,GAAD,CALnB;AAML,QAAA,KAAK,EAAE,iBAAiB,CAAC,GAAD,CANnB;AAOL,QAAA,IAAI,EAAE,oBAAoB,CAAC,GAAD,CAPrB;AAQL,QAAA,GAAG,EAAE,mBAAmB,CAAC,GAAD,CARnB;AASL,QAAA,YAAY,EAAE,gBAAgB,CAAC,GAAD,CATzB;AAUL,QAAA,SAAS,EAAE,iBAAiB,CAAC,GAAD;AAVvB,OAAP;AAYD,KAfkB,CAArB;AAiBD,GAjCK,CAAN;AAmCA,MAAI,cAAc,GAAG,IAArB;AACA,MAAI,4BAA4B,GAC9B,EADF;;AAGA,MAAI,CAAC,OAAO,CAAC,QAAb,EAAuB;AACrB,IAAA,MAAM,CAAC,yBAAD,EAA4B,MAAK;AACrC,MAAA,4BAA4B,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAC7B,iBAD6B,EAE7B,CAAC,MAAD,EAAS,WAAT,EAAsB,GAAtB,KAA6B;AAC3B,YAAI,OAAO,WAAW,CAAC,OAAnB,KAA+B,QAAnC,EAA6C;AAC3C,gBAAM,QAAQ,GAAG,WAAW,CAAC,OAAZ,CAAoB,UAApB,CAA+B,CAA/B,CAAjB;AACA,gBAAM,YAAY,GAAG,wBAAwB,CAAC,QAAD,CAA7C;AACA,UAAA,gBAAgB,CAAC,MAAD,EAAS,YAAT,EAAuB,kBAAkB,CAAC,GAAD,CAAzC,CAAhB;AACD,SAJD,MAIO,IAAI,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,WAAW,CAAC,gBAApB,CAAJ,EAA2C;AAChD,cAAI,gBAAJ;AACA,WAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,WAAW,CAAC,gBAApB,EAAuC,SAAD,IAAc;AAClD,kBAAM,QAAQ,GACZ,OAAO,SAAP,KAAqB,QAArB,GACI,SAAS,CAAC,UAAV,CAAqB,CAArB,CADJ,GAEI,SAHN;AAIA,kBAAM,gBAAgB,GAAG,wBAAwB,CAAC,QAAD,CAAjD,CALkD,CAMlD;;AACA;AACA;AACA;;AACA,gBAAI,gBAAgB,KAAK,gBAAzB,EAA2C;AACzC,cAAA,gBAAgB,GAAG,gBAAnB;AACA,cAAA,gBAAgB,CACd,MADc,EAEd,gBAFc,EAGd,kBAAkB,CAAC,GAAD,CAHJ,CAAhB;AAKD;AACF,WAlBD;AAmBD,SArBM,MAqBA,IAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,WAAW,CAAC,OAArB,CAAJ,EAAmC;AACxC,cAAI,WAAW,CAAC,OAAZ,CAAoB,OAAxB,EAAiC;AAC/B,YAAA,cAAc,GAAG,KAAjB;;AACA,gBAAI,OAAO,CAAC,mBAAZ,EAAiC;AAC/B,eAAA,GAAA,OAAA,CAAA,WAAA,EACE,GAAG,SAAA,CAAA,2BAA2B,EAA9B,GACE,yBAAyB,WAAW,CAAC,OAAZ,CAAoB,QAApB,EAA8B,eADzD,GAEE,sFAFF,GAGE,6DAHF,GAIE,kGALJ;AAOD;AACF,WAXD,MAWO;AACL,kBAAM,cAAc,GAAG,CAAA,GAAA,SAAA,CAAA,6BAAA,EACrB,WAAW,CAAC,OADS,EAErB,OAAO,CAAC,mBAFa,CAAvB;AAIA;AACA;AACA;;AACA,gBAAI,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,cAAR,CAAJ,EAA6B;AAC3B;AACA;AACA;AACA,cAAA,cAAc,GAAG,KAAjB;AACD;;AACD,aAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,cAAR,EAAyB,IAAD,IAAS;AAC/B,cAAA,gBAAgB,CAAC,MAAD,EAAS,IAAT,EAAe,kBAAkB,CAAC,GAAD,CAAjC,CAAhB;AACD,aAFD;AAGD;AACF,SA9BM,MA8BA;AACL,cAAI,OAAO,CAAC,mBAAZ,EAAiC;AAC/B,aAAA,GAAA,OAAA,CAAA,WAAA,EACE,GAAG,SAAA,CAAA,2BAA2B,EAA9B,GACE,iBAAiB,WAAW,CAAC,IAAI,qFADnC,GAEE,6DAFF,GAGE,iGAJJ;AAMD;;AACD,UAAA,cAAc,GAAG,KAAjB;AACD;;AAED,eAAO,MAAP;AACD,OAvE4B,EAwE7B,EAxE6B,CAA/B;AA0ED,KA3EK,CAAN;AA4ED;;AAED,SAAO;AACL,IAAA,WAAW,EAAE,WADR;AAEL,IAAA,kBAAkB,EAAE,kBAFf;AAGL,IAAA,4BAA4B,EAAE,4BAHzB;AAIL,IAAA,SAAS,EAAE,SAJN;AAKL,IAAA,cAAc,EAAE;AALX,GAAP;AAOD;;AA5TD,OAAA,CAAA,iBAAA,GAAA,iBAAA;;AA8TA,SAAgB,gBAAhB,CACE,UADF,EAEE,eAFF,EAE2B;AAEzB,MAAI,MAAM,GAA4B,EAAtC;AAEA,QAAM,aAAa,GAAG,mBAAmB,CAAC,UAAD,CAAzC;AACA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,aAAa,CAAC,MAA5B,CAAT;AAEA,QAAM,aAAa,GAAG,mBAAmB,CAAC,aAAa,CAAC,KAAf,CAAzC;AACA,QAAM,eAAe,GAAG,aAAa,CAAC,KAAtC;AACA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,aAAa,CAAC,MAA5B,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,qBAAqB,CAAC,eAAD,CAAnC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,oBAAoB,CAAC,eAAD,CAAlC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CACP,uBAAuB,CAAC,eAAD,EAAkB,eAAlB,CADhB,CAAT;AAIA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,uBAAuB,CAAC,eAAD,CAArC,CAAT;AAEA,SAAO,MAAP;AACD;;AAxBD,OAAA,CAAA,gBAAA,GAAA,gBAAA;;AA0BA,SAAS,qBAAT,CACE,UADF,EACyB;AAEvB,MAAI,MAAM,GAA4B,EAAtC;AACA,QAAM,kBAAkB,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,UAAP,EAAoB,WAAD,IAC5C,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,WAAW,CAAC,OAAD,CAApB,CADyB,CAA3B;AAIA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,oBAAoB,CAAC,kBAAD,CAAlC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,sBAAsB,CAAC,kBAAD,CAApC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,oBAAoB,CAAC,kBAAD,CAAlC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,qBAAqB,CAAC,kBAAD,CAAnC,CAAT;AAEA,EAAA,MAAM,GAAG,MAAM,CAAC,MAAP,CAAc,qBAAqB,CAAC,kBAAD,CAAnC,CAAT;AAEA,SAAO,MAAP;AACD;;AAOD,SAAgB,mBAAhB,CACE,UADF,EACyB;AAEvB,QAAM,4BAA4B,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,UAAP,EAAoB,QAAD,IAAa;AACnE,WAAO,CAAC,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,QAAJ,EAAc,OAAd,CAAR;AACD,GAFoC,CAArC;AAIA,QAAM,MAAM,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,4BAAJ,EAAmC,QAAD,IAAa;AAC5D,WAAO;AACL,MAAA,OAAO,EACL,mBACA,QAAQ,CAAC,IADT,GAEA,sCAJG;AAKL,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB,eAL1B;AAML,MAAA,UAAU,EAAE,CAAC,QAAD;AANP,KAAP;AAQD,GATc,CAAf;AAWA,QAAM,KAAK,GAAG,CAAA,GAAA,YAAA,CAAA,OAAA,EAAW,UAAX,EAAuB,4BAAvB,CAAd;AACA,SAAO;AAAE,IAAA,MAAF;AAAU,IAAA;AAAV,GAAP;AACD;;AApBD,OAAA,CAAA,mBAAA,GAAA,mBAAA;;AAsBA,SAAgB,mBAAhB,CACE,UADF,EACyB;AAEvB,QAAM,4BAA4B,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,UAAP,EAAoB,QAAD,IAAa;AACnE,UAAM,OAAO,GAAG,QAAQ,CAAC,OAAD,CAAxB;AACA,WACE,CAAC,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAT,CAAD,IACA,CAAC,CAAA,GAAA,YAAA,CAAA,OAAA,EAAW,OAAX,CADD,IAEA,CAAC,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,OAAJ,EAAa,MAAb,CAFD,IAGA,CAAC,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAT,CAJH;AAMD,GARoC,CAArC;AAUA,QAAM,MAAM,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,4BAAJ,EAAmC,QAAD,IAAa;AAC5D,WAAO;AACL,MAAA,OAAO,EACL,mBACA,QAAQ,CAAC,IADT,GAEA,6CAFA,GAGA,8GALG;AAML,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB,eAN1B;AAOL,MAAA,UAAU,EAAE,CAAC,QAAD;AAPP,KAAP;AASD,GAVc,CAAf;AAYA,QAAM,KAAK,GAAG,CAAA,GAAA,YAAA,CAAA,OAAA,EAAW,UAAX,EAAuB,4BAAvB,CAAd;AACA,SAAO;AAAE,IAAA,MAAF;AAAU,IAAA;AAAV,GAAP;AACD;;AA3BD,OAAA,CAAA,mBAAA,GAAA,mBAAA;AA6BA,MAAM,YAAY,GAAG,UAArB;;AAEA,SAAgB,oBAAhB,CACE,UADF,EACyB;AAEvB,QAAM,eAAN,SAA8B,eAAA,CAAA,iBAA9B,CAA+C;AAA/C,IAAA,WAAA,GAAA;;AACE,WAAA,KAAA,GAAQ,KAAR;AAKD;;AAHC,IAAA,cAAc,CAAC,IAAD,EAAc;AAC1B,WAAK,KAAL,GAAa,IAAb;AACD;;AAL4C;;AAQ/C,QAAM,YAAY,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,UAAP,EAAoB,QAAD,IAAa;AACnD,UAAM,OAAO,GAAG,QAAQ,CAAC,OAAzB;;AAEA,QAAI;AACF,YAAM,SAAS,GAAG,CAAA,GAAA,gBAAA,CAAA,YAAA,EAAa,OAAb,CAAlB;AACA,YAAM,gBAAgB,GAAG,IAAI,eAAJ,EAAzB;AACA,MAAA,gBAAgB,CAAC,KAAjB,CAAuB,SAAvB;AAEA,aAAO,gBAAgB,CAAC,KAAxB;AACD,KAND,CAME,OAAO,CAAP,EAAU;AACV;;AACA;AACA,aAAO,YAAY,CAAC,IAAb,CAAmB,OAAkB,CAAC,MAAtC,CAAP;AACD;AACF,GAdoB,CAArB;AAgBA,QAAM,MAAM,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,YAAJ,EAAmB,QAAD,IAAa;AAC5C,WAAO;AACL,MAAA,OAAO,EACL,sCACA,kBADA,GAEA,QAAQ,CAAC,IAFT,GAGA,8DAHA,GAIA,oEAJA,GAKA,gBAPG;AAQL,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB,gBAR1B;AASL,MAAA,UAAU,EAAE,CAAC,QAAD;AATP,KAAP;AAWD,GAZc,CAAf;AAcA,SAAO,MAAP;AACD;;AA1CD,OAAA,CAAA,oBAAA,GAAA,oBAAA;;AA4CA,SAAgB,qBAAhB,CACE,UADF,EACyB;AAEvB,QAAM,kBAAkB,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,UAAP,EAAoB,QAAD,IAAa;AACzD,UAAM,OAAO,GAAG,QAAQ,CAAC,OAAzB;AACA,WAAO,OAAO,CAAC,IAAR,CAAa,EAAb,CAAP;AACD,GAH0B,CAA3B;AAKA,QAAM,MAAM,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,kBAAJ,EAAyB,QAAD,IAAa;AAClD,WAAO;AACL,MAAA,OAAO,EACL,mBACA,QAAQ,CAAC,IADT,GAEA,oDAJG;AAKL,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB,mBAL1B;AAML,MAAA,UAAU,EAAE,CAAC,QAAD;AANP,KAAP;AAQD,GATc,CAAf;AAWA,SAAO,MAAP;AACD;;AApBD,OAAA,CAAA,qBAAA,GAAA,qBAAA;AAsBA,MAAM,cAAc,GAAG,gBAAvB;;AAEA,SAAgB,sBAAhB,CACE,UADF,EACyB;AAEvB,QAAM,iBAAN,SAAgC,eAAA,CAAA,iBAAhC,CAAiD;AAAjD,IAAA,WAAA,GAAA;;AACE,WAAA,KAAA,GAAQ,KAAR;AAKD;;AAHC,IAAA,gBAAgB,CAAC,IAAD,EAAc;AAC5B,WAAK,KAAL,GAAa,IAAb;AACD;;AAL8C;;AAQjD,QAAM,YAAY,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,UAAP,EAAoB,QAAD,IAAa;AACnD,UAAM,OAAO,GAAG,QAAQ,CAAC,OAAzB;;AACA,QAAI;AACF,YAAM,SAAS,GAAG,CAAA,GAAA,gBAAA,CAAA,YAAA,EAAa,OAAb,CAAlB;AACA,YAAM,kBAAkB,GAAG,IAAI,iBAAJ,EAA3B;AACA,MAAA,kBAAkB,CAAC,KAAnB,CAAyB,SAAzB;AAEA,aAAO,kBAAkB,CAAC,KAA1B;AACD,KAND,CAME,OAAO,CAAP,EAAU;AACV;;AACA;AACA,aAAO,cAAc,CAAC,IAAf,CAAoB,OAAO,CAAC,MAA5B,CAAP;AACD;AACF,GAboB,CAArB;AAeA,QAAM,MAAM,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,YAAJ,EAAmB,QAAD,IAAa;AAC5C,WAAO;AACL,MAAA,OAAO,EACL,sCACA,kBADA,GAEA,QAAQ,CAAC,IAFT,GAGA,gEAHA,GAIA,4EAJA,GAKA,gBAPG;AAQL,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB,gBAR1B;AASL,MAAA,UAAU,EAAE,CAAC,QAAD;AATP,KAAP;AAWD,GAZc,CAAf;AAcA,SAAO,MAAP;AACD;;AAzCD,OAAA,CAAA,sBAAA,GAAA,sBAAA;;AA2CA,SAAgB,oBAAhB,CACE,UADF,EACyB;AAEvB,QAAM,YAAY,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,UAAP,EAAoB,QAAD,IAAa;AACnD,UAAM,OAAO,GAAG,QAAQ,CAAC,OAAD,CAAxB;AACA,WAAO,OAAO,YAAY,MAAnB,KAA8B,OAAO,CAAC,SAAR,IAAqB,OAAO,CAAC,MAA3D,CAAP;AACD,GAHoB,CAArB;AAKA,QAAM,MAAM,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,YAAJ,EAAmB,QAAD,IAAa;AAC5C,WAAO;AACL,MAAA,OAAO,EACL,mBACA,QAAQ,CAAC,IADT,GAEA,mEAJG;AAKL,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB,uBAL1B;AAML,MAAA,UAAU,EAAE,CAAC,QAAD;AANP,KAAP;AAQD,GATc,CAAf;AAWA,SAAO,MAAP;AACD;;AApBD,OAAA,CAAA,oBAAA,GAAA,oBAAA,C,CAsBA;;AACA,SAAgB,qBAAhB,CACE,UADF,EACyB;AAEvB,QAAM,KAAK,GAAgB,EAA3B;AACA,MAAI,iBAAiB,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,UAAJ,EAAiB,SAAD,IAAmB;AACzD,WAAO,CAAA,GAAA,QAAA,CAAA,OAAA,EACL,UADK,EAEL,CAAC,MAAD,EAAS,SAAT,KAAsB;AACpB,UACE,SAAS,CAAC,OAAV,CAAkB,MAAlB,KAA8B,SAAS,CAAC,OAAV,CAA6B,MAA3D,IACA,CAAC,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,KAAT,EAAgB,SAAhB,CADD,IAEA,SAAS,CAAC,OAAV,KAAsB,cAAA,CAAA,KAAA,CAAM,EAH9B,EAIE;AACA;AACA;AACA,QAAA,KAAK,CAAC,IAAN,CAAW,SAAX;AACA,QAAA,MAAM,CAAC,IAAP,CAAY,SAAZ;AACA,eAAO,MAAP;AACD;;AACD,aAAO,MAAP;AACD,KAfI,EAgBL,EAhBK,CAAP;AAkBD,GAnBuB,CAAxB;AAqBA,EAAA,iBAAiB,GAAG,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,iBAAR,CAApB;AAEA,QAAM,iBAAiB,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,iBAAP,EAA2B,gBAAD,IAAqB;AACvE,WAAO,gBAAgB,CAAC,MAAjB,GAA0B,CAAjC;AACD,GAFyB,CAA1B;AAIA,QAAM,MAAM,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,iBAAJ,EAAwB,cAAD,IAAwB;AAC5D,UAAM,cAAc,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,cAAJ,EAAqB,QAAD,IAAkB;AAC3D,aAAO,QAAQ,CAAC,IAAhB;AACD,KAFsB,CAAvB;AAIA,UAAM,aAAa,GAAS,CAAA,GAAA,OAAA,CAAA,OAAA,EAAM,cAAN,EAAuB,OAAnD;AACA,WAAO;AACL,MAAA,OAAO,EACL,6BAA6B,aAAa,IAA1C,GACA,sDAAsD,cAAc,CAAC,IAAf,CACpD,IADoD,CAErD,KALE;AAML,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB,wBAN1B;AAOL,MAAA,UAAU,EAAE;AAPP,KAAP;AASD,GAfc,CAAf;AAiBA,SAAO,MAAP;AACD;;AAjDD,OAAA,CAAA,qBAAA,GAAA,qBAAA;;AAmDA,SAAgB,oBAAhB,CACE,UADF,EACyB;AAEvB,QAAM,YAAY,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,UAAP,EAAoB,KAAD,IAAe;AACrD,QAAI,CAAC,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,KAAJ,EAAW,OAAX,CAAL,EAA0B;AACxB,aAAO,KAAP;AACD;;AACD,UAAM,KAAK,GAAG,KAAK,CAAC,KAApB;AAEA,WAAO,KAAK,KAAK,cAAA,CAAA,KAAA,CAAM,OAAhB,IAA2B,KAAK,KAAK,cAAA,CAAA,KAAA,CAAM,EAA3C,IAAiD,CAAC,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,KAAT,CAAzD;AACD,GAPoB,CAArB;AASA,QAAM,MAAM,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,YAAJ,EAAmB,QAAD,IAAa;AAC5C,WAAO;AACL,MAAA,OAAO,EACL,mBACA,QAAQ,CAAC,IADT,GAEA,+DAJG;AAKL,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB,wBAL1B;AAML,MAAA,UAAU,EAAE,CAAC,QAAD;AANP,KAAP;AAQD,GATc,CAAf;AAWA,SAAO,MAAP;AACD;;AAxBD,OAAA,CAAA,oBAAA,GAAA,oBAAA;;AA0BA,SAAgB,uBAAhB,CACE,UADF,EAEE,UAFF,EAEsB;AAEpB,QAAM,YAAY,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,UAAP,EAAoB,KAAD,IAAe;AACrD,WACE,KAAK,CAAC,SAAN,KAAoB,SAApB,IAAiC,CAAC,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,UAAT,EAAqB,KAAK,CAAC,SAA3B,CADpC;AAGD,GAJoB,CAArB;AAMA,QAAM,MAAM,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,YAAJ,EAAmB,OAAD,IAAY;AAC3C,UAAM,GAAG,GACP,iBAAiB,OAAO,CAAC,IAAI,8DAA8D,OAAO,CAAC,SAAS,IAA5G,GACA,sBAFF;AAGA,WAAO;AACL,MAAA,OAAO,EAAE,GADJ;AAEL,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB,wBAF1B;AAGL,MAAA,UAAU,EAAE,CAAC,OAAD;AAHP,KAAP;AAKD,GATc,CAAf;AAWA,SAAO,MAAP;AACD;;AAtBD,OAAA,CAAA,uBAAA,GAAA,uBAAA;;AAwBA,SAAgB,uBAAhB,CACE,UADF,EACyB;AAEvB,QAAM,MAAM,GAA4B,EAAxC;AAEA,QAAM,WAAW,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EAClB,UADkB,EAElB,CAAC,MAAD,EAAS,OAAT,EAAkB,GAAlB,KAAyB;AACvB,UAAM,OAAO,GAAG,OAAO,CAAC,OAAxB;;AAEA,QAAI,OAAO,KAAK,cAAA,CAAA,KAAA,CAAM,EAAtB,EAA0B;AACxB,aAAO,MAAP;AACD,KALsB,CAOvB;AACA;;;AACA,QAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAT,CAAJ,EAAuB;AACrB,MAAA,MAAM,CAAC,IAAP,CAAY;AAAE,QAAA,GAAG,EAAE,OAAP;AAAgB,QAAA,GAAhB;AAAqB,QAAA,SAAS,EAAE;AAAhC,OAAZ;AACD,KAFD,MAEO,IAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAT,KAAqB,UAAU,CAAC,OAAD,CAAnC,EAA8C;AACnD,MAAA,MAAM,CAAC,IAAP,CAAY;AAAE,QAAA,GAAG,EAAE,OAAO,CAAC,MAAf;AAAuB,QAAA,GAAvB;AAA4B,QAAA,SAAS,EAAE;AAAvC,OAAZ;AACD;;AACD,WAAO,MAAP;AACD,GAjBiB,EAkBlB,EAlBkB,CAApB;AAqBA,GAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,UAAR,EAAoB,CAAC,OAAD,EAAU,OAAV,KAAqB;AACvC,KAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,WAAR,EAAqB,CAAC;AAAE,MAAA,GAAF;AAAO,MAAA,GAAP;AAAY,MAAA;AAAZ,KAAD,KAA4B;AAC/C,UAAI,OAAO,GAAG,GAAV,IAAiB,aAAa,CAAC,GAAD,EAAM,OAAO,CAAC,OAAd,CAAlC,EAA0D;AACxD,cAAM,GAAG,GACP,YAAY,SAAS,CAAC,IAAI,4BAA1B,GACA,6CAA6C,OAAO,CAAC,IAAI,IADzD,GAEA,8BAFA,GAGA,8EAJF;AAKA,QAAA,MAAM,CAAC,IAAP,CAAY;AACV,UAAA,OAAO,EAAE,GADC;AAEV,UAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB,mBAFrB;AAGV,UAAA,UAAU,EAAE,CAAC,OAAD,EAAU,SAAV;AAHF,SAAZ;AAKD;AACF,KAbD;AAcD,GAfD;AAiBA,SAAO,MAAP;AACD;;AA5CD,OAAA,CAAA,uBAAA,GAAA,uBAAA;;AA8CA,SAAS,aAAT,CAAuB,GAAvB,EAAoC,OAApC,EAAgD;AAC9C;AACA,MAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAT,CAAJ,EAAuB;AACrB,UAAM,WAAW,GAAG,OAAO,CAAC,IAAR,CAAa,GAAb,CAApB;AACA,WAAO,WAAW,KAAK,IAAhB,IAAwB,WAAW,CAAC,KAAZ,KAAsB,CAArD;AACD,GAHD,MAGO,IAAI,CAAA,GAAA,YAAA,CAAA,OAAA,EAAW,OAAX,CAAJ,EAAyB;AAC9B;AACA,WAAO,OAAO,CAAC,GAAD,EAAM,CAAN,EAAS,EAAT,EAAa,EAAb,CAAd;AACD,GAHM,MAGA,IAAI,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,OAAJ,EAAa,MAAb,CAAJ,EAA0B;AAC/B;AACA,WAAO,OAAO,CAAC,IAAR,CAAa,GAAb,EAAkB,CAAlB,EAAqB,EAArB,EAAyB,EAAzB,CAAP;AACD,GAHM,MAGA,IAAI,OAAO,OAAP,KAAmB,QAAvB,EAAiC;AACtC,WAAO,OAAO,KAAK,GAAnB;AACD,GAFM,MAEA;AACL,UAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;;AAED,SAAS,UAAT,CAAoB,MAApB,EAAkC;AAChC;AACA,QAAM,SAAS,GAAG,CAChB,GADgB,EAEhB,IAFgB,EAGhB,GAHgB,EAIhB,GAJgB,EAKhB,GALgB,EAMhB,GANgB,EAOhB,GAPgB,EAQhB,GARgB,EAShB,GATgB,EAUhB,GAVgB,EAWhB,GAXgB,EAYhB,GAZgB,EAahB,GAbgB,CAAlB;AAeA,SACE,CAAA,GAAA,MAAA,CAAA,OAAA,EAAK,SAAL,EAAiB,IAAD,IAAU,MAAM,CAAC,MAAP,CAAc,OAAd,CAAsB,IAAtB,MAAgC,CAAC,CAA3D,MAAkE,SADpE;AAGD;;AAED,SAAgB,eAAhB,CAAgC,OAAhC,EAA+C;AAC7C,QAAM,KAAK,GAAG,OAAO,CAAC,UAAR,GAAqB,GAArB,GAA2B,EAAzC,CAD6C,CAE7C;AACA;;AACA,SAAO,IAAI,MAAJ,CAAW,OAAO,OAAO,CAAC,MAAM,GAAhC,EAAqC,KAArC,CAAP;AACD;;AALD,OAAA,CAAA,eAAA,GAAA,eAAA;;AAOA,SAAgB,aAAhB,CAA8B,OAA9B,EAA6C;AAC3C,QAAM,KAAK,GAAG,OAAO,CAAC,UAAR,GAAqB,IAArB,GAA4B,GAA1C,CAD2C,CAE3C;AACA;;AACA,SAAO,IAAI,MAAJ,CAAW,GAAG,OAAO,CAAC,MAAM,EAA5B,EAAgC,KAAhC,CAAP;AACD;;AALD,OAAA,CAAA,aAAA,GAAA,aAAA;;AAOA,SAAgB,oBAAhB,CACE,eADF,EAEE,UAFF,EAGE,wBAHF,EAG+C;AAE7C,QAAM,MAAM,GAA4B,EAAxC,CAF6C,CAI7C;;AACA,MAAI,CAAC,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,eAAJ,EAAqB,OAAA,CAAA,YAArB,CAAL,EAAyC;AACvC,IAAA,MAAM,CAAC,IAAP,CAAY;AACV,MAAA,OAAO,EACL,wDACA,OAAA,CAAA,YADA,GAEA,gCAJQ;AAKV,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB;AALrB,KAAZ;AAOD;;AACD,MAAI,CAAC,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,eAAJ,EAAqB,OAAA,CAAA,KAArB,CAAL,EAAkC;AAChC,IAAA,MAAM,CAAC,IAAP,CAAY;AACV,MAAA,OAAO,EACL,wDACA,OAAA,CAAA,KADA,GAEA,gCAJQ;AAKV,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB;AALrB,KAAZ;AAOD;;AAED,MACE,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,eAAJ,EAAqB,OAAA,CAAA,KAArB,KACA,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,eAAJ,EAAqB,OAAA,CAAA,YAArB,CADA,IAEA,CAAC,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,eAAe,CAAC,KAApB,EAA2B,eAAe,CAAC,WAA3C,CAHH,EAIE;AACA,IAAA,MAAM,CAAC,IAAP,CAAY;AACV,MAAA,OAAO,EACL,kDAAkD,OAAA,CAAA,YAAY,MAAM,eAAe,CAAC,WAAW,GAA/F,GACA,wBAHQ;AAIV,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB;AAJrB,KAAZ;AAMD;;AAED,MAAI,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,eAAJ,EAAqB,OAAA,CAAA,KAArB,CAAJ,EAAiC;AAC/B,KAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,eAAe,CAAC,KAAxB,EAA+B,CAAC,aAAD,EAAgB,YAAhB,KAAgC;AAC7D,OAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,aAAR,EAAuB,CAAC,WAAD,EAAc,OAAd,KAAyB;AAC9C,YAAI,CAAA,GAAA,aAAA,CAAA,OAAA,EAAY,WAAZ,CAAJ,EAA8B;AAC5B,UAAA,MAAM,CAAC,IAAP,CAAY;AACV,YAAA,OAAO,EACL,oEAAA,GACA,IAAI,YAAY,gBAAgB,OAAO,KAH/B;AAIV,YAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB;AAJrB,WAAZ;AAMD,SAPD,MAOO,IAAI,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,WAAJ,EAAiB,YAAjB,CAAJ,EAAoC;AACzC,gBAAM,SAAS,GAAG,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,WAAW,CAAC,UAApB,IACd,WAAW,CAAC,UADE,GAEd,CAAC,WAAW,CAAC,UAAb,CAFJ;AAGA,WAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,SAAR,EAAoB,aAAD,IAAkB;AACnC,gBACE,CAAC,CAAA,GAAA,aAAA,CAAA,OAAA,EAAY,aAAZ,CAAD,IACA,CAAC,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,aAAT,EAAwB,aAAxB,CAFH,EAGE;AACA,cAAA,MAAM,CAAC,IAAP,CAAY;AACV,gBAAA,OAAO,EAAE,8DAA8D,aAAa,CAAC,IAAI,eAAe,WAAW,CAAC,IAAI,sBAAsB,YAAY,KADhJ;AAEV,gBAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB;AAFrB,eAAZ;AAID;AACF,WAVD;AAWD;AACF,OAxBD;AAyBD,KA1BD;AA2BD;;AAED,SAAO,MAAP;AACD;;AAvED,OAAA,CAAA,oBAAA,GAAA,oBAAA;;AAyEA,SAAgB,2BAAhB,CACE,eADF,EAEE,UAFF,EAGE,wBAHF,EAG+C;AAE7C,QAAM,QAAQ,GAAG,EAAjB;AACA,MAAI,eAAe,GAAG,KAAtB;AACA,QAAM,aAAa,GAAG,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,eAAe,CAAC,KAAvB,CAAR,CAAR,CAAtB;AAEA,QAAM,kBAAkB,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EACzB,aADyB,EAExB,QAAD,IAAc,QAAQ,CAAC,OAAD,CAAR,KAAsB,cAAA,CAAA,KAAA,CAAM,EAFjB,CAA3B;AAIA,QAAM,mBAAmB,GAAG,YAAY,CAAC,wBAAD,CAAxC;;AACA,MAAI,UAAJ,EAAgB;AACd,KAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,kBAAR,EAA6B,OAAD,IAAY;AACtC,YAAM,SAAS,GAAG,qBAAqB,CAAC,OAAD,EAAU,mBAAV,CAAvC;;AACA,UAAI,SAAS,KAAK,KAAlB,EAAyB;AACvB,cAAM,OAAO,GAAG,0BAA0B,CAAC,OAAD,EAAU,SAAV,CAA1C;AACA,cAAM,iBAAiB,GAAG;AACxB,UAAA,OADwB;AAExB,UAAA,IAAI,EAAE,SAAS,CAAC,KAFQ;AAGxB,UAAA,SAAS,EAAE;AAHa,SAA1B;AAKA,QAAA,QAAQ,CAAC,IAAT,CAAc,iBAAd;AACD,OARD,MAQO;AACL;AACA,YAAI,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,OAAJ,EAAa,aAAb,CAAJ,EAAiC;AAC/B,cAAI,OAAO,CAAC,WAAR,KAAwB,IAA5B,EAAkC;AAChC,YAAA,eAAe,GAAG,IAAlB;AACD;AACF,SAJD,MAIO;AACL,cACE,CAAA,GAAA,SAAA,CAAA,gBAAA,EAAiB,mBAAjB,EAAsC,OAAO,CAAC,OAA9C,CADF,EAEE;AACA,YAAA,eAAe,GAAG,IAAlB;AACD;AACF;AACF;AACF,KAxBD;AAyBD;;AAED,MAAI,UAAU,IAAI,CAAC,eAAnB,EAAoC;AAClC,IAAA,QAAQ,CAAC,IAAT,CAAc;AACZ,MAAA,OAAO,EACL,qCACA,uEADA,GAEA,kFAFA,GAGA,mFAHA,GAIA,gBANU;AAOZ,MAAA,IAAI,EAAE,cAAA,CAAA,wBAAA,CAAyB;AAPnB,KAAd;AASD;;AACD,SAAO,QAAP;AACD;;AAtDD,OAAA,CAAA,2BAAA,GAAA,2BAAA;;AAwDA,SAAgB,gBAAhB,CAAiC,WAAjC,EAEC;AACC,QAAM,YAAY,GAAQ,EAA1B;AACA,QAAM,SAAS,GAAG,CAAA,GAAA,MAAA,CAAA,OAAA,EAAK,WAAL,CAAlB;AAEA,GAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,SAAR,EAAoB,OAAD,IAAY;AAC7B,UAAM,cAAc,GAAG,WAAW,CAAC,OAAD,CAAlC;AAEA;;AACA,QAAI,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,cAAR,CAAJ,EAA6B;AAC3B,MAAA,YAAY,CAAC,OAAD,CAAZ,GAAwB,EAAxB;AACD,KAFD,MAEO;AACL,YAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF,GATD;AAWA,SAAO,YAAP;AACD;;AAlBD,OAAA,CAAA,gBAAA,GAAA,gBAAA,C,CAoBA;;AACA,SAAgB,eAAhB,CAAgC,SAAhC,EAAoD;AAClD,QAAM,OAAO,GAAG,SAAS,CAAC,OAA1B;AACA;;AACA,MAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAT,CAAJ,EAAuB;AACrB,WAAO,KAAP;AACD,GAFD,MAEO,IAAI,CAAA,GAAA,YAAA,CAAA,OAAA,EAAW,OAAX,CAAJ,EAAyB;AAC9B;AACA,WAAO,IAAP;AACD,GAHM,MAGA,IAAI,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,OAAJ,EAAa,MAAb,CAAJ,EAA0B;AAC/B;AACA,WAAO,IAAP;AACD,GAHM,MAGA,IAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAT,CAAJ,EAAuB;AAC5B,WAAO,KAAP;AACD,GAFM,MAEA;AACL,UAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;;AAhBD,OAAA,CAAA,eAAA,GAAA,eAAA;;AAkBA,SAAgB,cAAhB,CAA+B,OAA/B,EAA2C;AACzC,MAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAT,KAAqB,OAAO,CAAC,MAAR,KAAmB,CAA5C,EAA+C;AAC7C,WAAO,OAAO,CAAC,UAAR,CAAmB,CAAnB,CAAP;AACD,GAFD,MAEO;AACL,WAAO,KAAP;AACD;AACF;;AAND,OAAA,CAAA,cAAA,GAAA,cAAA;AAQA;;AAEG;;AACU,OAAA,CAAA,6BAAA,GAAwD;AACnE;AACA,EAAA,IAAI,EAAE,UAAU,IAAV,EAAc;AAClB,UAAM,GAAG,GAAG,IAAI,CAAC,MAAjB;;AACA,SAAK,IAAI,CAAC,GAAG,KAAK,SAAlB,EAA6B,CAAC,GAAG,GAAjC,EAAsC,CAAC,EAAvC,EAA2C;AACzC,YAAM,CAAC,GAAG,IAAI,CAAC,UAAL,CAAgB,CAAhB,CAAV;;AACA,UAAI,CAAC,KAAK,EAAV,EAAc;AACZ,aAAK,SAAL,GAAiB,CAAC,GAAG,CAArB;AACA,eAAO,IAAP;AACD,OAHD,MAGO,IAAI,CAAC,KAAK,EAAV,EAAc;AACnB,YAAI,IAAI,CAAC,UAAL,CAAgB,CAAC,GAAG,CAApB,MAA2B,EAA/B,EAAmC;AACjC,eAAK,SAAL,GAAiB,CAAC,GAAG,CAArB;AACD,SAFD,MAEO;AACL,eAAK,SAAL,GAAiB,CAAC,GAAG,CAArB;AACD;;AACD,eAAO,IAAP;AACD;AACF;;AACD,WAAO,KAAP;AACD,GAnBkE;AAqBnE,EAAA,SAAS,EAAE;AArBwD,CAAxD;;AAwBb,SAAS,qBAAT,CACE,OADF,EAEE,uBAFF,EAEmC;AASjC,MAAI,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,OAAJ,EAAa,aAAb,CAAJ,EAAiC;AAC/B;AACA;AACA,WAAO,KAAP;AACD,GAJD,MAIO;AACL;AACA,QAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAO,CAAC,OAAjB,CAAJ,EAA+B;AAC7B,UAAI;AACF;AACA,SAAA,GAAA,SAAA,CAAA,gBAAA,EAAiB,uBAAjB,EAA0C,OAAO,CAAC,OAAlD;AACD,OAHD,CAGE,OAAO,CAAP,EAAU;AACV;AACA,eAAO;AACL,UAAA,KAAK,EAAE,cAAA,CAAA,wBAAA,CAAyB,mBAD3B;AAEL,UAAA,MAAM,EAAG,CAAW,CAAC;AAFhB,SAAP;AAID;;AACD,aAAO,KAAP;AACD,KAZD,MAYO,IAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,OAAO,CAAC,OAAjB,CAAJ,EAA+B;AACpC;AACA,aAAO,KAAP;AACD,KAHM,MAGA,IAAI,eAAe,CAAC,OAAD,CAAnB,EAA8B;AACnC;AACA,aAAO;AAAE,QAAA,KAAK,EAAE,cAAA,CAAA,wBAAA,CAAyB;AAAlC,OAAP;AACD,KAHM,MAGA;AACL,YAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;AACF;;AAED,SAAgB,0BAAhB,CACE,OADF,EAEE,OAFF,EAOG;AAED;AACA,MAAI,OAAO,CAAC,KAAR,KAAkB,cAAA,CAAA,wBAAA,CAAyB,mBAA/C,EAAoE;AAClE,WACE,oEACA,4BAA4B,OAAO,CAAC,IAAI,gBADxC,GAEA,kBAAkB,OAAO,CAAC,MAAM,KAFhC,GAGA,qGAJF;AAMD,GAPD,MAOO,IAAI,OAAO,CAAC,KAAR,KAAkB,cAAA,CAAA,wBAAA,CAAyB,iBAA/C,EAAkE;AACvE,WACE,+EACA,4BAA4B,OAAO,CAAC,IAAI,gBADxC,GAEA,mGAHF;AAKD,GANM,MAMA;AACL,UAAM,KAAK,CAAC,sBAAD,CAAX;AACD;AACF;;AA1BD,OAAA,CAAA,0BAAA,GAAA,0BAAA;;AA4BA,SAAS,YAAT,CAAsB,YAAtB,EAAuD;AACrD,QAAM,SAAS,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,YAAJ,EAAmB,WAAD,IAAgB;AAClD,QAAI,CAAA,GAAA,UAAA,CAAA,OAAA,EAAS,WAAT,CAAJ,EAA2B;AACzB,aAAO,WAAW,CAAC,UAAZ,CAAuB,CAAvB,CAAP;AACD,KAFD,MAEO;AACL,aAAO,WAAP;AACD;AACF,GANiB,CAAlB;AAQA,SAAO,SAAP;AACD;;AAED,SAAS,gBAAT,CACE,GADF,EAEE,GAFF,EAGE,KAHF,EAGU;AAER,MAAI,GAAG,CAAC,GAAD,CAAH,KAAa,SAAjB,EAA4B;AAC1B,IAAA,GAAG,CAAC,GAAD,CAAH,GAAW,CAAC,KAAD,CAAX;AACD,GAFD,MAEO;AACL,IAAA,GAAG,CAAC,GAAD,CAAH,CAAS,IAAT,CAAc,KAAd;AACD;AACF;;AAEY,OAAA,CAAA,kBAAA,GAAqB,GAArB;AAEb;;;;;;;;;;;;;;AAcG;;AACH,IAAI,yBAAyB,GAAa,EAA1C;;AACA,SAAgB,wBAAhB,CAAyC,QAAzC,EAAyD;AACvD,SAAO,QAAQ,GAAG,OAAA,CAAA,kBAAX,GACH,QADG,GAEH,yBAAyB,CAAC,QAAD,CAF7B;AAGD;;AAJD,OAAA,CAAA,wBAAA,GAAA,wBAAA;AAMA;;;;;;;AAOG;;AACH,SAAS,+BAAT,GAAwC;AACtC,MAAI,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,yBAAR,CAAJ,EAAwC;AACtC,IAAA,yBAAyB,GAAG,IAAI,KAAJ,CAAU,KAAV,CAA5B;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAApB,EAA2B,CAAC,EAA5B,EAAgC;AAC9B,MAAA,yBAAyB,CAAC,CAAD,CAAzB,GAA+B,CAAC,GAAG,GAAJ,GAAU,MAAM,CAAC,EAAE,CAAC,GAAG,GAAN,CAAjB,GAA8B,CAA7D;AACD;AACF;AACF","sourceRoot":"","sourcesContent":["\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.charCodeToOptimizedIndex = exports.minOptimizationVal = exports.buildLineBreakIssueMessage = exports.LineTerminatorOptimizedTester = exports.isShortPattern = exports.isCustomPattern = exports.cloneEmptyGroups = exports.performWarningRuntimeChecks = exports.performRuntimeChecks = exports.addStickyFlag = exports.addStartOfInput = exports.findUnreachablePatterns = exports.findModesThatDoNotExist = exports.findInvalidGroupType = exports.findDuplicatePatterns = exports.findUnsupportedFlags = exports.findStartOfInputAnchor = exports.findEmptyMatchRegExps = exports.findEndOfInputAnchor = exports.findInvalidPatterns = exports.findMissingPatterns = exports.validatePatterns = exports.analyzeTokenTypes = exports.enableSticky = exports.disableSticky = exports.SUPPORT_STICKY = exports.MODES = exports.DEFAULT_MODE = void 0;\nconst regexp_to_ast_1 = require(\"regexp-to-ast\");\nconst lexer_public_1 = require(\"./lexer_public\");\nconst first_1 = __importDefault(require(\"lodash/first\"));\nconst isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\nconst compact_1 = __importDefault(require(\"lodash/compact\"));\nconst isArray_1 = __importDefault(require(\"lodash/isArray\"));\nconst values_1 = __importDefault(require(\"lodash/values\"));\nconst flatten_1 = __importDefault(require(\"lodash/flatten\"));\nconst reject_1 = __importDefault(require(\"lodash/reject\"));\nconst difference_1 = __importDefault(require(\"lodash/difference\"));\nconst indexOf_1 = __importDefault(require(\"lodash/indexOf\"));\nconst map_1 = __importDefault(require(\"lodash/map\"));\nconst forEach_1 = __importDefault(require(\"lodash/forEach\"));\nconst isString_1 = __importDefault(require(\"lodash/isString\"));\nconst isFunction_1 = __importDefault(require(\"lodash/isFunction\"));\nconst isUndefined_1 = __importDefault(require(\"lodash/isUndefined\"));\nconst find_1 = __importDefault(require(\"lodash/find\"));\nconst has_1 = __importDefault(require(\"lodash/has\"));\nconst keys_1 = __importDefault(require(\"lodash/keys\"));\nconst isRegExp_1 = __importDefault(require(\"lodash/isRegExp\"));\nconst filter_1 = __importDefault(require(\"lodash/filter\"));\nconst defaults_1 = __importDefault(require(\"lodash/defaults\"));\nconst reduce_1 = __importDefault(require(\"lodash/reduce\"));\nconst includes_1 = __importDefault(require(\"lodash/includes\"));\nconst utils_1 = require(\"@chevrotain/utils\");\nconst reg_exp_1 = require(\"./reg_exp\");\nconst reg_exp_parser_1 = require(\"./reg_exp_parser\");\nconst PATTERN = \"PATTERN\";\nexports.DEFAULT_MODE = \"defaultMode\";\nexports.MODES = \"modes\";\nexports.SUPPORT_STICKY = typeof new RegExp(\"(?:)\").sticky === \"boolean\";\nfunction disableSticky() {\n    exports.SUPPORT_STICKY = false;\n}\nexports.disableSticky = disableSticky;\nfunction enableSticky() {\n    exports.SUPPORT_STICKY = true;\n}\nexports.enableSticky = enableSticky;\nfunction analyzeTokenTypes(tokenTypes, options) {\n    options = (0, defaults_1.default)(options, {\n        useSticky: exports.SUPPORT_STICKY,\n        debug: false,\n        safeMode: false,\n        positionTracking: \"full\",\n        lineTerminatorCharacters: [\"\\r\", \"\\n\"],\n        tracer: (msg, action) => action()\n    });\n    const tracer = options.tracer;\n    tracer(\"initCharCodeToOptimizedIndexMap\", () => {\n        initCharCodeToOptimizedIndexMap();\n    });\n    let onlyRelevantTypes;\n    tracer(\"Reject Lexer.NA\", () => {\n        onlyRelevantTypes = (0, reject_1.default)(tokenTypes, (currType) => {\n            return currType[PATTERN] === lexer_public_1.Lexer.NA;\n        });\n    });\n    let hasCustom = false;\n    let allTransformedPatterns;\n    tracer(\"Transform Patterns\", () => {\n        hasCustom = false;\n        allTransformedPatterns = (0, map_1.default)(onlyRelevantTypes, (currType) => {\n            const currPattern = currType[PATTERN];\n            /* istanbul ignore else */\n            if ((0, isRegExp_1.default)(currPattern)) {\n                const regExpSource = currPattern.source;\n                if (regExpSource.length === 1 &&\n                    // only these regExp meta characters which can appear in a length one regExp\n                    regExpSource !== \"^\" &&\n                    regExpSource !== \"$\" &&\n                    regExpSource !== \".\" &&\n                    !currPattern.ignoreCase) {\n                    return regExpSource;\n                }\n                else if (regExpSource.length === 2 &&\n                    regExpSource[0] === \"\\\\\" &&\n                    // not a meta character\n                    !(0, includes_1.default)([\n                        \"d\",\n                        \"D\",\n                        \"s\",\n                        \"S\",\n                        \"t\",\n                        \"r\",\n                        \"n\",\n                        \"t\",\n                        \"0\",\n                        \"c\",\n                        \"b\",\n                        \"B\",\n                        \"f\",\n                        \"v\",\n                        \"w\",\n                        \"W\"\n                    ], regExpSource[1])) {\n                    // escaped meta Characters: /\\+/ /\\[/\n                    // or redundant escaping: /\\a/\n                    // without the escaping \"\\\"\n                    return regExpSource[1];\n                }\n                else {\n                    return options.useSticky\n                        ? addStickyFlag(currPattern)\n                        : addStartOfInput(currPattern);\n                }\n            }\n            else if ((0, isFunction_1.default)(currPattern)) {\n                hasCustom = true;\n                // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n                return { exec: currPattern };\n            }\n            else if (typeof currPattern === \"object\") {\n                hasCustom = true;\n                // ICustomPattern\n                return currPattern;\n            }\n            else if (typeof currPattern === \"string\") {\n                if (currPattern.length === 1) {\n                    return currPattern;\n                }\n                else {\n                    const escapedRegExpString = currPattern.replace(/[\\\\^$.*+?()[\\]{}|]/g, \"\\\\$&\");\n                    const wrappedRegExp = new RegExp(escapedRegExpString);\n                    return options.useSticky\n                        ? addStickyFlag(wrappedRegExp)\n                        : addStartOfInput(wrappedRegExp);\n                }\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n    });\n    let patternIdxToType;\n    let patternIdxToGroup;\n    let patternIdxToLongerAltIdxArr;\n    let patternIdxToPushMode;\n    let patternIdxToPopMode;\n    tracer(\"misc mapping\", () => {\n        patternIdxToType = (0, map_1.default)(onlyRelevantTypes, (currType) => currType.tokenTypeIdx);\n        patternIdxToGroup = (0, map_1.default)(onlyRelevantTypes, (clazz) => {\n            const groupName = clazz.GROUP;\n            /* istanbul ignore next */\n            if (groupName === lexer_public_1.Lexer.SKIPPED) {\n                return undefined;\n            }\n            else if ((0, isString_1.default)(groupName)) {\n                return groupName;\n            }\n            else if ((0, isUndefined_1.default)(groupName)) {\n                return false;\n            }\n            else {\n                throw Error(\"non exhaustive match\");\n            }\n        });\n        patternIdxToLongerAltIdxArr = (0, map_1.default)(onlyRelevantTypes, (clazz) => {\n            const longerAltType = clazz.LONGER_ALT;\n            if (longerAltType) {\n                const longerAltIdxArr = (0, isArray_1.default)(longerAltType)\n                    ? (0, map_1.default)(longerAltType, (type) => (0, indexOf_1.default)(onlyRelevantTypes, type))\n                    : [(0, indexOf_1.default)(onlyRelevantTypes, longerAltType)];\n                return longerAltIdxArr;\n            }\n        });\n        patternIdxToPushMode = (0, map_1.default)(onlyRelevantTypes, (clazz) => clazz.PUSH_MODE);\n        patternIdxToPopMode = (0, map_1.default)(onlyRelevantTypes, (clazz) => (0, has_1.default)(clazz, \"POP_MODE\"));\n    });\n    let patternIdxToCanLineTerminator;\n    tracer(\"Line Terminator Handling\", () => {\n        const lineTerminatorCharCodes = getCharCodes(options.lineTerminatorCharacters);\n        patternIdxToCanLineTerminator = (0, map_1.default)(onlyRelevantTypes, (tokType) => false);\n        if (options.positionTracking !== \"onlyOffset\") {\n            patternIdxToCanLineTerminator = (0, map_1.default)(onlyRelevantTypes, (tokType) => {\n                if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n                    return !!tokType.LINE_BREAKS;\n                }\n                else {\n                    return (checkLineBreaksIssues(tokType, lineTerminatorCharCodes) === false &&\n                        (0, reg_exp_1.canMatchCharCode)(lineTerminatorCharCodes, tokType.PATTERN));\n                }\n            });\n        }\n    });\n    let patternIdxToIsCustom;\n    let patternIdxToShort;\n    let emptyGroups;\n    let patternIdxToConfig;\n    tracer(\"Misc Mapping #2\", () => {\n        patternIdxToIsCustom = (0, map_1.default)(onlyRelevantTypes, isCustomPattern);\n        patternIdxToShort = (0, map_1.default)(allTransformedPatterns, isShortPattern);\n        emptyGroups = (0, reduce_1.default)(onlyRelevantTypes, (acc, clazz) => {\n            const groupName = clazz.GROUP;\n            if ((0, isString_1.default)(groupName) && !(groupName === lexer_public_1.Lexer.SKIPPED)) {\n                acc[groupName] = [];\n            }\n            return acc;\n        }, {});\n        patternIdxToConfig = (0, map_1.default)(allTransformedPatterns, (x, idx) => {\n            return {\n                pattern: allTransformedPatterns[idx],\n                longerAlt: patternIdxToLongerAltIdxArr[idx],\n                canLineTerminator: patternIdxToCanLineTerminator[idx],\n                isCustom: patternIdxToIsCustom[idx],\n                short: patternIdxToShort[idx],\n                group: patternIdxToGroup[idx],\n                push: patternIdxToPushMode[idx],\n                pop: patternIdxToPopMode[idx],\n                tokenTypeIdx: patternIdxToType[idx],\n                tokenType: onlyRelevantTypes[idx]\n            };\n        });\n    });\n    let canBeOptimized = true;\n    let charCodeToPatternIdxToConfig = [];\n    if (!options.safeMode) {\n        tracer(\"First Char Optimization\", () => {\n            charCodeToPatternIdxToConfig = (0, reduce_1.default)(onlyRelevantTypes, (result, currTokType, idx) => {\n                if (typeof currTokType.PATTERN === \"string\") {\n                    const charCode = currTokType.PATTERN.charCodeAt(0);\n                    const optimizedIdx = charCodeToOptimizedIndex(charCode);\n                    addToMapOfArrays(result, optimizedIdx, patternIdxToConfig[idx]);\n                }\n                else if ((0, isArray_1.default)(currTokType.START_CHARS_HINT)) {\n                    let lastOptimizedIdx;\n                    (0, forEach_1.default)(currTokType.START_CHARS_HINT, (charOrInt) => {\n                        const charCode = typeof charOrInt === \"string\"\n                            ? charOrInt.charCodeAt(0)\n                            : charOrInt;\n                        const currOptimizedIdx = charCodeToOptimizedIndex(charCode);\n                        // Avoid adding the config multiple times\n                        /* istanbul ignore else */\n                        // - Difficult to check this scenario effects as it is only a performance\n                        //   optimization that does not change correctness\n                        if (lastOptimizedIdx !== currOptimizedIdx) {\n                            lastOptimizedIdx = currOptimizedIdx;\n                            addToMapOfArrays(result, currOptimizedIdx, patternIdxToConfig[idx]);\n                        }\n                    });\n                }\n                else if ((0, isRegExp_1.default)(currTokType.PATTERN)) {\n                    if (currTokType.PATTERN.unicode) {\n                        canBeOptimized = false;\n                        if (options.ensureOptimizations) {\n                            (0, utils_1.PRINT_ERROR)(`${reg_exp_1.failedOptimizationPrefixMsg}` +\n                                `\\tUnable to analyze < ${currTokType.PATTERN.toString()} > pattern.\\n` +\n                                \"\\tThe regexp unicode flag is not currently supported by the regexp-to-ast library.\\n\" +\n                                \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                                \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNICODE_OPTIMIZE\");\n                        }\n                    }\n                    else {\n                        const optimizedCodes = (0, reg_exp_1.getOptimizedStartCodesIndices)(currTokType.PATTERN, options.ensureOptimizations);\n                        /* istanbul ignore if */\n                        // start code will only be empty given an empty regExp or failure of regexp-to-ast library\n                        // the first should be a different validation and the second cannot be tested.\n                        if ((0, isEmpty_1.default)(optimizedCodes)) {\n                            // we cannot understand what codes may start possible matches\n                            // The optimization correctness requires knowing start codes for ALL patterns.\n                            // Not actually sure this is an error, no debug message\n                            canBeOptimized = false;\n                        }\n                        (0, forEach_1.default)(optimizedCodes, (code) => {\n                            addToMapOfArrays(result, code, patternIdxToConfig[idx]);\n                        });\n                    }\n                }\n                else {\n                    if (options.ensureOptimizations) {\n                        (0, utils_1.PRINT_ERROR)(`${reg_exp_1.failedOptimizationPrefixMsg}` +\n                            `\\tTokenType: <${currTokType.name}> is using a custom token pattern without providing <start_chars_hint> parameter.\\n` +\n                            \"\\tThis will disable the lexer's first char optimizations.\\n\" +\n                            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_OPTIMIZE\");\n                    }\n                    canBeOptimized = false;\n                }\n                return result;\n            }, []);\n        });\n    }\n    return {\n        emptyGroups: emptyGroups,\n        patternIdxToConfig: patternIdxToConfig,\n        charCodeToPatternIdxToConfig: charCodeToPatternIdxToConfig,\n        hasCustom: hasCustom,\n        canBeOptimized: canBeOptimized\n    };\n}\nexports.analyzeTokenTypes = analyzeTokenTypes;\nfunction validatePatterns(tokenTypes, validModesNames) {\n    let errors = [];\n    const missingResult = findMissingPatterns(tokenTypes);\n    errors = errors.concat(missingResult.errors);\n    const invalidResult = findInvalidPatterns(missingResult.valid);\n    const validTokenTypes = invalidResult.valid;\n    errors = errors.concat(invalidResult.errors);\n    errors = errors.concat(validateRegExpPattern(validTokenTypes));\n    errors = errors.concat(findInvalidGroupType(validTokenTypes));\n    errors = errors.concat(findModesThatDoNotExist(validTokenTypes, validModesNames));\n    errors = errors.concat(findUnreachablePatterns(validTokenTypes));\n    return errors;\n}\nexports.validatePatterns = validatePatterns;\nfunction validateRegExpPattern(tokenTypes) {\n    let errors = [];\n    const withRegExpPatterns = (0, filter_1.default)(tokenTypes, (currTokType) => (0, isRegExp_1.default)(currTokType[PATTERN]));\n    errors = errors.concat(findEndOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findStartOfInputAnchor(withRegExpPatterns));\n    errors = errors.concat(findUnsupportedFlags(withRegExpPatterns));\n    errors = errors.concat(findDuplicatePatterns(withRegExpPatterns));\n    errors = errors.concat(findEmptyMatchRegExps(withRegExpPatterns));\n    return errors;\n}\nfunction findMissingPatterns(tokenTypes) {\n    const tokenTypesWithMissingPattern = (0, filter_1.default)(tokenTypes, (currType) => {\n        return !(0, has_1.default)(currType, PATTERN);\n    });\n    const errors = (0, map_1.default)(tokenTypesWithMissingPattern, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- missing static 'PATTERN' property\",\n            type: lexer_public_1.LexerDefinitionErrorType.MISSING_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    const valid = (0, difference_1.default)(tokenTypes, tokenTypesWithMissingPattern);\n    return { errors, valid };\n}\nexports.findMissingPatterns = findMissingPatterns;\nfunction findInvalidPatterns(tokenTypes) {\n    const tokenTypesWithInvalidPattern = (0, filter_1.default)(tokenTypes, (currType) => {\n        const pattern = currType[PATTERN];\n        return (!(0, isRegExp_1.default)(pattern) &&\n            !(0, isFunction_1.default)(pattern) &&\n            !(0, has_1.default)(pattern, \"exec\") &&\n            !(0, isString_1.default)(pattern));\n    });\n    const errors = (0, map_1.default)(tokenTypesWithInvalidPattern, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' can only be a RegExp, a\" +\n                \" Function matching the {CustomPatternMatcherFunc} type or an Object matching the {ICustomPattern} interface.\",\n            type: lexer_public_1.LexerDefinitionErrorType.INVALID_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    const valid = (0, difference_1.default)(tokenTypes, tokenTypesWithInvalidPattern);\n    return { errors, valid };\n}\nexports.findInvalidPatterns = findInvalidPatterns;\nconst end_of_input = /[^\\\\][$]/;\nfunction findEndOfInputAnchor(tokenTypes) {\n    class EndAnchorFinder extends regexp_to_ast_1.BaseRegExpVisitor {\n        constructor() {\n            super(...arguments);\n            this.found = false;\n        }\n        visitEndAnchor(node) {\n            this.found = true;\n        }\n    }\n    const invalidRegex = (0, filter_1.default)(tokenTypes, (currType) => {\n        const pattern = currType.PATTERN;\n        try {\n            const regexpAst = (0, reg_exp_parser_1.getRegExpAst)(pattern);\n            const endAnchorVisitor = new EndAnchorFinder();\n            endAnchorVisitor.visit(regexpAst);\n            return endAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return end_of_input.test(pattern.source);\n        }\n    });\n    const errors = (0, map_1.default)(invalidRegex, (currType) => {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain end of input anchor '$'\\n\" +\n                \"\\tSee chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: lexer_public_1.LexerDefinitionErrorType.EOI_ANCHOR_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findEndOfInputAnchor = findEndOfInputAnchor;\nfunction findEmptyMatchRegExps(tokenTypes) {\n    const matchesEmptyString = (0, filter_1.default)(tokenTypes, (currType) => {\n        const pattern = currType.PATTERN;\n        return pattern.test(\"\");\n    });\n    const errors = (0, map_1.default)(matchesEmptyString, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' must not match an empty string\",\n            type: lexer_public_1.LexerDefinitionErrorType.EMPTY_MATCH_PATTERN,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findEmptyMatchRegExps = findEmptyMatchRegExps;\nconst start_of_input = /[^\\\\[][\\^]|^\\^/;\nfunction findStartOfInputAnchor(tokenTypes) {\n    class StartAnchorFinder extends regexp_to_ast_1.BaseRegExpVisitor {\n        constructor() {\n            super(...arguments);\n            this.found = false;\n        }\n        visitStartAnchor(node) {\n            this.found = true;\n        }\n    }\n    const invalidRegex = (0, filter_1.default)(tokenTypes, (currType) => {\n        const pattern = currType.PATTERN;\n        try {\n            const regexpAst = (0, reg_exp_parser_1.getRegExpAst)(pattern);\n            const startAnchorVisitor = new StartAnchorFinder();\n            startAnchorVisitor.visit(regexpAst);\n            return startAnchorVisitor.found;\n        }\n        catch (e) {\n            // old behavior in case of runtime exceptions with regexp-to-ast.\n            /* istanbul ignore next - cannot ensure an error in regexp-to-ast*/\n            return start_of_input.test(pattern.source);\n        }\n    });\n    const errors = (0, map_1.default)(invalidRegex, (currType) => {\n        return {\n            message: \"Unexpected RegExp Anchor Error:\\n\" +\n                \"\\tToken Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' cannot contain start of input anchor '^'\\n\" +\n                \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#ANCHORS\" +\n                \"\\tfor details.\",\n            type: lexer_public_1.LexerDefinitionErrorType.SOI_ANCHOR_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findStartOfInputAnchor = findStartOfInputAnchor;\nfunction findUnsupportedFlags(tokenTypes) {\n    const invalidFlags = (0, filter_1.default)(tokenTypes, (currType) => {\n        const pattern = currType[PATTERN];\n        return pattern instanceof RegExp && (pattern.multiline || pattern.global);\n    });\n    const errors = (0, map_1.default)(invalidFlags, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'PATTERN' may NOT contain global('g') or multiline('m')\",\n            type: lexer_public_1.LexerDefinitionErrorType.UNSUPPORTED_FLAGS_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findUnsupportedFlags = findUnsupportedFlags;\n// This can only test for identical duplicate RegExps, not semantically equivalent ones.\nfunction findDuplicatePatterns(tokenTypes) {\n    const found = [];\n    let identicalPatterns = (0, map_1.default)(tokenTypes, (outerType) => {\n        return (0, reduce_1.default)(tokenTypes, (result, innerType) => {\n            if (outerType.PATTERN.source === innerType.PATTERN.source &&\n                !(0, includes_1.default)(found, innerType) &&\n                innerType.PATTERN !== lexer_public_1.Lexer.NA) {\n                // this avoids duplicates in the result, each Token Type may only appear in one \"set\"\n                // in essence we are creating Equivalence classes on equality relation.\n                found.push(innerType);\n                result.push(innerType);\n                return result;\n            }\n            return result;\n        }, []);\n    });\n    identicalPatterns = (0, compact_1.default)(identicalPatterns);\n    const duplicatePatterns = (0, filter_1.default)(identicalPatterns, (currIdenticalSet) => {\n        return currIdenticalSet.length > 1;\n    });\n    const errors = (0, map_1.default)(duplicatePatterns, (setOfIdentical) => {\n        const tokenTypeNames = (0, map_1.default)(setOfIdentical, (currType) => {\n            return currType.name;\n        });\n        const dupPatternSrc = (0, first_1.default)(setOfIdentical).PATTERN;\n        return {\n            message: `The same RegExp pattern ->${dupPatternSrc}<-` +\n                `has been used in all of the following Token Types: ${tokenTypeNames.join(\", \")} <-`,\n            type: lexer_public_1.LexerDefinitionErrorType.DUPLICATE_PATTERNS_FOUND,\n            tokenTypes: setOfIdentical\n        };\n    });\n    return errors;\n}\nexports.findDuplicatePatterns = findDuplicatePatterns;\nfunction findInvalidGroupType(tokenTypes) {\n    const invalidTypes = (0, filter_1.default)(tokenTypes, (clazz) => {\n        if (!(0, has_1.default)(clazz, \"GROUP\")) {\n            return false;\n        }\n        const group = clazz.GROUP;\n        return group !== lexer_public_1.Lexer.SKIPPED && group !== lexer_public_1.Lexer.NA && !(0, isString_1.default)(group);\n    });\n    const errors = (0, map_1.default)(invalidTypes, (currType) => {\n        return {\n            message: \"Token Type: ->\" +\n                currType.name +\n                \"<- static 'GROUP' can only be Lexer.SKIPPED/Lexer.NA/A String\",\n            type: lexer_public_1.LexerDefinitionErrorType.INVALID_GROUP_TYPE_FOUND,\n            tokenTypes: [currType]\n        };\n    });\n    return errors;\n}\nexports.findInvalidGroupType = findInvalidGroupType;\nfunction findModesThatDoNotExist(tokenTypes, validModes) {\n    const invalidModes = (0, filter_1.default)(tokenTypes, (clazz) => {\n        return (clazz.PUSH_MODE !== undefined && !(0, includes_1.default)(validModes, clazz.PUSH_MODE));\n    });\n    const errors = (0, map_1.default)(invalidModes, (tokType) => {\n        const msg = `Token Type: ->${tokType.name}<- static 'PUSH_MODE' value cannot refer to a Lexer Mode ->${tokType.PUSH_MODE}<-` +\n            `which does not exist`;\n        return {\n            message: msg,\n            type: lexer_public_1.LexerDefinitionErrorType.PUSH_MODE_DOES_NOT_EXIST,\n            tokenTypes: [tokType]\n        };\n    });\n    return errors;\n}\nexports.findModesThatDoNotExist = findModesThatDoNotExist;\nfunction findUnreachablePatterns(tokenTypes) {\n    const errors = [];\n    const canBeTested = (0, reduce_1.default)(tokenTypes, (result, tokType, idx) => {\n        const pattern = tokType.PATTERN;\n        if (pattern === lexer_public_1.Lexer.NA) {\n            return result;\n        }\n        // a more comprehensive validation for all forms of regExps would require\n        // deeper regExp analysis capabilities\n        if ((0, isString_1.default)(pattern)) {\n            result.push({ str: pattern, idx, tokenType: tokType });\n        }\n        else if ((0, isRegExp_1.default)(pattern) && noMetaChar(pattern)) {\n            result.push({ str: pattern.source, idx, tokenType: tokType });\n        }\n        return result;\n    }, []);\n    (0, forEach_1.default)(tokenTypes, (tokType, testIdx) => {\n        (0, forEach_1.default)(canBeTested, ({ str, idx, tokenType }) => {\n            if (testIdx < idx && testTokenType(str, tokType.PATTERN)) {\n                const msg = `Token: ->${tokenType.name}<- can never be matched.\\n` +\n                    `Because it appears AFTER the Token Type ->${tokType.name}<-` +\n                    `in the lexer's definition.\\n` +\n                    `See https://chevrotain.io/docs/guide/resolving_lexer_errors.html#UNREACHABLE`;\n                errors.push({\n                    message: msg,\n                    type: lexer_public_1.LexerDefinitionErrorType.UNREACHABLE_PATTERN,\n                    tokenTypes: [tokType, tokenType]\n                });\n            }\n        });\n    });\n    return errors;\n}\nexports.findUnreachablePatterns = findUnreachablePatterns;\nfunction testTokenType(str, pattern) {\n    /* istanbul ignore else */\n    if ((0, isRegExp_1.default)(pattern)) {\n        const regExpArray = pattern.exec(str);\n        return regExpArray !== null && regExpArray.index === 0;\n    }\n    else if ((0, isFunction_1.default)(pattern)) {\n        // maintain the API of custom patterns\n        return pattern(str, 0, [], {});\n    }\n    else if ((0, has_1.default)(pattern, \"exec\")) {\n        // maintain the API of custom patterns\n        return pattern.exec(str, 0, [], {});\n    }\n    else if (typeof pattern === \"string\") {\n        return pattern === str;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nfunction noMetaChar(regExp) {\n    //https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp\n    const metaChars = [\n        \".\",\n        \"\\\\\",\n        \"[\",\n        \"]\",\n        \"|\",\n        \"^\",\n        \"$\",\n        \"(\",\n        \")\",\n        \"?\",\n        \"*\",\n        \"+\",\n        \"{\"\n    ];\n    return ((0, find_1.default)(metaChars, (char) => regExp.source.indexOf(char) !== -1) === undefined);\n}\nfunction addStartOfInput(pattern) {\n    const flags = pattern.ignoreCase ? \"i\" : \"\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(`^(?:${pattern.source})`, flags);\n}\nexports.addStartOfInput = addStartOfInput;\nfunction addStickyFlag(pattern) {\n    const flags = pattern.ignoreCase ? \"iy\" : \"y\";\n    // always wrapping in a none capturing group preceded by '^' to make sure matching can only work on start of input.\n    // duplicate/redundant start of input markers have no meaning (/^^^^A/ === /^A/)\n    return new RegExp(`${pattern.source}`, flags);\n}\nexports.addStickyFlag = addStickyFlag;\nfunction performRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    const errors = [];\n    // some run time checks to help the end users.\n    if (!(0, has_1.default)(lexerDefinition, exports.DEFAULT_MODE)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                exports.DEFAULT_MODE +\n                \"> property in its definition\\n\",\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\n        });\n    }\n    if (!(0, has_1.default)(lexerDefinition, exports.MODES)) {\n        errors.push({\n            message: \"A MultiMode Lexer cannot be initialized without a <\" +\n                exports.MODES +\n                \"> property in its definition\\n\",\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\n        });\n    }\n    if ((0, has_1.default)(lexerDefinition, exports.MODES) &&\n        (0, has_1.default)(lexerDefinition, exports.DEFAULT_MODE) &&\n        !(0, has_1.default)(lexerDefinition.modes, lexerDefinition.defaultMode)) {\n        errors.push({\n            message: `A MultiMode Lexer cannot be initialized with a ${exports.DEFAULT_MODE}: <${lexerDefinition.defaultMode}>` +\n                `which does not exist\\n`,\n            type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\n        });\n    }\n    if ((0, has_1.default)(lexerDefinition, exports.MODES)) {\n        (0, forEach_1.default)(lexerDefinition.modes, (currModeValue, currModeName) => {\n            (0, forEach_1.default)(currModeValue, (currTokType, currIdx) => {\n                if ((0, isUndefined_1.default)(currTokType)) {\n                    errors.push({\n                        message: `A Lexer cannot be initialized using an undefined Token Type. Mode:` +\n                            `<${currModeName}> at index: <${currIdx}>\\n`,\n                        type: lexer_public_1.LexerDefinitionErrorType.LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\n                    });\n                }\n                else if ((0, has_1.default)(currTokType, \"LONGER_ALT\")) {\n                    const longerAlt = (0, isArray_1.default)(currTokType.LONGER_ALT)\n                        ? currTokType.LONGER_ALT\n                        : [currTokType.LONGER_ALT];\n                    (0, forEach_1.default)(longerAlt, (currLongerAlt) => {\n                        if (!(0, isUndefined_1.default)(currLongerAlt) &&\n                            !(0, includes_1.default)(currModeValue, currLongerAlt)) {\n                            errors.push({\n                                message: `A MultiMode Lexer cannot be initialized with a longer_alt <${currLongerAlt.name}> on token <${currTokType.name}> outside of mode <${currModeName}>\\n`,\n                                type: lexer_public_1.LexerDefinitionErrorType.MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\n                            });\n                        }\n                    });\n                }\n            });\n        });\n    }\n    return errors;\n}\nexports.performRuntimeChecks = performRuntimeChecks;\nfunction performWarningRuntimeChecks(lexerDefinition, trackLines, lineTerminatorCharacters) {\n    const warnings = [];\n    let hasAnyLineBreak = false;\n    const allTokenTypes = (0, compact_1.default)((0, flatten_1.default)((0, values_1.default)(lexerDefinition.modes)));\n    const concreteTokenTypes = (0, reject_1.default)(allTokenTypes, (currType) => currType[PATTERN] === lexer_public_1.Lexer.NA);\n    const terminatorCharCodes = getCharCodes(lineTerminatorCharacters);\n    if (trackLines) {\n        (0, forEach_1.default)(concreteTokenTypes, (tokType) => {\n            const currIssue = checkLineBreaksIssues(tokType, terminatorCharCodes);\n            if (currIssue !== false) {\n                const message = buildLineBreakIssueMessage(tokType, currIssue);\n                const warningDescriptor = {\n                    message,\n                    type: currIssue.issue,\n                    tokenType: tokType\n                };\n                warnings.push(warningDescriptor);\n            }\n            else {\n                // we don't want to attempt to scan if the user explicitly specified the line_breaks option.\n                if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n                    if (tokType.LINE_BREAKS === true) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n                else {\n                    if ((0, reg_exp_1.canMatchCharCode)(terminatorCharCodes, tokType.PATTERN)) {\n                        hasAnyLineBreak = true;\n                    }\n                }\n            }\n        });\n    }\n    if (trackLines && !hasAnyLineBreak) {\n        warnings.push({\n            message: \"Warning: No LINE_BREAKS Found.\\n\" +\n                \"\\tThis Lexer has been defined to track line and column information,\\n\" +\n                \"\\tBut none of the Token Types can be identified as matching a line terminator.\\n\" +\n                \"\\tSee https://chevrotain.io/docs/guide/resolving_lexer_errors.html#LINE_BREAKS \\n\" +\n                \"\\tfor details.\",\n            type: lexer_public_1.LexerDefinitionErrorType.NO_LINE_BREAKS_FLAGS\n        });\n    }\n    return warnings;\n}\nexports.performWarningRuntimeChecks = performWarningRuntimeChecks;\nfunction cloneEmptyGroups(emptyGroups) {\n    const clonedResult = {};\n    const groupKeys = (0, keys_1.default)(emptyGroups);\n    (0, forEach_1.default)(groupKeys, (currKey) => {\n        const currGroupValue = emptyGroups[currKey];\n        /* istanbul ignore else */\n        if ((0, isArray_1.default)(currGroupValue)) {\n            clonedResult[currKey] = [];\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    });\n    return clonedResult;\n}\nexports.cloneEmptyGroups = cloneEmptyGroups;\n// TODO: refactor to avoid duplication\nfunction isCustomPattern(tokenType) {\n    const pattern = tokenType.PATTERN;\n    /* istanbul ignore else */\n    if ((0, isRegExp_1.default)(pattern)) {\n        return false;\n    }\n    else if ((0, isFunction_1.default)(pattern)) {\n        // CustomPatternMatcherFunc - custom patterns do not require any transformations, only wrapping in a RegExp Like object\n        return true;\n    }\n    else if ((0, has_1.default)(pattern, \"exec\")) {\n        // ICustomPattern\n        return true;\n    }\n    else if ((0, isString_1.default)(pattern)) {\n        return false;\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexports.isCustomPattern = isCustomPattern;\nfunction isShortPattern(pattern) {\n    if ((0, isString_1.default)(pattern) && pattern.length === 1) {\n        return pattern.charCodeAt(0);\n    }\n    else {\n        return false;\n    }\n}\nexports.isShortPattern = isShortPattern;\n/**\n * Faster than using a RegExp for default newline detection during lexing.\n */\nexports.LineTerminatorOptimizedTester = {\n    // implements /\\n|\\r\\n?/g.test\n    test: function (text) {\n        const len = text.length;\n        for (let i = this.lastIndex; i < len; i++) {\n            const c = text.charCodeAt(i);\n            if (c === 10) {\n                this.lastIndex = i + 1;\n                return true;\n            }\n            else if (c === 13) {\n                if (text.charCodeAt(i + 1) === 10) {\n                    this.lastIndex = i + 2;\n                }\n                else {\n                    this.lastIndex = i + 1;\n                }\n                return true;\n            }\n        }\n        return false;\n    },\n    lastIndex: 0\n};\nfunction checkLineBreaksIssues(tokType, lineTerminatorCharCodes) {\n    if ((0, has_1.default)(tokType, \"LINE_BREAKS\")) {\n        // if the user explicitly declared the line_breaks option we will respect their choice\n        // and assume it is correct.\n        return false;\n    }\n    else {\n        /* istanbul ignore else */\n        if ((0, isRegExp_1.default)(tokType.PATTERN)) {\n            try {\n                // TODO: why is the casting suddenly needed?\n                (0, reg_exp_1.canMatchCharCode)(lineTerminatorCharCodes, tokType.PATTERN);\n            }\n            catch (e) {\n                /* istanbul ignore next - to test this we would have to mock <canMatchCharCode> to throw an error */\n                return {\n                    issue: lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR,\n                    errMsg: e.message\n                };\n            }\n            return false;\n        }\n        else if ((0, isString_1.default)(tokType.PATTERN)) {\n            // string literal patterns can always be analyzed to detect line terminator usage\n            return false;\n        }\n        else if (isCustomPattern(tokType)) {\n            // custom token types\n            return { issue: lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK };\n        }\n        else {\n            throw Error(\"non exhaustive match\");\n        }\n    }\n}\nfunction buildLineBreakIssueMessage(tokType, details) {\n    /* istanbul ignore else */\n    if (details.issue === lexer_public_1.LexerDefinitionErrorType.IDENTIFY_TERMINATOR) {\n        return (\"Warning: unable to identify line terminator usage in pattern.\\n\" +\n            `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n            `\\t Root cause: ${details.errMsg}.\\n` +\n            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#IDENTIFY_TERMINATOR\");\n    }\n    else if (details.issue === lexer_public_1.LexerDefinitionErrorType.CUSTOM_LINE_BREAK) {\n        return (\"Warning: A Custom Token Pattern should specify the <line_breaks> option.\\n\" +\n            `\\tThe problem is in the <${tokType.name}> Token Type\\n` +\n            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#CUSTOM_LINE_BREAK\");\n    }\n    else {\n        throw Error(\"non exhaustive match\");\n    }\n}\nexports.buildLineBreakIssueMessage = buildLineBreakIssueMessage;\nfunction getCharCodes(charsOrCodes) {\n    const charCodes = (0, map_1.default)(charsOrCodes, (numOrString) => {\n        if ((0, isString_1.default)(numOrString)) {\n            return numOrString.charCodeAt(0);\n        }\n        else {\n            return numOrString;\n        }\n    });\n    return charCodes;\n}\nfunction addToMapOfArrays(map, key, value) {\n    if (map[key] === undefined) {\n        map[key] = [value];\n    }\n    else {\n        map[key].push(value);\n    }\n}\nexports.minOptimizationVal = 256;\n/**\n * We are mapping charCode above ASCI (256) into buckets each in the size of 256.\n * This is because ASCI are the most common start chars so each one of those will get its own\n * possible token configs vector.\n *\n * Tokens starting with charCodes \"above\" ASCI are uncommon, so we can \"afford\"\n * to place these into buckets of possible token configs, What we gain from\n * this is avoiding the case of creating an optimization 'charCodeToPatternIdxToConfig'\n * which would contain 10,000+ arrays of small size (e.g unicode Identifiers scenario).\n * Our 'charCodeToPatternIdxToConfig' max size will now be:\n * 256 + (2^16 / 2^8) - 1 === 511\n *\n * note the hack for fast division integer part extraction\n * See: https://stackoverflow.com/a/4228528\n */\nlet charCodeToOptimizedIdxMap = [];\nfunction charCodeToOptimizedIndex(charCode) {\n    return charCode < exports.minOptimizationVal\n        ? charCode\n        : charCodeToOptimizedIdxMap[charCode];\n}\nexports.charCodeToOptimizedIndex = charCodeToOptimizedIndex;\n/**\n * This is a compromise between cold start / hot running performance\n * Creating this array takes ~3ms on a modern machine,\n * But if we perform the computation at runtime as needed the CSS Lexer benchmark\n * performance degrades by ~10%\n *\n * TODO: Perhaps it should be lazy initialized only if a charCode > 255 is used.\n */\nfunction initCharCodeToOptimizedIndexMap() {\n    if ((0, isEmpty_1.default)(charCodeToOptimizedIdxMap)) {\n        charCodeToOptimizedIdxMap = new Array(65536);\n        for (let i = 0; i < 65536; i++) {\n            charCodeToOptimizedIdxMap[i] = i > 255 ? 255 + ~~(i / 255) : i;\n        }\n    }\n}\n//# sourceMappingURL=lexer.js.map"]},"metadata":{},"sourceType":"script"}