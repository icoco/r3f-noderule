{"ast":null,"code":"\"use strict\";\n\nvar __importDefault = this && this.__importDefault || function (mod) {\n  return mod && mod.__esModule ? mod : {\n    \"default\": mod\n  };\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Lexer = exports.LexerDefinitionErrorType = void 0;\n\nconst lexer_1 = require(\"./lexer\");\n\nconst noop_1 = __importDefault(require(\"lodash/noop\"));\n\nconst isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\n\nconst isArray_1 = __importDefault(require(\"lodash/isArray\"));\n\nconst last_1 = __importDefault(require(\"lodash/last\"));\n\nconst reject_1 = __importDefault(require(\"lodash/reject\"));\n\nconst map_1 = __importDefault(require(\"lodash/map\"));\n\nconst forEach_1 = __importDefault(require(\"lodash/forEach\"));\n\nconst keys_1 = __importDefault(require(\"lodash/keys\"));\n\nconst isUndefined_1 = __importDefault(require(\"lodash/isUndefined\"));\n\nconst identity_1 = __importDefault(require(\"lodash/identity\"));\n\nconst assign_1 = __importDefault(require(\"lodash/assign\"));\n\nconst reduce_1 = __importDefault(require(\"lodash/reduce\"));\n\nconst clone_1 = __importDefault(require(\"lodash/clone\"));\n\nconst utils_1 = require(\"@chevrotain/utils\");\n\nconst tokens_1 = require(\"./tokens\");\n\nconst lexer_errors_public_1 = require(\"./lexer_errors_public\");\n\nconst reg_exp_parser_1 = require(\"./reg_exp_parser\");\n\nvar LexerDefinitionErrorType;\n\n(function (LexerDefinitionErrorType) {\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MISSING_PATTERN\"] = 0] = \"MISSING_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_PATTERN\"] = 1] = \"INVALID_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"EOI_ANCHOR_FOUND\"] = 2] = \"EOI_ANCHOR_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNSUPPORTED_FLAGS_FOUND\"] = 3] = \"UNSUPPORTED_FLAGS_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"DUPLICATE_PATTERNS_FOUND\"] = 4] = \"DUPLICATE_PATTERNS_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_GROUP_TYPE_FOUND\"] = 5] = \"INVALID_GROUP_TYPE_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"PUSH_MODE_DOES_NOT_EXIST\"] = 6] = \"PUSH_MODE_DOES_NOT_EXIST\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\"] = 7] = \"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\"] = 8] = \"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\"] = 9] = \"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\"] = 10] = \"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"SOI_ANCHOR_FOUND\"] = 11] = \"SOI_ANCHOR_FOUND\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"EMPTY_MATCH_PATTERN\"] = 12] = \"EMPTY_MATCH_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"NO_LINE_BREAKS_FLAGS\"] = 13] = \"NO_LINE_BREAKS_FLAGS\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNREACHABLE_PATTERN\"] = 14] = \"UNREACHABLE_PATTERN\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"IDENTIFY_TERMINATOR\"] = 15] = \"IDENTIFY_TERMINATOR\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"CUSTOM_LINE_BREAK\"] = 16] = \"CUSTOM_LINE_BREAK\";\n  LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\"] = 17] = \"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\";\n})(LexerDefinitionErrorType = exports.LexerDefinitionErrorType || (exports.LexerDefinitionErrorType = {}));\n\nconst DEFAULT_LEXER_CONFIG = {\n  deferDefinitionErrorsHandling: false,\n  positionTracking: \"full\",\n  lineTerminatorsPattern: /\\n|\\r\\n?/g,\n  lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n  ensureOptimizations: false,\n  safeMode: false,\n  errorMessageProvider: lexer_errors_public_1.defaultLexerErrorProvider,\n  traceInitPerf: false,\n  skipValidations: false,\n  recoveryEnabled: true\n};\nObject.freeze(DEFAULT_LEXER_CONFIG);\n\nclass Lexer {\n  constructor(lexerDefinition, config = DEFAULT_LEXER_CONFIG) {\n    this.lexerDefinition = lexerDefinition;\n    this.lexerDefinitionErrors = [];\n    this.lexerDefinitionWarning = [];\n    this.patternIdxToConfig = {};\n    this.charCodeToPatternIdxToConfig = {};\n    this.modes = [];\n    this.emptyGroups = {};\n    this.trackStartLines = true;\n    this.trackEndLines = true;\n    this.hasCustom = false;\n    this.canModeBeOptimized = {}; // Duplicated from the parser's perf trace trait to allow future extraction\n    // of the lexer to a separate package.\n\n    this.TRACE_INIT = (phaseDesc, phaseImpl) => {\n      // No need to optimize this using NOOP pattern because\n      // It is not called in a hot spot...\n      if (this.traceInitPerf === true) {\n        this.traceInitIndent++;\n        const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n\n        if (this.traceInitIndent < this.traceInitMaxIdent) {\n          console.log(`${indent}--> <${phaseDesc}>`);\n        }\n\n        const {\n          time,\n          value\n        } = (0, utils_1.timer)(phaseImpl);\n        /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n\n        const traceMethod = time > 10 ? console.warn : console.log;\n\n        if (this.traceInitIndent < this.traceInitMaxIdent) {\n          traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n        }\n\n        this.traceInitIndent--;\n        return value;\n      } else {\n        return phaseImpl();\n      }\n    };\n\n    if (typeof config === \"boolean\") {\n      throw Error(\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" + \"a boolean 2nd argument is no longer supported\");\n    } // todo: defaults func?\n\n\n    this.config = (0, assign_1.default)({}, DEFAULT_LEXER_CONFIG, config);\n    const traceInitVal = this.config.traceInitPerf;\n\n    if (traceInitVal === true) {\n      this.traceInitMaxIdent = Infinity;\n      this.traceInitPerf = true;\n    } else if (typeof traceInitVal === \"number\") {\n      this.traceInitMaxIdent = traceInitVal;\n      this.traceInitPerf = true;\n    }\n\n    this.traceInitIndent = -1;\n    this.TRACE_INIT(\"Lexer Constructor\", () => {\n      let actualDefinition;\n      let hasOnlySingleMode = true;\n      this.TRACE_INIT(\"Lexer Config handling\", () => {\n        if (this.config.lineTerminatorsPattern === DEFAULT_LEXER_CONFIG.lineTerminatorsPattern) {\n          // optimized built-in implementation for the defaults definition of lineTerminators\n          this.config.lineTerminatorsPattern = lexer_1.LineTerminatorOptimizedTester;\n        } else {\n          if (this.config.lineTerminatorCharacters === DEFAULT_LEXER_CONFIG.lineTerminatorCharacters) {\n            throw Error(\"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" + \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\");\n          }\n        }\n\n        if (config.safeMode && config.ensureOptimizations) {\n          throw Error('\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.');\n        }\n\n        this.trackStartLines = /full|onlyStart/i.test(this.config.positionTracking);\n        this.trackEndLines = /full/i.test(this.config.positionTracking); // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n\n        if ((0, isArray_1.default)(lexerDefinition)) {\n          actualDefinition = {\n            modes: {\n              defaultMode: (0, clone_1.default)(lexerDefinition)\n            },\n            defaultMode: lexer_1.DEFAULT_MODE\n          };\n        } else {\n          // no conversion needed, input should already be a IMultiModeLexerDefinition\n          hasOnlySingleMode = false;\n          actualDefinition = (0, clone_1.default)(lexerDefinition);\n        }\n      });\n\n      if (this.config.skipValidations === false) {\n        this.TRACE_INIT(\"performRuntimeChecks\", () => {\n          this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat((0, lexer_1.performRuntimeChecks)(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n        });\n        this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n          this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat((0, lexer_1.performWarningRuntimeChecks)(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n        });\n      } // for extra robustness to avoid throwing an none informative error message\n\n\n      actualDefinition.modes = actualDefinition.modes ? actualDefinition.modes : {}; // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n      // this transformation is to increase robustness in the case of partially invalid lexer definition.\n\n      (0, forEach_1.default)(actualDefinition.modes, (currModeValue, currModeName) => {\n        actualDefinition.modes[currModeName] = (0, reject_1.default)(currModeValue, currTokType => (0, isUndefined_1.default)(currTokType));\n      });\n      const allModeNames = (0, keys_1.default)(actualDefinition.modes);\n      (0, forEach_1.default)(actualDefinition.modes, (currModDef, currModName) => {\n        this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n          this.modes.push(currModName);\n\n          if (this.config.skipValidations === false) {\n            this.TRACE_INIT(`validatePatterns`, () => {\n              this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat((0, lexer_1.validatePatterns)(currModDef, allModeNames));\n            });\n          } // If definition errors were encountered, the analysis phase may fail unexpectedly/\n          // Considering a lexer with definition errors may never be used, there is no point\n          // to performing the analysis anyhow...\n\n\n          if ((0, isEmpty_1.default)(this.lexerDefinitionErrors)) {\n            (0, tokens_1.augmentTokenTypes)(currModDef);\n            let currAnalyzeResult;\n            this.TRACE_INIT(`analyzeTokenTypes`, () => {\n              currAnalyzeResult = (0, lexer_1.analyzeTokenTypes)(currModDef, {\n                lineTerminatorCharacters: this.config.lineTerminatorCharacters,\n                positionTracking: config.positionTracking,\n                ensureOptimizations: config.ensureOptimizations,\n                safeMode: config.safeMode,\n                tracer: this.TRACE_INIT\n              });\n            });\n            this.patternIdxToConfig[currModName] = currAnalyzeResult.patternIdxToConfig;\n            this.charCodeToPatternIdxToConfig[currModName] = currAnalyzeResult.charCodeToPatternIdxToConfig;\n            this.emptyGroups = (0, assign_1.default)({}, this.emptyGroups, currAnalyzeResult.emptyGroups);\n            this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom;\n            this.canModeBeOptimized[currModName] = currAnalyzeResult.canBeOptimized;\n          }\n        });\n      });\n      this.defaultMode = actualDefinition.defaultMode;\n\n      if (!(0, isEmpty_1.default)(this.lexerDefinitionErrors) && !this.config.deferDefinitionErrorsHandling) {\n        const allErrMessages = (0, map_1.default)(this.lexerDefinitionErrors, error => {\n          return error.message;\n        });\n        const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n        throw new Error(\"Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n      } // Only print warning if there are no errors, This will avoid pl\n\n\n      (0, forEach_1.default)(this.lexerDefinitionWarning, warningDescriptor => {\n        (0, utils_1.PRINT_WARNING)(warningDescriptor.message);\n      });\n      this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n        // Choose the relevant internal implementations for this specific parser.\n        // These implementations should be in-lined by the JavaScript engine\n        // to provide optimal performance in each scenario.\n        if (lexer_1.SUPPORT_STICKY) {\n          this.chopInput = identity_1.default;\n          this.match = this.matchWithTest;\n        } else {\n          this.updateLastIndex = noop_1.default;\n          this.match = this.matchWithExec;\n        }\n\n        if (hasOnlySingleMode) {\n          this.handleModes = noop_1.default;\n        }\n\n        if (this.trackStartLines === false) {\n          this.computeNewColumn = identity_1.default;\n        }\n\n        if (this.trackEndLines === false) {\n          this.updateTokenEndLineColumnLocation = noop_1.default;\n        }\n\n        if (/full/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createFullToken;\n        } else if (/onlyStart/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createStartOnlyToken;\n        } else if (/onlyOffset/i.test(this.config.positionTracking)) {\n          this.createTokenInstance = this.createOffsetOnlyToken;\n        } else {\n          throw Error(`Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`);\n        }\n\n        if (this.hasCustom) {\n          this.addToken = this.addTokenUsingPush;\n          this.handlePayload = this.handlePayloadWithCustom;\n        } else {\n          this.addToken = this.addTokenUsingMemberAccess;\n          this.handlePayload = this.handlePayloadNoCustom;\n        }\n      });\n      this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n        const unOptimizedModes = (0, reduce_1.default)(this.canModeBeOptimized, (cannotBeOptimized, canBeOptimized, modeName) => {\n          if (canBeOptimized === false) {\n            cannotBeOptimized.push(modeName);\n          }\n\n          return cannotBeOptimized;\n        }, []);\n\n        if (config.ensureOptimizations && !(0, isEmpty_1.default)(unOptimizedModes)) {\n          throw Error(`Lexer Modes: < ${unOptimizedModes.join(\", \")} > cannot be optimized.\\n` + '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' + \"\\t Or inspect the console log for details on how to resolve these issues.\");\n        }\n      });\n      this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n        (0, reg_exp_parser_1.clearRegExpParserCache)();\n      });\n      this.TRACE_INIT(\"toFastProperties\", () => {\n        (0, utils_1.toFastProperties)(this);\n      });\n    });\n  }\n\n  tokenize(text, initialMode = this.defaultMode) {\n    if (!(0, isEmpty_1.default)(this.lexerDefinitionErrors)) {\n      const allErrMessages = (0, map_1.default)(this.lexerDefinitionErrors, error => {\n        return error.message;\n      });\n      const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n      throw new Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n    }\n\n    return this.tokenizeInternal(text, initialMode);\n  } // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n  // This is intentional due to performance considerations.\n  // this method also used quite a bit of `!` none null assertions because it is too optimized\n  // for `tsc` to always understand it is \"safe\"\n\n\n  tokenizeInternal(text, initialMode) {\n    let i, j, k, matchAltImage, longerAlt, matchedImage, payload, altPayload, imageLength, group, tokType, newToken, errLength, droppedChar, msg, match;\n    const orgText = text;\n    const orgLength = orgText.length;\n    let offset = 0;\n    let matchedTokensIndex = 0; // initializing the tokensArray to the \"guessed\" size.\n    // guessing too little will still reduce the number of array re-sizes on pushes.\n    // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n    // but would still have a faster runtime by avoiding (All but one) array resizing.\n\n    const guessedNumberOfTokens = this.hasCustom ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n    : Math.floor(text.length / 10);\n    const matchedTokens = new Array(guessedNumberOfTokens);\n    const errors = [];\n    let line = this.trackStartLines ? 1 : undefined;\n    let column = this.trackStartLines ? 1 : undefined;\n    const groups = (0, lexer_1.cloneEmptyGroups)(this.emptyGroups);\n    const trackLines = this.trackStartLines;\n    const lineTerminatorPattern = this.config.lineTerminatorsPattern;\n    let currModePatternsLength = 0;\n    let patternIdxToConfig = [];\n    let currCharCodeToPatternIdxToConfig = [];\n    const modeStack = [];\n    const emptyArray = [];\n    Object.freeze(emptyArray);\n    let getPossiblePatterns;\n\n    function getPossiblePatternsSlow() {\n      return patternIdxToConfig;\n    }\n\n    function getPossiblePatternsOptimized(charCode) {\n      const optimizedCharIdx = (0, lexer_1.charCodeToOptimizedIndex)(charCode);\n      const possiblePatterns = currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n\n      if (possiblePatterns === undefined) {\n        return emptyArray;\n      } else {\n        return possiblePatterns;\n      }\n    }\n\n    const pop_mode = popToken => {\n      // TODO: perhaps avoid this error in the edge case there is no more input?\n      if (modeStack.length === 1 && // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n      // So no error should occur.\n      popToken.tokenType.PUSH_MODE === undefined) {\n        // if we try to pop the last mode there lexer will no longer have ANY mode.\n        // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n        const msg = this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);\n        errors.push({\n          offset: popToken.startOffset,\n          line: popToken.startLine,\n          column: popToken.startColumn,\n          length: popToken.image.length,\n          message: msg\n        });\n      } else {\n        modeStack.pop();\n        const newMode = (0, last_1.default)(modeStack);\n        patternIdxToConfig = this.patternIdxToConfig[newMode];\n        currCharCodeToPatternIdxToConfig = this.charCodeToPatternIdxToConfig[newMode];\n        currModePatternsLength = patternIdxToConfig.length;\n        const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n\n        if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n          getPossiblePatterns = getPossiblePatternsOptimized;\n        } else {\n          getPossiblePatterns = getPossiblePatternsSlow;\n        }\n      }\n    };\n\n    function push_mode(newMode) {\n      modeStack.push(newMode);\n      currCharCodeToPatternIdxToConfig = this.charCodeToPatternIdxToConfig[newMode];\n      patternIdxToConfig = this.patternIdxToConfig[newMode];\n      currModePatternsLength = patternIdxToConfig.length;\n      currModePatternsLength = patternIdxToConfig.length;\n      const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n\n      if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n        getPossiblePatterns = getPossiblePatternsOptimized;\n      } else {\n        getPossiblePatterns = getPossiblePatternsSlow;\n      }\n    } // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n    // seem to matter performance wise.\n\n\n    push_mode.call(this, initialMode);\n    let currConfig;\n    const recoveryEnabled = this.config.recoveryEnabled;\n\n    while (offset < orgLength) {\n      matchedImage = null;\n      const nextCharCode = orgText.charCodeAt(offset);\n      const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n      const chosenPatternsLength = chosenPatternIdxToConfig.length;\n\n      for (i = 0; i < chosenPatternsLength; i++) {\n        currConfig = chosenPatternIdxToConfig[i];\n        const currPattern = currConfig.pattern;\n        payload = null; // manually in-lined because > 600 chars won't be in-lined in V8\n\n        const singleCharCode = currConfig.short;\n\n        if (singleCharCode !== false) {\n          if (nextCharCode === singleCharCode) {\n            // single character string\n            matchedImage = currPattern;\n          }\n        } else if (currConfig.isCustom === true) {\n          match = currPattern.exec(orgText, offset, matchedTokens, groups);\n\n          if (match !== null) {\n            matchedImage = match[0];\n\n            if (match.payload !== undefined) {\n              payload = match.payload;\n            }\n          } else {\n            matchedImage = null;\n          }\n        } else {\n          this.updateLastIndex(currPattern, offset);\n          matchedImage = this.match(currPattern, text, offset);\n        }\n\n        if (matchedImage !== null) {\n          // even though this pattern matched we must try a another longer alternative.\n          // this can be used to prioritize keywords over identifiers\n          longerAlt = currConfig.longerAlt;\n\n          if (longerAlt !== undefined) {\n            // TODO: micro optimize, avoid extra prop access\n            // by saving/linking longerAlt on the original config?\n            const longerAltLength = longerAlt.length;\n\n            for (k = 0; k < longerAltLength; k++) {\n              const longerAltConfig = patternIdxToConfig[longerAlt[k]];\n              const longerAltPattern = longerAltConfig.pattern;\n              altPayload = null; // single Char can never be a longer alt so no need to test it.\n              // manually in-lined because > 600 chars won't be in-lined in V8\n\n              if (longerAltConfig.isCustom === true) {\n                match = longerAltPattern.exec(orgText, offset, matchedTokens, groups);\n\n                if (match !== null) {\n                  matchAltImage = match[0];\n\n                  if (match.payload !== undefined) {\n                    altPayload = match.payload;\n                  }\n                } else {\n                  matchAltImage = null;\n                }\n              } else {\n                this.updateLastIndex(longerAltPattern, offset);\n                matchAltImage = this.match(longerAltPattern, text, offset);\n              }\n\n              if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                matchedImage = matchAltImage;\n                payload = altPayload;\n                currConfig = longerAltConfig; // Exit the loop early after matching one of the longer alternatives\n                // The first matched alternative takes precedence\n\n                break;\n              }\n            }\n          }\n\n          break;\n        }\n      } // successful match\n\n\n      if (matchedImage !== null) {\n        imageLength = matchedImage.length;\n        group = currConfig.group;\n\n        if (group !== undefined) {\n          tokType = currConfig.tokenTypeIdx; // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n          // createFullToken method\n\n          newToken = this.createTokenInstance(matchedImage, offset, tokType, currConfig.tokenType, line, column, imageLength);\n          this.handlePayload(newToken, payload); // TODO: optimize NOOP in case there are no special groups?\n\n          if (group === false) {\n            matchedTokensIndex = this.addToken(matchedTokens, matchedTokensIndex, newToken);\n          } else {\n            groups[group].push(newToken);\n          }\n        }\n\n        text = this.chopInput(text, imageLength);\n        offset = offset + imageLength; // TODO: with newlines the column may be assigned twice\n\n        column = this.computeNewColumn(column, imageLength);\n\n        if (trackLines === true && currConfig.canLineTerminator === true) {\n          let numOfLTsInMatch = 0;\n          let foundTerminator;\n          let lastLTEndOffset;\n          lineTerminatorPattern.lastIndex = 0;\n\n          do {\n            foundTerminator = lineTerminatorPattern.test(matchedImage);\n\n            if (foundTerminator === true) {\n              lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n              numOfLTsInMatch++;\n            }\n          } while (foundTerminator === true);\n\n          if (numOfLTsInMatch !== 0) {\n            line = line + numOfLTsInMatch;\n            column = imageLength - lastLTEndOffset;\n            this.updateTokenEndLineColumnLocation(newToken, group, lastLTEndOffset, numOfLTsInMatch, line, column, imageLength);\n          }\n        } // will be NOOP if no modes present\n\n\n        this.handleModes(currConfig, pop_mode, push_mode, newToken);\n      } else {\n        // error recovery, drop characters until we identify a valid token's start point\n        const errorStartOffset = offset;\n        const errorLine = line;\n        const errorColumn = column;\n        let foundResyncPoint = recoveryEnabled === false;\n\n        while (foundResyncPoint === false && offset < orgLength) {\n          // Identity Func (when sticky flag is enabled)\n          text = this.chopInput(text, 1);\n          offset++;\n\n          for (j = 0; j < currModePatternsLength; j++) {\n            const currConfig = patternIdxToConfig[j];\n            const currPattern = currConfig.pattern; // manually in-lined because > 600 chars won't be in-lined in V8\n\n            const singleCharCode = currConfig.short;\n\n            if (singleCharCode !== false) {\n              if (orgText.charCodeAt(offset) === singleCharCode) {\n                // single character string\n                foundResyncPoint = true;\n              }\n            } else if (currConfig.isCustom === true) {\n              foundResyncPoint = currPattern.exec(orgText, offset, matchedTokens, groups) !== null;\n            } else {\n              this.updateLastIndex(currPattern, offset);\n              foundResyncPoint = currPattern.exec(text) !== null;\n            }\n\n            if (foundResyncPoint === true) {\n              break;\n            }\n          }\n        }\n\n        errLength = offset - errorStartOffset; // at this point we either re-synced or reached the end of the input text\n\n        msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText, errorStartOffset, errLength, errorLine, errorColumn);\n        errors.push({\n          offset: errorStartOffset,\n          line: errorLine,\n          column: errorColumn,\n          length: errLength,\n          message: msg\n        });\n\n        if (recoveryEnabled === false) {\n          break;\n        }\n      }\n    } // if we do have custom patterns which push directly into the\n    // TODO: custom tokens should not push directly??\n\n\n    if (!this.hasCustom) {\n      // if we guessed a too large size for the tokens array this will shrink it to the right size.\n      matchedTokens.length = matchedTokensIndex;\n    }\n\n    return {\n      tokens: matchedTokens,\n      groups: groups,\n      errors: errors\n    };\n  }\n\n  handleModes(config, pop_mode, push_mode, newToken) {\n    if (config.pop === true) {\n      // need to save the PUSH_MODE property as if the mode is popped\n      // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n      const pushMode = config.push;\n      pop_mode(newToken);\n\n      if (pushMode !== undefined) {\n        push_mode.call(this, pushMode);\n      }\n    } else if (config.push !== undefined) {\n      push_mode.call(this, config.push);\n    }\n  }\n\n  chopInput(text, length) {\n    return text.substring(length);\n  }\n\n  updateLastIndex(regExp, newLastIndex) {\n    regExp.lastIndex = newLastIndex;\n  } // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n\n\n  updateTokenEndLineColumnLocation(newToken, group, lastLTIdx, numOfLTsInMatch, line, column, imageLength) {\n    let lastCharIsLT, fixForEndingInLT;\n\n    if (group !== undefined) {\n      // a none skipped multi line Token, need to update endLine/endColumn\n      lastCharIsLT = lastLTIdx === imageLength - 1;\n      fixForEndingInLT = lastCharIsLT ? -1 : 0;\n\n      if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n        // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n        newToken.endLine = line + fixForEndingInLT; // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n        // inclusive to exclusive range.\n\n        newToken.endColumn = column - 1 + -fixForEndingInLT;\n      } // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n\n    }\n  }\n\n  computeNewColumn(oldColumn, imageLength) {\n    return oldColumn + imageLength;\n  }\n\n  createOffsetOnlyToken(image, startOffset, tokenTypeIdx, tokenType) {\n    return {\n      image,\n      startOffset,\n      tokenTypeIdx,\n      tokenType\n    };\n  }\n\n  createStartOnlyToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn) {\n    return {\n      image,\n      startOffset,\n      startLine,\n      startColumn,\n      tokenTypeIdx,\n      tokenType\n    };\n  }\n\n  createFullToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn, imageLength) {\n    return {\n      image,\n      startOffset,\n      endOffset: startOffset + imageLength - 1,\n      startLine,\n      endLine: startLine,\n      startColumn,\n      endColumn: startColumn + imageLength - 1,\n      tokenTypeIdx,\n      tokenType\n    };\n  }\n\n  addTokenUsingPush(tokenVector, index, tokenToAdd) {\n    tokenVector.push(tokenToAdd);\n    return index;\n  }\n\n  addTokenUsingMemberAccess(tokenVector, index, tokenToAdd) {\n    tokenVector[index] = tokenToAdd;\n    index++;\n    return index;\n  }\n\n  handlePayloadNoCustom(token, payload) {}\n\n  handlePayloadWithCustom(token, payload) {\n    if (payload !== null) {\n      token.payload = payload;\n    }\n  }\n\n  matchWithTest(pattern, text, offset) {\n    const found = pattern.test(text);\n\n    if (found === true) {\n      return text.substring(offset, pattern.lastIndex);\n    }\n\n    return null;\n  }\n\n  matchWithExec(pattern, text) {\n    const regExpArray = pattern.exec(text);\n    return regExpArray !== null ? regExpArray[0] : null;\n  }\n\n}\n\nexports.Lexer = Lexer;\nLexer.SKIPPED = \"This marks a skipped Token pattern, this means each token identified by it will\" + \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\nLexer.NA = /NOT_APPLICABLE/;","map":{"version":3,"sources":["../../../src/scan/lexer_public.ts"],"names":[],"mappings":";;;;;;;;;;;;;AAAA,MAAA,OAAA,GAAA,OAAA,CAAA,SAAA,CAAA;;AAaA,MAAA,MAAA,GAAA,eAAA,CAAA,OAAA,CAAA,aAAA,CAAA,CAAA;;AACA,MAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,MAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,MAAA,MAAA,GAAA,eAAA,CAAA,OAAA,CAAA,aAAA,CAAA,CAAA;;AACA,MAAA,QAAA,GAAA,eAAA,CAAA,OAAA,CAAA,eAAA,CAAA,CAAA;;AACA,MAAA,KAAA,GAAA,eAAA,CAAA,OAAA,CAAA,YAAA,CAAA,CAAA;;AACA,MAAA,SAAA,GAAA,eAAA,CAAA,OAAA,CAAA,gBAAA,CAAA,CAAA;;AACA,MAAA,MAAA,GAAA,eAAA,CAAA,OAAA,CAAA,aAAA,CAAA,CAAA;;AACA,MAAA,aAAA,GAAA,eAAA,CAAA,OAAA,CAAA,oBAAA,CAAA,CAAA;;AACA,MAAA,UAAA,GAAA,eAAA,CAAA,OAAA,CAAA,iBAAA,CAAA,CAAA;;AACA,MAAA,QAAA,GAAA,eAAA,CAAA,OAAA,CAAA,eAAA,CAAA,CAAA;;AACA,MAAA,QAAA,GAAA,eAAA,CAAA,OAAA,CAAA,eAAA,CAAA,CAAA;;AACA,MAAA,OAAA,GAAA,eAAA,CAAA,OAAA,CAAA,cAAA,CAAA,CAAA;;AACA,MAAA,OAAA,GAAA,OAAA,CAAA,mBAAA,CAAA;;AACA,MAAA,QAAA,GAAA,OAAA,CAAA,UAAA,CAAA;;AAWA,MAAA,qBAAA,GAAA,OAAA,CAAA,uBAAA,CAAA;;AACA,MAAA,gBAAA,GAAA,OAAA,CAAA,kBAAA,CAAA;;AAQA,IAAY,wBAAZ;;AAAA,CAAA,UAAY,wBAAZ,EAAoC;AAClC,EAAA,wBAAA,CAAA,wBAAA,CAAA,iBAAA,CAAA,GAAA,CAAA,CAAA,GAAA,iBAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,iBAAA,CAAA,GAAA,CAAA,CAAA,GAAA,iBAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,kBAAA,CAAA,GAAA,CAAA,CAAA,GAAA,kBAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,yBAAA,CAAA,GAAA,CAAA,CAAA,GAAA,yBAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,0BAAA,CAAA,GAAA,CAAA,CAAA,GAAA,0BAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,0BAAA,CAAA,GAAA,CAAA,CAAA,GAAA,0BAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,0BAAA,CAAA,GAAA,CAAA,CAAA,GAAA,0BAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,uCAAA,CAAA,GAAA,CAAA,CAAA,GAAA,uCAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,yCAAA,CAAA,GAAA,CAAA,CAAA,GAAA,yCAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,oDAAA,CAAA,GAAA,CAAA,CAAA,GAAA,oDAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,2CAAA,CAAA,GAAA,EAAA,CAAA,GAAA,2CAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,kBAAA,CAAA,GAAA,EAAA,CAAA,GAAA,kBAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,qBAAA,CAAA,GAAA,EAAA,CAAA,GAAA,qBAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,sBAAA,CAAA,GAAA,EAAA,CAAA,GAAA,sBAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,qBAAA,CAAA,GAAA,EAAA,CAAA,GAAA,qBAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,qBAAA,CAAA,GAAA,EAAA,CAAA,GAAA,qBAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,mBAAA,CAAA,GAAA,EAAA,CAAA,GAAA,mBAAA;AACA,EAAA,wBAAA,CAAA,wBAAA,CAAA,iDAAA,CAAA,GAAA,EAAA,CAAA,GAAA,iDAAA;AACD,CAnBD,EAAY,wBAAwB,GAAxB,OAAA,CAAA,wBAAA,KAAA,OAAA,CAAA,wBAAA,GAAwB,EAAxB,CAAZ;;AAyBA,MAAM,oBAAoB,GAA2B;AACnD,EAAA,6BAA6B,EAAE,KADoB;AAEnD,EAAA,gBAAgB,EAAE,MAFiC;AAGnD,EAAA,sBAAsB,EAAE,WAH2B;AAInD,EAAA,wBAAwB,EAAE,CAAC,IAAD,EAAO,IAAP,CAJyB;AAKnD,EAAA,mBAAmB,EAAE,KAL8B;AAMnD,EAAA,QAAQ,EAAE,KANyC;AAOnD,EAAA,oBAAoB,EAAE,qBAAA,CAAA,yBAP6B;AAQnD,EAAA,aAAa,EAAE,KARoC;AASnD,EAAA,eAAe,EAAE,KATkC;AAUnD,EAAA,eAAe,EAAE;AAVkC,CAArD;AAaA,MAAM,CAAC,MAAP,CAAc,oBAAd;;AAEA,MAAa,KAAb,CAAkB;AA4BhB,EAAA,WAAA,CACY,eADZ,EAEE,MAAA,GAAuB,oBAFzB,EAE6C;AADjC,SAAA,eAAA,GAAA,eAAA;AAvBL,SAAA,qBAAA,GAAiD,EAAjD;AACA,SAAA,sBAAA,GAAkD,EAAlD;AAEG,SAAA,kBAAA,GAAuD,EAAvD;AACA,SAAA,4BAAA,GAEN,EAFM;AAIA,SAAA,KAAA,GAAkB,EAAlB;AAEA,SAAA,WAAA,GAA+C,EAA/C;AAGF,SAAA,eAAA,GAA2B,IAA3B;AACA,SAAA,aAAA,GAAyB,IAAzB;AACA,SAAA,SAAA,GAAqB,KAArB;AACA,SAAA,kBAAA,GAA8C,EAA9C,CAQqC,CA4zB7C;AACA;;AACA,SAAA,UAAA,GAAa,CAAI,SAAJ,EAAuB,SAAvB,KAAgD;AAC3D;AACA;AACA,UAAI,KAAK,aAAL,KAAuB,IAA3B,EAAiC;AAC/B,aAAK,eAAL;AACA,cAAM,MAAM,GAAG,IAAI,KAAJ,CAAU,KAAK,eAAL,GAAuB,CAAjC,EAAoC,IAApC,CAAyC,IAAzC,CAAf;;AACA,YAAI,KAAK,eAAL,GAAuB,KAAK,iBAAhC,EAAmD;AACjD,UAAA,OAAO,CAAC,GAAR,CAAY,GAAG,MAAM,QAAQ,SAAS,GAAtC;AACD;;AACD,cAAM;AAAE,UAAA,IAAF;AAAQ,UAAA;AAAR,YAAkB,CAAA,GAAA,OAAA,CAAA,KAAA,EAAM,SAAN,CAAxB;AACA;;AACA,cAAM,WAAW,GAAG,IAAI,GAAG,EAAP,GAAY,OAAO,CAAC,IAApB,GAA2B,OAAO,CAAC,GAAvD;;AACA,YAAI,KAAK,eAAL,GAAuB,KAAK,iBAAhC,EAAmD;AACjD,UAAA,WAAW,CAAC,GAAG,MAAM,QAAQ,SAAS,WAAW,IAAI,IAA1C,CAAX;AACD;;AACD,aAAK,eAAL;AACA,eAAO,KAAP;AACD,OAdD,MAcO;AACL,eAAO,SAAS,EAAhB;AACD;AACF,KApBD;;AA5zBE,QAAI,OAAO,MAAP,KAAkB,SAAtB,EAAiC;AAC/B,YAAM,KAAK,CACT,kFACE,+CAFO,CAAX;AAID,KAP0C,CAS3C;;;AACA,SAAK,MAAL,GAAc,CAAA,GAAA,QAAA,CAAA,OAAA,EAAO,EAAP,EAAW,oBAAX,EAAiC,MAAjC,CAAd;AAEA,UAAM,YAAY,GAAG,KAAK,MAAL,CAAY,aAAjC;;AACA,QAAI,YAAY,KAAK,IAArB,EAA2B;AACzB,WAAK,iBAAL,GAAyB,QAAzB;AACA,WAAK,aAAL,GAAqB,IAArB;AACD,KAHD,MAGO,IAAI,OAAO,YAAP,KAAwB,QAA5B,EAAsC;AAC3C,WAAK,iBAAL,GAAyB,YAAzB;AACA,WAAK,aAAL,GAAqB,IAArB;AACD;;AACD,SAAK,eAAL,GAAuB,CAAC,CAAxB;AAEA,SAAK,UAAL,CAAgB,mBAAhB,EAAqC,MAAK;AACxC,UAAI,gBAAJ;AACA,UAAI,iBAAiB,GAAG,IAAxB;AACA,WAAK,UAAL,CAAgB,uBAAhB,EAAyC,MAAK;AAC5C,YACE,KAAK,MAAL,CAAY,sBAAZ,KACA,oBAAoB,CAAC,sBAFvB,EAGE;AACA;AACA,eAAK,MAAL,CAAY,sBAAZ,GAAqC,OAAA,CAAA,6BAArC;AACD,SAND,MAMO;AACL,cACE,KAAK,MAAL,CAAY,wBAAZ,KACA,oBAAoB,CAAC,wBAFvB,EAGE;AACA,kBAAM,KAAK,CACT,8EACE,yGAFO,CAAX;AAID;AACF;;AAED,YAAI,MAAM,CAAC,QAAP,IAAmB,MAAM,CAAC,mBAA9B,EAAmD;AACjD,gBAAM,KAAK,CACT,oEADS,CAAX;AAGD;;AAED,aAAK,eAAL,GAAuB,kBAAkB,IAAlB,CACrB,KAAK,MAAL,CAAY,gBADS,CAAvB;AAGA,aAAK,aAAL,GAAqB,QAAQ,IAAR,CAAa,KAAK,MAAL,CAAY,gBAAzB,CAArB,CA5B4C,CA8B5C;;AACA,YAAI,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,eAAR,CAAJ,EAA8B;AAC5B,UAAA,gBAAgB,GAAG;AACjB,YAAA,KAAK,EAAE;AAAE,cAAA,WAAW,EAAE,CAAA,GAAA,OAAA,CAAA,OAAA,EAAM,eAAN;AAAf,aADU;AAEjB,YAAA,WAAW,EAAE,OAAA,CAAA;AAFI,WAAnB;AAID,SALD,MAKO;AACL;AACA,UAAA,iBAAiB,GAAG,KAApB;AACA,UAAA,gBAAgB,GAAG,CAAA,GAAA,OAAA,CAAA,OAAA,EAAiC,eAAjC,CAAnB;AACD;AACF,OAzCD;;AA2CA,UAAI,KAAK,MAAL,CAAY,eAAZ,KAAgC,KAApC,EAA2C;AACzC,aAAK,UAAL,CAAgB,sBAAhB,EAAwC,MAAK;AAC3C,eAAK,qBAAL,GAA6B,KAAK,qBAAL,CAA2B,MAA3B,CAC3B,CAAA,GAAA,OAAA,CAAA,oBAAA,EACE,gBADF,EAEE,KAAK,eAFP,EAGE,KAAK,MAAL,CAAY,wBAHd,CAD2B,CAA7B;AAOD,SARD;AAUA,aAAK,UAAL,CAAgB,6BAAhB,EAA+C,MAAK;AAClD,eAAK,sBAAL,GAA8B,KAAK,sBAAL,CAA4B,MAA5B,CAC5B,CAAA,GAAA,OAAA,CAAA,2BAAA,EACE,gBADF,EAEE,KAAK,eAFP,EAGE,KAAK,MAAL,CAAY,wBAHd,CAD4B,CAA9B;AAOD,SARD;AASD,OAlEuC,CAoExC;;;AACA,MAAA,gBAAgB,CAAC,KAAjB,GAAyB,gBAAgB,CAAC,KAAjB,GACrB,gBAAgB,CAAC,KADI,GAErB,EAFJ,CArEwC,CAyExC;AACA;;AACA,OAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,gBAAgB,CAAC,KAAzB,EAAgC,CAAC,aAAD,EAAgB,YAAhB,KAAgC;AAC9D,QAAA,gBAAgB,CAAC,KAAjB,CAAuB,YAAvB,IAAuC,CAAA,GAAA,QAAA,CAAA,OAAA,EACrC,aADqC,EAEpC,WAAD,IAAiB,CAAA,GAAA,aAAA,CAAA,OAAA,EAAY,WAAZ,CAFoB,CAAvC;AAID,OALD;AAOA,YAAM,YAAY,GAAG,CAAA,GAAA,MAAA,CAAA,OAAA,EAAK,gBAAgB,CAAC,KAAtB,CAArB;AAEA,OAAA,GAAA,SAAA,CAAA,OAAA,EACE,gBAAgB,CAAC,KADnB,EAEE,CAAC,UAAD,EAA0B,WAA1B,KAAyC;AACvC,aAAK,UAAL,CAAgB,UAAU,WAAW,cAArC,EAAqD,MAAK;AACxD,eAAK,KAAL,CAAW,IAAX,CAAgB,WAAhB;;AAEA,cAAI,KAAK,MAAL,CAAY,eAAZ,KAAgC,KAApC,EAA2C;AACzC,iBAAK,UAAL,CAAgB,kBAAhB,EAAoC,MAAK;AACvC,mBAAK,qBAAL,GAA6B,KAAK,qBAAL,CAA2B,MAA3B,CAC3B,CAAA,GAAA,OAAA,CAAA,gBAAA,EAAiB,UAAjB,EAA6B,YAA7B,CAD2B,CAA7B;AAGD,aAJD;AAKD,WATuD,CAWxD;AACA;AACA;;;AACA,cAAI,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,KAAK,qBAAb,CAAJ,EAAyC;AACvC,aAAA,GAAA,QAAA,CAAA,iBAAA,EAAkB,UAAlB;AAEA,gBAAI,iBAAJ;AACA,iBAAK,UAAL,CAAgB,mBAAhB,EAAqC,MAAK;AACxC,cAAA,iBAAiB,GAAG,CAAA,GAAA,OAAA,CAAA,iBAAA,EAAkB,UAAlB,EAA8B;AAChD,gBAAA,wBAAwB,EACtB,KAAK,MAAL,CAAY,wBAFkC;AAGhD,gBAAA,gBAAgB,EAAE,MAAM,CAAC,gBAHuB;AAIhD,gBAAA,mBAAmB,EAAE,MAAM,CAAC,mBAJoB;AAKhD,gBAAA,QAAQ,EAAE,MAAM,CAAC,QAL+B;AAMhD,gBAAA,MAAM,EAAE,KAAK;AANmC,eAA9B,CAApB;AAQD,aATD;AAWA,iBAAK,kBAAL,CAAwB,WAAxB,IACE,iBAAiB,CAAC,kBADpB;AAGA,iBAAK,4BAAL,CAAkC,WAAlC,IACE,iBAAiB,CAAC,4BADpB;AAGA,iBAAK,WAAL,GAAmB,CAAA,GAAA,QAAA,CAAA,OAAA,EACjB,EADiB,EAEjB,KAAK,WAFY,EAGjB,iBAAiB,CAAC,WAHD,CAAnB;AAMA,iBAAK,SAAL,GAAiB,iBAAiB,CAAC,SAAlB,IAA+B,KAAK,SAArD;AAEA,iBAAK,kBAAL,CAAwB,WAAxB,IACE,iBAAiB,CAAC,cADpB;AAED;AACF,SA9CD;AA+CD,OAlDH;AAqDA,WAAK,WAAL,GAAmB,gBAAgB,CAAC,WAApC;;AAEA,UACE,CAAC,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,KAAK,qBAAb,CAAD,IACA,CAAC,KAAK,MAAL,CAAY,6BAFf,EAGE;AACA,cAAM,cAAc,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,KAAK,qBAAT,EAAiC,KAAD,IAAU;AAC/D,iBAAO,KAAK,CAAC,OAAb;AACD,SAFsB,CAAvB;AAGA,cAAM,oBAAoB,GAAG,cAAc,CAAC,IAAf,CAC3B,2BAD2B,CAA7B;AAGA,cAAM,IAAI,KAAJ,CACJ,8CAA8C,oBAD1C,CAAN;AAGD,OAxJuC,CA0JxC;;;AACA,OAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,KAAK,sBAAb,EAAsC,iBAAD,IAAsB;AACzD,SAAA,GAAA,OAAA,CAAA,aAAA,EAAc,iBAAiB,CAAC,OAAhC;AACD,OAFD;AAIA,WAAK,UAAL,CAAgB,sCAAhB,EAAwD,MAAK;AAC3D;AACA;AACA;AACA,YAAI,OAAA,CAAA,cAAJ,EAAoB;AAClB,eAAK,SAAL,GAAsB,UAAA,CAAA,OAAtB;AACA,eAAK,KAAL,GAAa,KAAK,aAAlB;AACD,SAHD,MAGO;AACL,eAAK,eAAL,GAAuB,MAAA,CAAA,OAAvB;AACA,eAAK,KAAL,GAAa,KAAK,aAAlB;AACD;;AAED,YAAI,iBAAJ,EAAuB;AACrB,eAAK,WAAL,GAAmB,MAAA,CAAA,OAAnB;AACD;;AAED,YAAI,KAAK,eAAL,KAAyB,KAA7B,EAAoC;AAClC,eAAK,gBAAL,GAAwB,UAAA,CAAA,OAAxB;AACD;;AAED,YAAI,KAAK,aAAL,KAAuB,KAA3B,EAAkC;AAChC,eAAK,gCAAL,GAAwC,MAAA,CAAA,OAAxC;AACD;;AAED,YAAI,QAAQ,IAAR,CAAa,KAAK,MAAL,CAAY,gBAAzB,CAAJ,EAAgD;AAC9C,eAAK,mBAAL,GAA2B,KAAK,eAAhC;AACD,SAFD,MAEO,IAAI,aAAa,IAAb,CAAkB,KAAK,MAAL,CAAY,gBAA9B,CAAJ,EAAqD;AAC1D,eAAK,mBAAL,GAA2B,KAAK,oBAAhC;AACD,SAFM,MAEA,IAAI,cAAc,IAAd,CAAmB,KAAK,MAAL,CAAY,gBAA/B,CAAJ,EAAsD;AAC3D,eAAK,mBAAL,GAA2B,KAAK,qBAAhC;AACD,SAFM,MAEA;AACL,gBAAM,KAAK,CACT,8CAA8C,KAAK,MAAL,CAAY,gBAAgB,GADjE,CAAX;AAGD;;AAED,YAAI,KAAK,SAAT,EAAoB;AAClB,eAAK,QAAL,GAAgB,KAAK,iBAArB;AACA,eAAK,aAAL,GAAqB,KAAK,uBAA1B;AACD,SAHD,MAGO;AACL,eAAK,QAAL,GAAgB,KAAK,yBAArB;AACA,eAAK,aAAL,GAAqB,KAAK,qBAA1B;AACD;AACF,OA3CD;AA6CA,WAAK,UAAL,CAAgB,8BAAhB,EAAgD,MAAK;AACnD,cAAM,gBAAgB,GAAG,CAAA,GAAA,QAAA,CAAA,OAAA,EACvB,KAAK,kBADkB,EAEvB,CAAC,iBAAD,EAAoB,cAApB,EAAoC,QAApC,KAAgD;AAC9C,cAAI,cAAc,KAAK,KAAvB,EAA8B;AAC5B,YAAA,iBAAiB,CAAC,IAAlB,CAAuB,QAAvB;AACD;;AACD,iBAAO,iBAAP;AACD,SAPsB,EAQvB,EARuB,CAAzB;;AAWA,YAAI,MAAM,CAAC,mBAAP,IAA8B,CAAC,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,gBAAR,CAAnC,EAA8D;AAC5D,gBAAM,KAAK,CACT,kBAAkB,gBAAgB,CAAC,IAAjB,CAChB,IADgB,CAEjB,2BAFD,GAGE,6HAHF,GAIE,2EALO,CAAX;AAOD;AACF,OArBD;AAuBA,WAAK,UAAL,CAAgB,wBAAhB,EAA0C,MAAK;AAC7C,SAAA,GAAA,gBAAA,CAAA,sBAAA;AACD,OAFD;AAIA,WAAK,UAAL,CAAgB,kBAAhB,EAAoC,MAAK;AACvC,SAAA,GAAA,OAAA,CAAA,gBAAA,EAAiB,IAAjB;AACD,OAFD;AAGD,KA1OD;AA2OD;;AAEM,EAAA,QAAQ,CACb,IADa,EAEb,WAAA,GAAsB,KAAK,WAFd,EAEyB;AAEtC,QAAI,CAAC,CAAA,GAAA,SAAA,CAAA,OAAA,EAAQ,KAAK,qBAAb,CAAL,EAA0C;AACxC,YAAM,cAAc,GAAG,CAAA,GAAA,KAAA,CAAA,OAAA,EAAI,KAAK,qBAAT,EAAiC,KAAD,IAAU;AAC/D,eAAO,KAAK,CAAC,OAAb;AACD,OAFsB,CAAvB;AAGA,YAAM,oBAAoB,GAAG,cAAc,CAAC,IAAf,CAC3B,2BAD2B,CAA7B;AAGA,YAAM,IAAI,KAAJ,CACJ,yEACE,oBAFE,CAAN;AAID;;AAED,WAAO,KAAK,gBAAL,CAAsB,IAAtB,EAA4B,WAA5B,CAAP;AACD,GAnTe,CAqThB;AACA;AACA;AACA;;;AACQ,EAAA,gBAAgB,CAAC,IAAD,EAAe,WAAf,EAAkC;AACxD,QAAI,CAAJ,EACE,CADF,EAEE,CAFF,EAGE,aAHF,EAIE,SAJF,EAKE,YALF,EAME,OANF,EAOE,UAPF,EAQE,WARF,EASE,KATF,EAUE,OAVF,EAWE,QAXF,EAYE,SAZF,EAaE,WAbF,EAcE,GAdF,EAeE,KAfF;AAgBA,UAAM,OAAO,GAAG,IAAhB;AACA,UAAM,SAAS,GAAG,OAAO,CAAC,MAA1B;AACA,QAAI,MAAM,GAAG,CAAb;AACA,QAAI,kBAAkB,GAAG,CAAzB,CApBwD,CAqBxD;AACA;AACA;AACA;;AACA,UAAM,qBAAqB,GAAG,KAAK,SAAL,GAC1B,CAD0B,CACxB;AADwB,MAE1B,IAAI,CAAC,KAAL,CAAW,IAAI,CAAC,MAAL,GAAc,EAAzB,CAFJ;AAGA,UAAM,aAAa,GAAG,IAAI,KAAJ,CAAU,qBAAV,CAAtB;AACA,UAAM,MAAM,GAAmB,EAA/B;AACA,QAAI,IAAI,GAAG,KAAK,eAAL,GAAuB,CAAvB,GAA2B,SAAtC;AACA,QAAI,MAAM,GAAG,KAAK,eAAL,GAAuB,CAAvB,GAA2B,SAAxC;AACA,UAAM,MAAM,GAAQ,CAAA,GAAA,OAAA,CAAA,gBAAA,EAAiB,KAAK,WAAtB,CAApB;AACA,UAAM,UAAU,GAAG,KAAK,eAAxB;AACA,UAAM,qBAAqB,GAAG,KAAK,MAAL,CAAY,sBAA1C;AAEA,QAAI,sBAAsB,GAAG,CAA7B;AACA,QAAI,kBAAkB,GAAqB,EAA3C;AACA,QAAI,gCAAgC,GAEhC,EAFJ;AAIA,UAAM,SAAS,GAAa,EAA5B;AAEA,UAAM,UAAU,GAAqB,EAArC;AACA,IAAA,MAAM,CAAC,MAAP,CAAc,UAAd;AACA,QAAI,mBAAJ;;AAEA,aAAS,uBAAT,GAAgC;AAC9B,aAAO,kBAAP;AACD;;AAED,aAAS,4BAAT,CAAsC,QAAtC,EAAsD;AACpD,YAAM,gBAAgB,GAAG,CAAA,GAAA,OAAA,CAAA,wBAAA,EAAyB,QAAzB,CAAzB;AACA,YAAM,gBAAgB,GACpB,gCAAgC,CAAC,gBAAD,CADlC;;AAEA,UAAI,gBAAgB,KAAK,SAAzB,EAAoC;AAClC,eAAO,UAAP;AACD,OAFD,MAEO;AACL,eAAO,gBAAP;AACD;AACF;;AAED,UAAM,QAAQ,GAAI,QAAD,IAAqB;AACpC;AACA,UACE,SAAS,CAAC,MAAV,KAAqB,CAArB,IACA;AACA;AACA,MAAA,QAAQ,CAAC,SAAT,CAAmB,SAAnB,KAAiC,SAJnC,EAKE;AACA;AACA;AACA,cAAM,GAAG,GACP,KAAK,MAAL,CAAY,oBAAZ,CAAiC,gCAAjC,CACE,QADF,CADF;AAKA,QAAA,MAAM,CAAC,IAAP,CAAY;AACV,UAAA,MAAM,EAAE,QAAQ,CAAC,WADP;AAEV,UAAA,IAAI,EAAE,QAAQ,CAAC,SAFL;AAGV,UAAA,MAAM,EAAE,QAAQ,CAAC,WAHP;AAIV,UAAA,MAAM,EAAE,QAAQ,CAAC,KAAT,CAAe,MAJb;AAKV,UAAA,OAAO,EAAE;AALC,SAAZ;AAOD,OApBD,MAoBO;AACL,QAAA,SAAS,CAAC,GAAV;AACA,cAAM,OAAO,GAAG,CAAA,GAAA,MAAA,CAAA,OAAA,EAAK,SAAL,CAAhB;AACA,QAAA,kBAAkB,GAAG,KAAK,kBAAL,CAAwB,OAAxB,CAArB;AACA,QAAA,gCAAgC,GAC9B,KAAK,4BAAL,CAAkC,OAAlC,CADF;AAEA,QAAA,sBAAsB,GAAG,kBAAkB,CAAC,MAA5C;AACA,cAAM,kBAAkB,GACtB,KAAK,kBAAL,CAAwB,OAAxB,KAAoC,KAAK,MAAL,CAAY,QAAZ,KAAyB,KAD/D;;AAGA,YAAI,gCAAgC,IAAI,kBAAxC,EAA4D;AAC1D,UAAA,mBAAmB,GAAG,4BAAtB;AACD,SAFD,MAEO;AACL,UAAA,mBAAmB,GAAG,uBAAtB;AACD;AACF;AACF,KAtCD;;AAwCA,aAAS,SAAT,CAAgC,OAAhC,EAA+C;AAC7C,MAAA,SAAS,CAAC,IAAV,CAAe,OAAf;AACA,MAAA,gCAAgC,GAC9B,KAAK,4BAAL,CAAkC,OAAlC,CADF;AAGA,MAAA,kBAAkB,GAAG,KAAK,kBAAL,CAAwB,OAAxB,CAArB;AACA,MAAA,sBAAsB,GAAG,kBAAkB,CAAC,MAA5C;AAEA,MAAA,sBAAsB,GAAG,kBAAkB,CAAC,MAA5C;AACA,YAAM,kBAAkB,GACtB,KAAK,kBAAL,CAAwB,OAAxB,KAAoC,KAAK,MAAL,CAAY,QAAZ,KAAyB,KAD/D;;AAGA,UAAI,gCAAgC,IAAI,kBAAxC,EAA4D;AAC1D,QAAA,mBAAmB,GAAG,4BAAtB;AACD,OAFD,MAEO;AACL,QAAA,mBAAmB,GAAG,uBAAtB;AACD;AACF,KAxHuD,CA0HxD;AACA;;;AACA,IAAA,SAAS,CAAC,IAAV,CAAe,IAAf,EAAqB,WAArB;AAEA,QAAI,UAAJ;AAEA,UAAM,eAAe,GAAG,KAAK,MAAL,CAAY,eAApC;;AAEA,WAAO,MAAM,GAAG,SAAhB,EAA2B;AACzB,MAAA,YAAY,GAAG,IAAf;AAEA,YAAM,YAAY,GAAG,OAAO,CAAC,UAAR,CAAmB,MAAnB,CAArB;AACA,YAAM,wBAAwB,GAAG,mBAAmB,CAAC,YAAD,CAApD;AACA,YAAM,oBAAoB,GAAG,wBAAwB,CAAC,MAAtD;;AAEA,WAAK,CAAC,GAAG,CAAT,EAAY,CAAC,GAAG,oBAAhB,EAAsC,CAAC,EAAvC,EAA2C;AACzC,QAAA,UAAU,GAAG,wBAAwB,CAAC,CAAD,CAArC;AACA,cAAM,WAAW,GAAG,UAAU,CAAC,OAA/B;AACA,QAAA,OAAO,GAAG,IAAV,CAHyC,CAKzC;;AACA,cAAM,cAAc,GAAG,UAAU,CAAC,KAAlC;;AACA,YAAI,cAAc,KAAK,KAAvB,EAA8B;AAC5B,cAAI,YAAY,KAAK,cAArB,EAAqC;AACnC;AACA,YAAA,YAAY,GAAG,WAAf;AACD;AACF,SALD,MAKO,IAAI,UAAU,CAAC,QAAX,KAAwB,IAA5B,EAAkC;AACvC,UAAA,KAAK,GAAI,WAA2B,CAAC,IAA5B,CACP,OADO,EAEP,MAFO,EAGP,aAHO,EAIP,MAJO,CAAT;;AAMA,cAAI,KAAK,KAAK,IAAd,EAAoB;AAClB,YAAA,YAAY,GAAG,KAAK,CAAC,CAAD,CAApB;;AACA,gBAAK,KAAoC,CAAC,OAArC,KAAiD,SAAtD,EAAiE;AAC/D,cAAA,OAAO,GAAI,KAAoC,CAAC,OAAhD;AACD;AACF,WALD,MAKO;AACL,YAAA,YAAY,GAAG,IAAf;AACD;AACF,SAfM,MAeA;AACL,eAAK,eAAL,CAAqB,WAArB,EAA4C,MAA5C;AACA,UAAA,YAAY,GAAG,KAAK,KAAL,CAAW,WAAX,EAAkC,IAAlC,EAAwC,MAAxC,CAAf;AACD;;AAED,YAAI,YAAY,KAAK,IAArB,EAA2B;AACzB;AACA;AACA,UAAA,SAAS,GAAG,UAAU,CAAC,SAAvB;;AACA,cAAI,SAAS,KAAK,SAAlB,EAA6B;AAC3B;AACA;AACA,kBAAM,eAAe,GAAG,SAAS,CAAC,MAAlC;;AACA,iBAAK,CAAC,GAAG,CAAT,EAAY,CAAC,GAAG,eAAhB,EAAiC,CAAC,EAAlC,EAAsC;AACpC,oBAAM,eAAe,GAAG,kBAAkB,CAAC,SAAS,CAAC,CAAD,CAAV,CAA1C;AACA,oBAAM,gBAAgB,GAAG,eAAe,CAAC,OAAzC;AACA,cAAA,UAAU,GAAG,IAAb,CAHoC,CAKpC;AACA;;AACA,kBAAI,eAAe,CAAC,QAAhB,KAA6B,IAAjC,EAAuC;AACrC,gBAAA,KAAK,GAAI,gBAAgC,CAAC,IAAjC,CACP,OADO,EAEP,MAFO,EAGP,aAHO,EAIP,MAJO,CAAT;;AAMA,oBAAI,KAAK,KAAK,IAAd,EAAoB;AAClB,kBAAA,aAAa,GAAG,KAAK,CAAC,CAAD,CAArB;;AACA,sBACG,KAAoC,CAAC,OAArC,KAAiD,SADpD,EAEE;AACA,oBAAA,UAAU,GAAI,KAAoC,CAAC,OAAnD;AACD;AACF,iBAPD,MAOO;AACL,kBAAA,aAAa,GAAG,IAAhB;AACD;AACF,eAjBD,MAiBO;AACL,qBAAK,eAAL,CAAqB,gBAArB,EAAiD,MAAjD;AACA,gBAAA,aAAa,GAAG,KAAK,KAAL,CACd,gBADc,EAEd,IAFc,EAGd,MAHc,CAAhB;AAKD;;AAED,kBAAI,aAAa,IAAI,aAAa,CAAC,MAAd,GAAuB,YAAY,CAAC,MAAzD,EAAiE;AAC/D,gBAAA,YAAY,GAAG,aAAf;AACA,gBAAA,OAAO,GAAG,UAAV;AACA,gBAAA,UAAU,GAAG,eAAb,CAH+D,CAI/D;AACA;;AACA;AACD;AACF;AACF;;AACD;AACD;AACF,OA5FwB,CA8FzB;;;AACA,UAAI,YAAY,KAAK,IAArB,EAA2B;AACzB,QAAA,WAAW,GAAG,YAAY,CAAC,MAA3B;AACA,QAAA,KAAK,GAAG,UAAU,CAAC,KAAnB;;AACA,YAAI,KAAK,KAAK,SAAd,EAAyB;AACvB,UAAA,OAAO,GAAG,UAAU,CAAC,YAArB,CADuB,CAEvB;AACA;;AACA,UAAA,QAAQ,GAAG,KAAK,mBAAL,CACT,YADS,EAET,MAFS,EAGT,OAHS,EAIT,UAAU,CAAC,SAJF,EAKT,IALS,EAMT,MANS,EAOT,WAPS,CAAX;AAUA,eAAK,aAAL,CAAmB,QAAnB,EAA6B,OAA7B,EAduB,CAgBvB;;AACA,cAAI,KAAK,KAAK,KAAd,EAAqB;AACnB,YAAA,kBAAkB,GAAG,KAAK,QAAL,CACnB,aADmB,EAEnB,kBAFmB,EAGnB,QAHmB,CAArB;AAKD,WAND,MAMO;AACL,YAAA,MAAM,CAAC,KAAD,CAAN,CAAc,IAAd,CAAmB,QAAnB;AACD;AACF;;AACD,QAAA,IAAI,GAAG,KAAK,SAAL,CAAe,IAAf,EAAqB,WAArB,CAAP;AACA,QAAA,MAAM,GAAG,MAAM,GAAG,WAAlB,CA/ByB,CAiCzB;;AACA,QAAA,MAAM,GAAG,KAAK,gBAAL,CAAsB,MAAtB,EAA+B,WAA/B,CAAT;;AAEA,YAAI,UAAU,KAAK,IAAf,IAAuB,UAAU,CAAC,iBAAX,KAAiC,IAA5D,EAAkE;AAChE,cAAI,eAAe,GAAG,CAAtB;AACA,cAAI,eAAJ;AACA,cAAI,eAAJ;AACA,UAAA,qBAAqB,CAAC,SAAtB,GAAkC,CAAlC;;AACA,aAAG;AACD,YAAA,eAAe,GAAG,qBAAqB,CAAC,IAAtB,CAA2B,YAA3B,CAAlB;;AACA,gBAAI,eAAe,KAAK,IAAxB,EAA8B;AAC5B,cAAA,eAAe,GAAG,qBAAqB,CAAC,SAAtB,GAAkC,CAApD;AACA,cAAA,eAAe;AAChB;AACF,WAND,QAMS,eAAe,KAAK,IAN7B;;AAQA,cAAI,eAAe,KAAK,CAAxB,EAA2B;AACzB,YAAA,IAAI,GAAG,IAAK,GAAG,eAAf;AACA,YAAA,MAAM,GAAG,WAAW,GAAG,eAAvB;AACA,iBAAK,gCAAL,CACE,QADF,EAEE,KAFF,EAGE,eAHF,EAIE,eAJF,EAKE,IALF,EAME,MANF,EAOE,WAPF;AASD;AACF,SA9DwB,CA+DzB;;;AACA,aAAK,WAAL,CAAiB,UAAjB,EAA6B,QAA7B,EAAuC,SAAvC,EAAkD,QAAlD;AACD,OAjED,MAiEO;AACL;AACA,cAAM,gBAAgB,GAAG,MAAzB;AACA,cAAM,SAAS,GAAG,IAAlB;AACA,cAAM,WAAW,GAAG,MAApB;AACA,YAAI,gBAAgB,GAAG,eAAe,KAAK,KAA3C;;AAEA,eAAO,gBAAgB,KAAK,KAArB,IAA8B,MAAM,GAAG,SAA9C,EAAyD;AACvD;AACA,UAAA,IAAI,GAAG,KAAK,SAAL,CAAe,IAAf,EAAqB,CAArB,CAAP;AACA,UAAA,MAAM;;AACN,eAAK,CAAC,GAAG,CAAT,EAAY,CAAC,GAAG,sBAAhB,EAAwC,CAAC,EAAzC,EAA6C;AAC3C,kBAAM,UAAU,GAAG,kBAAkB,CAAC,CAAD,CAArC;AACA,kBAAM,WAAW,GAAG,UAAU,CAAC,OAA/B,CAF2C,CAI3C;;AACA,kBAAM,cAAc,GAAG,UAAU,CAAC,KAAlC;;AACA,gBAAI,cAAc,KAAK,KAAvB,EAA8B;AAC5B,kBAAI,OAAO,CAAC,UAAR,CAAmB,MAAnB,MAA+B,cAAnC,EAAmD;AACjD;AACA,gBAAA,gBAAgB,GAAG,IAAnB;AACD;AACF,aALD,MAKO,IAAI,UAAU,CAAC,QAAX,KAAwB,IAA5B,EAAkC;AACvC,cAAA,gBAAgB,GACb,WAA2B,CAAC,IAA5B,CACC,OADD,EAEC,MAFD,EAGC,aAHD,EAIC,MAJD,MAKK,IANR;AAOD,aARM,MAQA;AACL,mBAAK,eAAL,CAAqB,WAArB,EAA4C,MAA5C;AACA,cAAA,gBAAgB,GAAI,WAAsB,CAAC,IAAvB,CAA4B,IAA5B,MAAsC,IAA1D;AACD;;AAED,gBAAI,gBAAgB,KAAK,IAAzB,EAA+B;AAC7B;AACD;AACF;AACF;;AAED,QAAA,SAAS,GAAG,MAAM,GAAG,gBAArB,CAzCK,CA0CL;;AACA,QAAA,GAAG,GAAG,KAAK,MAAL,CAAY,oBAAZ,CAAiC,gCAAjC,CACJ,OADI,EAEJ,gBAFI,EAGJ,SAHI,EAIJ,SAJI,EAKJ,WALI,CAAN;AAOA,QAAA,MAAM,CAAC,IAAP,CAAY;AACV,UAAA,MAAM,EAAE,gBADE;AAEV,UAAA,IAAI,EAAE,SAFI;AAGV,UAAA,MAAM,EAAE,WAHE;AAIV,UAAA,MAAM,EAAE,SAJE;AAKV,UAAA,OAAO,EAAE;AALC,SAAZ;;AAQA,YAAI,eAAe,KAAK,KAAxB,EAA+B;AAC7B;AACD;AACF;AACF,KAhWuD,CAkWxD;AACA;;;AACA,QAAI,CAAC,KAAK,SAAV,EAAqB;AACnB;AACA,MAAA,aAAa,CAAC,MAAd,GAAuB,kBAAvB;AACD;;AAED,WAAO;AACL,MAAA,MAAM,EAAE,aADH;AAEL,MAAA,MAAM,EAAE,MAFH;AAGL,MAAA,MAAM,EAAE;AAHH,KAAP;AAKD;;AAEO,EAAA,WAAW,CACjB,MADiB,EAEjB,QAFiB,EAGjB,SAHiB,EAIjB,QAJiB,EAID;AAEhB,QAAI,MAAM,CAAC,GAAP,KAAe,IAAnB,EAAyB;AACvB;AACA;AACA,YAAM,QAAQ,GAAG,MAAM,CAAC,IAAxB;AACA,MAAA,QAAQ,CAAC,QAAD,CAAR;;AACA,UAAI,QAAQ,KAAK,SAAjB,EAA4B;AAC1B,QAAA,SAAS,CAAC,IAAV,CAAe,IAAf,EAAqB,QAArB;AACD;AACF,KARD,MAQO,IAAI,MAAM,CAAC,IAAP,KAAgB,SAApB,EAA+B;AACpC,MAAA,SAAS,CAAC,IAAV,CAAe,IAAf,EAAqB,MAAM,CAAC,IAA5B;AACD;AACF;;AAEO,EAAA,SAAS,CAAC,IAAD,EAAe,MAAf,EAA6B;AAC5C,WAAO,IAAI,CAAC,SAAL,CAAe,MAAf,CAAP;AACD;;AAEO,EAAA,eAAe,CAAC,MAAD,EAAiB,YAAjB,EAAqC;AAC1D,IAAA,MAAM,CAAC,SAAP,GAAmB,YAAnB;AACD,GAlsBe,CAosBhB;;;AACQ,EAAA,gCAAgC,CACtC,QADsC,EAEtC,KAFsC,EAGtC,SAHsC,EAItC,eAJsC,EAKtC,IALsC,EAMtC,MANsC,EAOtC,WAPsC,EAOnB;AAEnB,QAAI,YAAJ,EAAkB,gBAAlB;;AACA,QAAI,KAAK,KAAK,SAAd,EAAyB;AACvB;AACA,MAAA,YAAY,GAAG,SAAS,KAAK,WAAW,GAAG,CAA3C;AACA,MAAA,gBAAgB,GAAG,YAAY,GAAG,CAAC,CAAJ,GAAQ,CAAvC;;AACA,UAAI,EAAE,eAAe,KAAK,CAApB,IAAyB,YAAY,KAAK,IAA5C,CAAJ,EAAuD;AACrD;AACA,QAAA,QAAQ,CAAC,OAAT,GAAmB,IAAI,GAAG,gBAA1B,CAFqD,CAGrD;AACA;;AACA,QAAA,QAAQ,CAAC,SAAT,GAAqB,MAAM,GAAG,CAAT,GAAa,CAAC,gBAAnC;AACD,OAVsB,CAWvB;;AACD;AACF;;AAEO,EAAA,gBAAgB,CAAC,SAAD,EAAoB,WAApB,EAAuC;AAC7D,WAAO,SAAS,GAAG,WAAnB;AACD;;AAMO,EAAA,qBAAqB,CAC3B,KAD2B,EAE3B,WAF2B,EAG3B,YAH2B,EAI3B,SAJ2B,EAIP;AAEpB,WAAO;AACL,MAAA,KADK;AAEL,MAAA,WAFK;AAGL,MAAA,YAHK;AAIL,MAAA;AAJK,KAAP;AAMD;;AAEO,EAAA,oBAAoB,CAC1B,KAD0B,EAE1B,WAF0B,EAG1B,YAH0B,EAI1B,SAJ0B,EAK1B,SAL0B,EAM1B,WAN0B,EAMP;AAEnB,WAAO;AACL,MAAA,KADK;AAEL,MAAA,WAFK;AAGL,MAAA,SAHK;AAIL,MAAA,WAJK;AAKL,MAAA,YALK;AAML,MAAA;AANK,KAAP;AAQD;;AAEO,EAAA,eAAe,CACrB,KADqB,EAErB,WAFqB,EAGrB,YAHqB,EAIrB,SAJqB,EAKrB,SALqB,EAMrB,WANqB,EAOrB,WAPqB,EAOF;AAEnB,WAAO;AACL,MAAA,KADK;AAEL,MAAA,WAFK;AAGL,MAAA,SAAS,EAAE,WAAW,GAAG,WAAd,GAA4B,CAHlC;AAIL,MAAA,SAJK;AAKL,MAAA,OAAO,EAAE,SALJ;AAML,MAAA,WANK;AAOL,MAAA,SAAS,EAAE,WAAW,GAAG,WAAd,GAA4B,CAPlC;AAQL,MAAA,YARK;AASL,MAAA;AATK,KAAP;AAWD;;AAUO,EAAA,iBAAiB,CACvB,WADuB,EAEvB,KAFuB,EAGvB,UAHuB,EAGL;AAElB,IAAA,WAAW,CAAC,IAAZ,CAAiB,UAAjB;AACA,WAAO,KAAP;AACD;;AAEO,EAAA,yBAAyB,CAC/B,WAD+B,EAE/B,KAF+B,EAG/B,UAH+B,EAGb;AAElB,IAAA,WAAW,CAAC,KAAD,CAAX,GAAqB,UAArB;AACA,IAAA,KAAK;AACL,WAAO,KAAP;AACD;;AAKO,EAAA,qBAAqB,CAAC,KAAD,EAAgB,OAAhB,EAA4B,CAAU;;AAE3D,EAAA,uBAAuB,CAAC,KAAD,EAAgB,OAAhB,EAA4B;AACzD,QAAI,OAAO,KAAK,IAAhB,EAAsB;AACpB,MAAA,KAAK,CAAC,OAAN,GAAgB,OAAhB;AACD;AACF;;AASO,EAAA,aAAa,CACnB,OADmB,EAEnB,IAFmB,EAGnB,MAHmB,EAGL;AAEd,UAAM,KAAK,GAAG,OAAO,CAAC,IAAR,CAAa,IAAb,CAAd;;AACA,QAAI,KAAK,KAAK,IAAd,EAAoB;AAClB,aAAO,IAAI,CAAC,SAAL,CAAe,MAAf,EAAuB,OAAO,CAAC,SAA/B,CAAP;AACD;;AACD,WAAO,IAAP;AACD;;AAEO,EAAA,aAAa,CAAC,OAAD,EAAkB,IAAlB,EAA8B;AACjD,UAAM,WAAW,GAAG,OAAO,CAAC,IAAR,CAAa,IAAb,CAApB;AACA,WAAO,WAAW,KAAK,IAAhB,GAAuB,WAAW,CAAC,CAAD,CAAlC,GAAwC,IAA/C;AACD;;AAx1Be;;AAAlB,OAAA,CAAA,KAAA,GAAA,KAAA;AACgB,KAAA,CAAA,OAAA,GACZ,oFACA,6GAFY;AAIA,KAAA,CAAA,EAAA,GAAK,gBAAL","sourceRoot":"","sourcesContent":["\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Lexer = exports.LexerDefinitionErrorType = void 0;\nconst lexer_1 = require(\"./lexer\");\nconst noop_1 = __importDefault(require(\"lodash/noop\"));\nconst isEmpty_1 = __importDefault(require(\"lodash/isEmpty\"));\nconst isArray_1 = __importDefault(require(\"lodash/isArray\"));\nconst last_1 = __importDefault(require(\"lodash/last\"));\nconst reject_1 = __importDefault(require(\"lodash/reject\"));\nconst map_1 = __importDefault(require(\"lodash/map\"));\nconst forEach_1 = __importDefault(require(\"lodash/forEach\"));\nconst keys_1 = __importDefault(require(\"lodash/keys\"));\nconst isUndefined_1 = __importDefault(require(\"lodash/isUndefined\"));\nconst identity_1 = __importDefault(require(\"lodash/identity\"));\nconst assign_1 = __importDefault(require(\"lodash/assign\"));\nconst reduce_1 = __importDefault(require(\"lodash/reduce\"));\nconst clone_1 = __importDefault(require(\"lodash/clone\"));\nconst utils_1 = require(\"@chevrotain/utils\");\nconst tokens_1 = require(\"./tokens\");\nconst lexer_errors_public_1 = require(\"./lexer_errors_public\");\nconst reg_exp_parser_1 = require(\"./reg_exp_parser\");\nvar LexerDefinitionErrorType;\n(function (LexerDefinitionErrorType) {\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MISSING_PATTERN\"] = 0] = \"MISSING_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_PATTERN\"] = 1] = \"INVALID_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"EOI_ANCHOR_FOUND\"] = 2] = \"EOI_ANCHOR_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNSUPPORTED_FLAGS_FOUND\"] = 3] = \"UNSUPPORTED_FLAGS_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"DUPLICATE_PATTERNS_FOUND\"] = 4] = \"DUPLICATE_PATTERNS_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"INVALID_GROUP_TYPE_FOUND\"] = 5] = \"INVALID_GROUP_TYPE_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"PUSH_MODE_DOES_NOT_EXIST\"] = 6] = \"PUSH_MODE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\"] = 7] = \"MULTI_MODE_LEXER_WITHOUT_DEFAULT_MODE\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\"] = 8] = \"MULTI_MODE_LEXER_WITHOUT_MODES_PROPERTY\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\"] = 9] = \"MULTI_MODE_LEXER_DEFAULT_MODE_VALUE_DOES_NOT_EXIST\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\"] = 10] = \"LEXER_DEFINITION_CANNOT_CONTAIN_UNDEFINED\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"SOI_ANCHOR_FOUND\"] = 11] = \"SOI_ANCHOR_FOUND\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"EMPTY_MATCH_PATTERN\"] = 12] = \"EMPTY_MATCH_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"NO_LINE_BREAKS_FLAGS\"] = 13] = \"NO_LINE_BREAKS_FLAGS\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"UNREACHABLE_PATTERN\"] = 14] = \"UNREACHABLE_PATTERN\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"IDENTIFY_TERMINATOR\"] = 15] = \"IDENTIFY_TERMINATOR\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"CUSTOM_LINE_BREAK\"] = 16] = \"CUSTOM_LINE_BREAK\";\n    LexerDefinitionErrorType[LexerDefinitionErrorType[\"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\"] = 17] = \"MULTI_MODE_LEXER_LONGER_ALT_NOT_IN_CURRENT_MODE\";\n})(LexerDefinitionErrorType = exports.LexerDefinitionErrorType || (exports.LexerDefinitionErrorType = {}));\nconst DEFAULT_LEXER_CONFIG = {\n    deferDefinitionErrorsHandling: false,\n    positionTracking: \"full\",\n    lineTerminatorsPattern: /\\n|\\r\\n?/g,\n    lineTerminatorCharacters: [\"\\n\", \"\\r\"],\n    ensureOptimizations: false,\n    safeMode: false,\n    errorMessageProvider: lexer_errors_public_1.defaultLexerErrorProvider,\n    traceInitPerf: false,\n    skipValidations: false,\n    recoveryEnabled: true\n};\nObject.freeze(DEFAULT_LEXER_CONFIG);\nclass Lexer {\n    constructor(lexerDefinition, config = DEFAULT_LEXER_CONFIG) {\n        this.lexerDefinition = lexerDefinition;\n        this.lexerDefinitionErrors = [];\n        this.lexerDefinitionWarning = [];\n        this.patternIdxToConfig = {};\n        this.charCodeToPatternIdxToConfig = {};\n        this.modes = [];\n        this.emptyGroups = {};\n        this.trackStartLines = true;\n        this.trackEndLines = true;\n        this.hasCustom = false;\n        this.canModeBeOptimized = {};\n        // Duplicated from the parser's perf trace trait to allow future extraction\n        // of the lexer to a separate package.\n        this.TRACE_INIT = (phaseDesc, phaseImpl) => {\n            // No need to optimize this using NOOP pattern because\n            // It is not called in a hot spot...\n            if (this.traceInitPerf === true) {\n                this.traceInitIndent++;\n                const indent = new Array(this.traceInitIndent + 1).join(\"\\t\");\n                if (this.traceInitIndent < this.traceInitMaxIdent) {\n                    console.log(`${indent}--> <${phaseDesc}>`);\n                }\n                const { time, value } = (0, utils_1.timer)(phaseImpl);\n                /* istanbul ignore next - Difficult to reproduce specific performance behavior (>10ms) in tests */\n                const traceMethod = time > 10 ? console.warn : console.log;\n                if (this.traceInitIndent < this.traceInitMaxIdent) {\n                    traceMethod(`${indent}<-- <${phaseDesc}> time: ${time}ms`);\n                }\n                this.traceInitIndent--;\n                return value;\n            }\n            else {\n                return phaseImpl();\n            }\n        };\n        if (typeof config === \"boolean\") {\n            throw Error(\"The second argument to the Lexer constructor is now an ILexerConfig Object.\\n\" +\n                \"a boolean 2nd argument is no longer supported\");\n        }\n        // todo: defaults func?\n        this.config = (0, assign_1.default)({}, DEFAULT_LEXER_CONFIG, config);\n        const traceInitVal = this.config.traceInitPerf;\n        if (traceInitVal === true) {\n            this.traceInitMaxIdent = Infinity;\n            this.traceInitPerf = true;\n        }\n        else if (typeof traceInitVal === \"number\") {\n            this.traceInitMaxIdent = traceInitVal;\n            this.traceInitPerf = true;\n        }\n        this.traceInitIndent = -1;\n        this.TRACE_INIT(\"Lexer Constructor\", () => {\n            let actualDefinition;\n            let hasOnlySingleMode = true;\n            this.TRACE_INIT(\"Lexer Config handling\", () => {\n                if (this.config.lineTerminatorsPattern ===\n                    DEFAULT_LEXER_CONFIG.lineTerminatorsPattern) {\n                    // optimized built-in implementation for the defaults definition of lineTerminators\n                    this.config.lineTerminatorsPattern = lexer_1.LineTerminatorOptimizedTester;\n                }\n                else {\n                    if (this.config.lineTerminatorCharacters ===\n                        DEFAULT_LEXER_CONFIG.lineTerminatorCharacters) {\n                        throw Error(\"Error: Missing <lineTerminatorCharacters> property on the Lexer config.\\n\" +\n                            \"\\tFor details See: https://chevrotain.io/docs/guide/resolving_lexer_errors.html#MISSING_LINE_TERM_CHARS\");\n                    }\n                }\n                if (config.safeMode && config.ensureOptimizations) {\n                    throw Error('\"safeMode\" and \"ensureOptimizations\" flags are mutually exclusive.');\n                }\n                this.trackStartLines = /full|onlyStart/i.test(this.config.positionTracking);\n                this.trackEndLines = /full/i.test(this.config.positionTracking);\n                // Convert SingleModeLexerDefinition into a IMultiModeLexerDefinition.\n                if ((0, isArray_1.default)(lexerDefinition)) {\n                    actualDefinition = {\n                        modes: { defaultMode: (0, clone_1.default)(lexerDefinition) },\n                        defaultMode: lexer_1.DEFAULT_MODE\n                    };\n                }\n                else {\n                    // no conversion needed, input should already be a IMultiModeLexerDefinition\n                    hasOnlySingleMode = false;\n                    actualDefinition = (0, clone_1.default)(lexerDefinition);\n                }\n            });\n            if (this.config.skipValidations === false) {\n                this.TRACE_INIT(\"performRuntimeChecks\", () => {\n                    this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat((0, lexer_1.performRuntimeChecks)(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n                });\n                this.TRACE_INIT(\"performWarningRuntimeChecks\", () => {\n                    this.lexerDefinitionWarning = this.lexerDefinitionWarning.concat((0, lexer_1.performWarningRuntimeChecks)(actualDefinition, this.trackStartLines, this.config.lineTerminatorCharacters));\n                });\n            }\n            // for extra robustness to avoid throwing an none informative error message\n            actualDefinition.modes = actualDefinition.modes\n                ? actualDefinition.modes\n                : {};\n            // an error of undefined TokenTypes will be detected in \"performRuntimeChecks\" above.\n            // this transformation is to increase robustness in the case of partially invalid lexer definition.\n            (0, forEach_1.default)(actualDefinition.modes, (currModeValue, currModeName) => {\n                actualDefinition.modes[currModeName] = (0, reject_1.default)(currModeValue, (currTokType) => (0, isUndefined_1.default)(currTokType));\n            });\n            const allModeNames = (0, keys_1.default)(actualDefinition.modes);\n            (0, forEach_1.default)(actualDefinition.modes, (currModDef, currModName) => {\n                this.TRACE_INIT(`Mode: <${currModName}> processing`, () => {\n                    this.modes.push(currModName);\n                    if (this.config.skipValidations === false) {\n                        this.TRACE_INIT(`validatePatterns`, () => {\n                            this.lexerDefinitionErrors = this.lexerDefinitionErrors.concat((0, lexer_1.validatePatterns)(currModDef, allModeNames));\n                        });\n                    }\n                    // If definition errors were encountered, the analysis phase may fail unexpectedly/\n                    // Considering a lexer with definition errors may never be used, there is no point\n                    // to performing the analysis anyhow...\n                    if ((0, isEmpty_1.default)(this.lexerDefinitionErrors)) {\n                        (0, tokens_1.augmentTokenTypes)(currModDef);\n                        let currAnalyzeResult;\n                        this.TRACE_INIT(`analyzeTokenTypes`, () => {\n                            currAnalyzeResult = (0, lexer_1.analyzeTokenTypes)(currModDef, {\n                                lineTerminatorCharacters: this.config.lineTerminatorCharacters,\n                                positionTracking: config.positionTracking,\n                                ensureOptimizations: config.ensureOptimizations,\n                                safeMode: config.safeMode,\n                                tracer: this.TRACE_INIT\n                            });\n                        });\n                        this.patternIdxToConfig[currModName] =\n                            currAnalyzeResult.patternIdxToConfig;\n                        this.charCodeToPatternIdxToConfig[currModName] =\n                            currAnalyzeResult.charCodeToPatternIdxToConfig;\n                        this.emptyGroups = (0, assign_1.default)({}, this.emptyGroups, currAnalyzeResult.emptyGroups);\n                        this.hasCustom = currAnalyzeResult.hasCustom || this.hasCustom;\n                        this.canModeBeOptimized[currModName] =\n                            currAnalyzeResult.canBeOptimized;\n                    }\n                });\n            });\n            this.defaultMode = actualDefinition.defaultMode;\n            if (!(0, isEmpty_1.default)(this.lexerDefinitionErrors) &&\n                !this.config.deferDefinitionErrorsHandling) {\n                const allErrMessages = (0, map_1.default)(this.lexerDefinitionErrors, (error) => {\n                    return error.message;\n                });\n                const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n                throw new Error(\"Errors detected in definition of Lexer:\\n\" + allErrMessagesString);\n            }\n            // Only print warning if there are no errors, This will avoid pl\n            (0, forEach_1.default)(this.lexerDefinitionWarning, (warningDescriptor) => {\n                (0, utils_1.PRINT_WARNING)(warningDescriptor.message);\n            });\n            this.TRACE_INIT(\"Choosing sub-methods implementations\", () => {\n                // Choose the relevant internal implementations for this specific parser.\n                // These implementations should be in-lined by the JavaScript engine\n                // to provide optimal performance in each scenario.\n                if (lexer_1.SUPPORT_STICKY) {\n                    this.chopInput = identity_1.default;\n                    this.match = this.matchWithTest;\n                }\n                else {\n                    this.updateLastIndex = noop_1.default;\n                    this.match = this.matchWithExec;\n                }\n                if (hasOnlySingleMode) {\n                    this.handleModes = noop_1.default;\n                }\n                if (this.trackStartLines === false) {\n                    this.computeNewColumn = identity_1.default;\n                }\n                if (this.trackEndLines === false) {\n                    this.updateTokenEndLineColumnLocation = noop_1.default;\n                }\n                if (/full/i.test(this.config.positionTracking)) {\n                    this.createTokenInstance = this.createFullToken;\n                }\n                else if (/onlyStart/i.test(this.config.positionTracking)) {\n                    this.createTokenInstance = this.createStartOnlyToken;\n                }\n                else if (/onlyOffset/i.test(this.config.positionTracking)) {\n                    this.createTokenInstance = this.createOffsetOnlyToken;\n                }\n                else {\n                    throw Error(`Invalid <positionTracking> config option: \"${this.config.positionTracking}\"`);\n                }\n                if (this.hasCustom) {\n                    this.addToken = this.addTokenUsingPush;\n                    this.handlePayload = this.handlePayloadWithCustom;\n                }\n                else {\n                    this.addToken = this.addTokenUsingMemberAccess;\n                    this.handlePayload = this.handlePayloadNoCustom;\n                }\n            });\n            this.TRACE_INIT(\"Failed Optimization Warnings\", () => {\n                const unOptimizedModes = (0, reduce_1.default)(this.canModeBeOptimized, (cannotBeOptimized, canBeOptimized, modeName) => {\n                    if (canBeOptimized === false) {\n                        cannotBeOptimized.push(modeName);\n                    }\n                    return cannotBeOptimized;\n                }, []);\n                if (config.ensureOptimizations && !(0, isEmpty_1.default)(unOptimizedModes)) {\n                    throw Error(`Lexer Modes: < ${unOptimizedModes.join(\", \")} > cannot be optimized.\\n` +\n                        '\\t Disable the \"ensureOptimizations\" lexer config flag to silently ignore this and run the lexer in an un-optimized mode.\\n' +\n                        \"\\t Or inspect the console log for details on how to resolve these issues.\");\n                }\n            });\n            this.TRACE_INIT(\"clearRegExpParserCache\", () => {\n                (0, reg_exp_parser_1.clearRegExpParserCache)();\n            });\n            this.TRACE_INIT(\"toFastProperties\", () => {\n                (0, utils_1.toFastProperties)(this);\n            });\n        });\n    }\n    tokenize(text, initialMode = this.defaultMode) {\n        if (!(0, isEmpty_1.default)(this.lexerDefinitionErrors)) {\n            const allErrMessages = (0, map_1.default)(this.lexerDefinitionErrors, (error) => {\n                return error.message;\n            });\n            const allErrMessagesString = allErrMessages.join(\"-----------------------\\n\");\n            throw new Error(\"Unable to Tokenize because Errors detected in definition of Lexer:\\n\" +\n                allErrMessagesString);\n        }\n        return this.tokenizeInternal(text, initialMode);\n    }\n    // There is quite a bit of duplication between this and \"tokenizeInternalLazy\"\n    // This is intentional due to performance considerations.\n    // this method also used quite a bit of `!` none null assertions because it is too optimized\n    // for `tsc` to always understand it is \"safe\"\n    tokenizeInternal(text, initialMode) {\n        let i, j, k, matchAltImage, longerAlt, matchedImage, payload, altPayload, imageLength, group, tokType, newToken, errLength, droppedChar, msg, match;\n        const orgText = text;\n        const orgLength = orgText.length;\n        let offset = 0;\n        let matchedTokensIndex = 0;\n        // initializing the tokensArray to the \"guessed\" size.\n        // guessing too little will still reduce the number of array re-sizes on pushes.\n        // guessing too large (Tested by guessing x4 too large) may cost a bit more of memory\n        // but would still have a faster runtime by avoiding (All but one) array resizing.\n        const guessedNumberOfTokens = this.hasCustom\n            ? 0 // will break custom token pattern APIs the matchedTokens array will contain undefined elements.\n            : Math.floor(text.length / 10);\n        const matchedTokens = new Array(guessedNumberOfTokens);\n        const errors = [];\n        let line = this.trackStartLines ? 1 : undefined;\n        let column = this.trackStartLines ? 1 : undefined;\n        const groups = (0, lexer_1.cloneEmptyGroups)(this.emptyGroups);\n        const trackLines = this.trackStartLines;\n        const lineTerminatorPattern = this.config.lineTerminatorsPattern;\n        let currModePatternsLength = 0;\n        let patternIdxToConfig = [];\n        let currCharCodeToPatternIdxToConfig = [];\n        const modeStack = [];\n        const emptyArray = [];\n        Object.freeze(emptyArray);\n        let getPossiblePatterns;\n        function getPossiblePatternsSlow() {\n            return patternIdxToConfig;\n        }\n        function getPossiblePatternsOptimized(charCode) {\n            const optimizedCharIdx = (0, lexer_1.charCodeToOptimizedIndex)(charCode);\n            const possiblePatterns = currCharCodeToPatternIdxToConfig[optimizedCharIdx];\n            if (possiblePatterns === undefined) {\n                return emptyArray;\n            }\n            else {\n                return possiblePatterns;\n            }\n        }\n        const pop_mode = (popToken) => {\n            // TODO: perhaps avoid this error in the edge case there is no more input?\n            if (modeStack.length === 1 &&\n                // if we have both a POP_MODE and a PUSH_MODE this is in-fact a \"transition\"\n                // So no error should occur.\n                popToken.tokenType.PUSH_MODE === undefined) {\n                // if we try to pop the last mode there lexer will no longer have ANY mode.\n                // thus the pop is ignored, an error will be created and the lexer will continue parsing in the previous mode.\n                const msg = this.config.errorMessageProvider.buildUnableToPopLexerModeMessage(popToken);\n                errors.push({\n                    offset: popToken.startOffset,\n                    line: popToken.startLine,\n                    column: popToken.startColumn,\n                    length: popToken.image.length,\n                    message: msg\n                });\n            }\n            else {\n                modeStack.pop();\n                const newMode = (0, last_1.default)(modeStack);\n                patternIdxToConfig = this.patternIdxToConfig[newMode];\n                currCharCodeToPatternIdxToConfig =\n                    this.charCodeToPatternIdxToConfig[newMode];\n                currModePatternsLength = patternIdxToConfig.length;\n                const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n                if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n                    getPossiblePatterns = getPossiblePatternsOptimized;\n                }\n                else {\n                    getPossiblePatterns = getPossiblePatternsSlow;\n                }\n            }\n        };\n        function push_mode(newMode) {\n            modeStack.push(newMode);\n            currCharCodeToPatternIdxToConfig =\n                this.charCodeToPatternIdxToConfig[newMode];\n            patternIdxToConfig = this.patternIdxToConfig[newMode];\n            currModePatternsLength = patternIdxToConfig.length;\n            currModePatternsLength = patternIdxToConfig.length;\n            const modeCanBeOptimized = this.canModeBeOptimized[newMode] && this.config.safeMode === false;\n            if (currCharCodeToPatternIdxToConfig && modeCanBeOptimized) {\n                getPossiblePatterns = getPossiblePatternsOptimized;\n            }\n            else {\n                getPossiblePatterns = getPossiblePatternsSlow;\n            }\n        }\n        // this pattern seems to avoid a V8 de-optimization, although that de-optimization does not\n        // seem to matter performance wise.\n        push_mode.call(this, initialMode);\n        let currConfig;\n        const recoveryEnabled = this.config.recoveryEnabled;\n        while (offset < orgLength) {\n            matchedImage = null;\n            const nextCharCode = orgText.charCodeAt(offset);\n            const chosenPatternIdxToConfig = getPossiblePatterns(nextCharCode);\n            const chosenPatternsLength = chosenPatternIdxToConfig.length;\n            for (i = 0; i < chosenPatternsLength; i++) {\n                currConfig = chosenPatternIdxToConfig[i];\n                const currPattern = currConfig.pattern;\n                payload = null;\n                // manually in-lined because > 600 chars won't be in-lined in V8\n                const singleCharCode = currConfig.short;\n                if (singleCharCode !== false) {\n                    if (nextCharCode === singleCharCode) {\n                        // single character string\n                        matchedImage = currPattern;\n                    }\n                }\n                else if (currConfig.isCustom === true) {\n                    match = currPattern.exec(orgText, offset, matchedTokens, groups);\n                    if (match !== null) {\n                        matchedImage = match[0];\n                        if (match.payload !== undefined) {\n                            payload = match.payload;\n                        }\n                    }\n                    else {\n                        matchedImage = null;\n                    }\n                }\n                else {\n                    this.updateLastIndex(currPattern, offset);\n                    matchedImage = this.match(currPattern, text, offset);\n                }\n                if (matchedImage !== null) {\n                    // even though this pattern matched we must try a another longer alternative.\n                    // this can be used to prioritize keywords over identifiers\n                    longerAlt = currConfig.longerAlt;\n                    if (longerAlt !== undefined) {\n                        // TODO: micro optimize, avoid extra prop access\n                        // by saving/linking longerAlt on the original config?\n                        const longerAltLength = longerAlt.length;\n                        for (k = 0; k < longerAltLength; k++) {\n                            const longerAltConfig = patternIdxToConfig[longerAlt[k]];\n                            const longerAltPattern = longerAltConfig.pattern;\n                            altPayload = null;\n                            // single Char can never be a longer alt so no need to test it.\n                            // manually in-lined because > 600 chars won't be in-lined in V8\n                            if (longerAltConfig.isCustom === true) {\n                                match = longerAltPattern.exec(orgText, offset, matchedTokens, groups);\n                                if (match !== null) {\n                                    matchAltImage = match[0];\n                                    if (match.payload !== undefined) {\n                                        altPayload = match.payload;\n                                    }\n                                }\n                                else {\n                                    matchAltImage = null;\n                                }\n                            }\n                            else {\n                                this.updateLastIndex(longerAltPattern, offset);\n                                matchAltImage = this.match(longerAltPattern, text, offset);\n                            }\n                            if (matchAltImage && matchAltImage.length > matchedImage.length) {\n                                matchedImage = matchAltImage;\n                                payload = altPayload;\n                                currConfig = longerAltConfig;\n                                // Exit the loop early after matching one of the longer alternatives\n                                // The first matched alternative takes precedence\n                                break;\n                            }\n                        }\n                    }\n                    break;\n                }\n            }\n            // successful match\n            if (matchedImage !== null) {\n                imageLength = matchedImage.length;\n                group = currConfig.group;\n                if (group !== undefined) {\n                    tokType = currConfig.tokenTypeIdx;\n                    // TODO: \"offset + imageLength\" and the new column may be computed twice in case of \"full\" location information inside\n                    // createFullToken method\n                    newToken = this.createTokenInstance(matchedImage, offset, tokType, currConfig.tokenType, line, column, imageLength);\n                    this.handlePayload(newToken, payload);\n                    // TODO: optimize NOOP in case there are no special groups?\n                    if (group === false) {\n                        matchedTokensIndex = this.addToken(matchedTokens, matchedTokensIndex, newToken);\n                    }\n                    else {\n                        groups[group].push(newToken);\n                    }\n                }\n                text = this.chopInput(text, imageLength);\n                offset = offset + imageLength;\n                // TODO: with newlines the column may be assigned twice\n                column = this.computeNewColumn(column, imageLength);\n                if (trackLines === true && currConfig.canLineTerminator === true) {\n                    let numOfLTsInMatch = 0;\n                    let foundTerminator;\n                    let lastLTEndOffset;\n                    lineTerminatorPattern.lastIndex = 0;\n                    do {\n                        foundTerminator = lineTerminatorPattern.test(matchedImage);\n                        if (foundTerminator === true) {\n                            lastLTEndOffset = lineTerminatorPattern.lastIndex - 1;\n                            numOfLTsInMatch++;\n                        }\n                    } while (foundTerminator === true);\n                    if (numOfLTsInMatch !== 0) {\n                        line = line + numOfLTsInMatch;\n                        column = imageLength - lastLTEndOffset;\n                        this.updateTokenEndLineColumnLocation(newToken, group, lastLTEndOffset, numOfLTsInMatch, line, column, imageLength);\n                    }\n                }\n                // will be NOOP if no modes present\n                this.handleModes(currConfig, pop_mode, push_mode, newToken);\n            }\n            else {\n                // error recovery, drop characters until we identify a valid token's start point\n                const errorStartOffset = offset;\n                const errorLine = line;\n                const errorColumn = column;\n                let foundResyncPoint = recoveryEnabled === false;\n                while (foundResyncPoint === false && offset < orgLength) {\n                    // Identity Func (when sticky flag is enabled)\n                    text = this.chopInput(text, 1);\n                    offset++;\n                    for (j = 0; j < currModePatternsLength; j++) {\n                        const currConfig = patternIdxToConfig[j];\n                        const currPattern = currConfig.pattern;\n                        // manually in-lined because > 600 chars won't be in-lined in V8\n                        const singleCharCode = currConfig.short;\n                        if (singleCharCode !== false) {\n                            if (orgText.charCodeAt(offset) === singleCharCode) {\n                                // single character string\n                                foundResyncPoint = true;\n                            }\n                        }\n                        else if (currConfig.isCustom === true) {\n                            foundResyncPoint =\n                                currPattern.exec(orgText, offset, matchedTokens, groups) !== null;\n                        }\n                        else {\n                            this.updateLastIndex(currPattern, offset);\n                            foundResyncPoint = currPattern.exec(text) !== null;\n                        }\n                        if (foundResyncPoint === true) {\n                            break;\n                        }\n                    }\n                }\n                errLength = offset - errorStartOffset;\n                // at this point we either re-synced or reached the end of the input text\n                msg = this.config.errorMessageProvider.buildUnexpectedCharactersMessage(orgText, errorStartOffset, errLength, errorLine, errorColumn);\n                errors.push({\n                    offset: errorStartOffset,\n                    line: errorLine,\n                    column: errorColumn,\n                    length: errLength,\n                    message: msg\n                });\n                if (recoveryEnabled === false) {\n                    break;\n                }\n            }\n        }\n        // if we do have custom patterns which push directly into the\n        // TODO: custom tokens should not push directly??\n        if (!this.hasCustom) {\n            // if we guessed a too large size for the tokens array this will shrink it to the right size.\n            matchedTokens.length = matchedTokensIndex;\n        }\n        return {\n            tokens: matchedTokens,\n            groups: groups,\n            errors: errors\n        };\n    }\n    handleModes(config, pop_mode, push_mode, newToken) {\n        if (config.pop === true) {\n            // need to save the PUSH_MODE property as if the mode is popped\n            // patternIdxToPopMode is updated to reflect the new mode after popping the stack\n            const pushMode = config.push;\n            pop_mode(newToken);\n            if (pushMode !== undefined) {\n                push_mode.call(this, pushMode);\n            }\n        }\n        else if (config.push !== undefined) {\n            push_mode.call(this, config.push);\n        }\n    }\n    chopInput(text, length) {\n        return text.substring(length);\n    }\n    updateLastIndex(regExp, newLastIndex) {\n        regExp.lastIndex = newLastIndex;\n    }\n    // TODO: decrease this under 600 characters? inspect stripping comments option in TSC compiler\n    updateTokenEndLineColumnLocation(newToken, group, lastLTIdx, numOfLTsInMatch, line, column, imageLength) {\n        let lastCharIsLT, fixForEndingInLT;\n        if (group !== undefined) {\n            // a none skipped multi line Token, need to update endLine/endColumn\n            lastCharIsLT = lastLTIdx === imageLength - 1;\n            fixForEndingInLT = lastCharIsLT ? -1 : 0;\n            if (!(numOfLTsInMatch === 1 && lastCharIsLT === true)) {\n                // if a token ends in a LT that last LT only affects the line numbering of following Tokens\n                newToken.endLine = line + fixForEndingInLT;\n                // the last LT in a token does not affect the endColumn either as the [columnStart ... columnEnd)\n                // inclusive to exclusive range.\n                newToken.endColumn = column - 1 + -fixForEndingInLT;\n            }\n            // else single LT in the last character of a token, no need to modify the endLine/EndColumn\n        }\n    }\n    computeNewColumn(oldColumn, imageLength) {\n        return oldColumn + imageLength;\n    }\n    createOffsetOnlyToken(image, startOffset, tokenTypeIdx, tokenType) {\n        return {\n            image,\n            startOffset,\n            tokenTypeIdx,\n            tokenType\n        };\n    }\n    createStartOnlyToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn) {\n        return {\n            image,\n            startOffset,\n            startLine,\n            startColumn,\n            tokenTypeIdx,\n            tokenType\n        };\n    }\n    createFullToken(image, startOffset, tokenTypeIdx, tokenType, startLine, startColumn, imageLength) {\n        return {\n            image,\n            startOffset,\n            endOffset: startOffset + imageLength - 1,\n            startLine,\n            endLine: startLine,\n            startColumn,\n            endColumn: startColumn + imageLength - 1,\n            tokenTypeIdx,\n            tokenType\n        };\n    }\n    addTokenUsingPush(tokenVector, index, tokenToAdd) {\n        tokenVector.push(tokenToAdd);\n        return index;\n    }\n    addTokenUsingMemberAccess(tokenVector, index, tokenToAdd) {\n        tokenVector[index] = tokenToAdd;\n        index++;\n        return index;\n    }\n    handlePayloadNoCustom(token, payload) { }\n    handlePayloadWithCustom(token, payload) {\n        if (payload !== null) {\n            token.payload = payload;\n        }\n    }\n    matchWithTest(pattern, text, offset) {\n        const found = pattern.test(text);\n        if (found === true) {\n            return text.substring(offset, pattern.lastIndex);\n        }\n        return null;\n    }\n    matchWithExec(pattern, text) {\n        const regExpArray = pattern.exec(text);\n        return regExpArray !== null ? regExpArray[0] : null;\n    }\n}\nexports.Lexer = Lexer;\nLexer.SKIPPED = \"This marks a skipped Token pattern, this means each token identified by it will\" +\n    \"be consumed and then thrown into oblivion, this can be used to for example to completely ignore whitespace.\";\nLexer.NA = /NOT_APPLICABLE/;\n//# sourceMappingURL=lexer_public.js.map"]},"metadata":{},"sourceType":"script"}